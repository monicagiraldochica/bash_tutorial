{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to shell scripting Shell is used to run commands on the operating system. These can be simple instructions such as copying or moving files, or long scripts that contain hundreds of commands. Users typically interact with a shell using a terminal window (command line), which can be run from the same or a remote machine. There are different types of shells, but I will refer in this tutorial only to the Bourne-Again shell. Bash is the programming language used to write commands and scripts in shell. The terminal window for Mac can be found inside the applications folder and in the subfolder Utilities. You can also open it by pressing the command and space bar in your keyboard to open the spotlight, and then type Terminal. In Linux, the easiest way to open the terminal is to use the key combination Ctl + Alt + T. Shell scripting is very powerful. Things that would take hours to do by hand, could be executed in seconds. However, it can also be dangerous. Through the terminal you will have access to any files or system resources if you have the right permissions, and the freedom to do anything with them. Inadvertent \"small\" typing errors such as adding an extra space in the remove command could delete everything in your computer (including the root directory) or any external drive connected to your machine. Unfortunately, there is no way to completely protect your computer from potential mistakes that you may do when writing and running shell scripts. However, there are a couple of tips that you can follow in order to minimize the chances of making unfixable mistakes: Create constant backups. Preferably save those in an external hard drive or remote machine, which won't be constantly connected to your computer. It is not a bad idea to have more than one backup if your data is not easily recoverable. If you're using a shared computer or account, control access permissions to important files and folders. By managing permissions , you can allow a file to be read but not to written (hence preventing it from being modified or deleted). The root user is an account in any Linux or Unix operating system that has access to all commands, files and directories. This is very helpful when installing software or modifying the default settings of your computer. However, coding as the root user can be extremely dangerous. For this reason, it is advisable to only login as a root when strictly necessary and log out once you're done. Use aliases to protect from \"dangerous\" commands. Two of the most commonly used but dangerous commands are rm (to remove files) and mv (to move files). When you use any of these two commands, always double check what you have written before clicking enter. Be careful when copy pasting commands from a website into the terminal. There can be errors that will be executed right away if the text you're copying contains a carriage return at the end of the line. It is better to paste into a shell script and then either execute the shell script or copy from the shell script into the command line. Although generally not dangerous, you might also run into errors when copy pasting from Microsoft word or other editors that modify symbols such as dash or underscore and convert them into new symbols that Bash won't understand.","title":"Home"},{"location":"#introduction-to-shell-scripting","text":"Shell is used to run commands on the operating system. These can be simple instructions such as copying or moving files, or long scripts that contain hundreds of commands. Users typically interact with a shell using a terminal window (command line), which can be run from the same or a remote machine. There are different types of shells, but I will refer in this tutorial only to the Bourne-Again shell. Bash is the programming language used to write commands and scripts in shell. The terminal window for Mac can be found inside the applications folder and in the subfolder Utilities. You can also open it by pressing the command and space bar in your keyboard to open the spotlight, and then type Terminal. In Linux, the easiest way to open the terminal is to use the key combination Ctl + Alt + T. Shell scripting is very powerful. Things that would take hours to do by hand, could be executed in seconds. However, it can also be dangerous. Through the terminal you will have access to any files or system resources if you have the right permissions, and the freedom to do anything with them. Inadvertent \"small\" typing errors such as adding an extra space in the remove command could delete everything in your computer (including the root directory) or any external drive connected to your machine. Unfortunately, there is no way to completely protect your computer from potential mistakes that you may do when writing and running shell scripts. However, there are a couple of tips that you can follow in order to minimize the chances of making unfixable mistakes: Create constant backups. Preferably save those in an external hard drive or remote machine, which won't be constantly connected to your computer. It is not a bad idea to have more than one backup if your data is not easily recoverable. If you're using a shared computer or account, control access permissions to important files and folders. By managing permissions , you can allow a file to be read but not to written (hence preventing it from being modified or deleted). The root user is an account in any Linux or Unix operating system that has access to all commands, files and directories. This is very helpful when installing software or modifying the default settings of your computer. However, coding as the root user can be extremely dangerous. For this reason, it is advisable to only login as a root when strictly necessary and log out once you're done. Use aliases to protect from \"dangerous\" commands. Two of the most commonly used but dangerous commands are rm (to remove files) and mv (to move files). When you use any of these two commands, always double check what you have written before clicking enter. Be careful when copy pasting commands from a website into the terminal. There can be errors that will be executed right away if the text you're copying contains a carriage return at the end of the line. It is better to paste into a shell script and then either execute the shell script or copy from the shell script into the command line. Although generally not dangerous, you might also run into errors when copy pasting from Microsoft word or other editors that modify symbols such as dash or underscore and convert them into new symbols that Bash won't understand.","title":"Introduction to shell scripting"},{"location":"advanced_bash/","text":"Complex bash scripts Reading arguments Using functions Using libraries Parallel processes","title":"Advanced bash"},{"location":"advanced_bash/#complex-bash-scripts","text":"","title":"Complex bash scripts"},{"location":"advanced_bash/#reading-arguments","text":"","title":"Reading arguments"},{"location":"advanced_bash/#using-functions","text":"","title":"Using functions"},{"location":"advanced_bash/#using-libraries","text":"","title":"Using libraries"},{"location":"advanced_bash/#parallel-processes","text":"","title":"Parallel processes"},{"location":"aliases/","text":"Aliases","title":"Aliases"},{"location":"aliases/#aliases","text":"","title":"Aliases"},{"location":"arrays/","text":"Arrays Declaring and assigning values An array is a data structure that stores a group of elements. Unlike in other programming languages, in Bash you don't need to specify the type of elements that the array will contain, and you can mix different types of elements in the same array. For example, an array can contain strings and numbers. You can create and add elements to an array in different ways: Keep in mind that in Bash the first element of an array is always in INDEX =0, instead of INDEX =1. Syntax Usage ARRAY[INDEX]=VAL If ARRAY has not been initialized, it will create the array and put element VAL in the position INDEX . If ARRAY already exists, it will replace ARRAY in the position INDEX with the new value VAL . declare -a ARRAY=('VAL1' 'VAL2' 'VAL3' ...) Initializes ARRAY and puts the values inside the parenthesis into the array, respecting the same order. The array is emptied before assigning the values if it already exists. read -a ARRAY Each word that the user input is assigned to sequential indices of ARRAY . The words must be separated by spaces. The array is emptied before assigning the values if it already exists. IFS='DEL' read -a ARRAY Splits the user input using delimiter DEL , which must be a character or a space. Then, saves the different elements into ARRAY . The array is emptied before assigning the values if it already exists. IFS='DEL' read -a ARRAY <<< STRING Splits STRING using delimiter DEL , which must be a character or a space. Then, saves the different elements into ARRAY . The array is emptied before assigning the values if it already exists. ARRAY=($(seq FIRST STEP SIZE)) Creates an array of equally spaced numbers beginning with FIRST and separated by STEP . It will add SIZE numbers to ARRAY . ARRAY=$(count -digits N FIRST LAST) Creates an array of numbers, each with N number of digits, starting with FIRST and ending with LAST . If the number has less digits, it will add zeros in front (i.e. if using two digits, number 1 will be saved as 01 in the array). ARRAY=$(seq N) Creates an array of sequential numbers, starting with 1 and ending with N . ARRAY=(ELEMENT1 ELEMENT3 ...) Creates an array with the elements specified inside the parenthesis. Usage of ${ARRAY[INDEX]} The following examples will use the syntax ${ARRAY[INDEX]} to access the element located in the position INDEX inside ARRAY . After assigning all the values to my array, I can print its contents using the expression echo ${ARRAY[@]} . I can also check the size of my array using echo ${#ARRAY[@]} . If I add an element to a position where the array already contains an element, then the old value will be replaced by the new value. In the example below, 59 was initially added to the position 0 of the array age . When another element ( 72 ) is added to the position 0, the previous value ( 59 ) is replaced. Create an array called age and add 5 elements to it: age[0]=59 age[1]=63 age[2]=21 age[3]=15 age[4]=94 Print the content of the array: $ echo \"Array: ${age[@]}\" Array: 59 63 21 15 94 Get the array size: $ echo \"Array size: ${#age[@]}\" Array size: 5 Get the first, second, last and penultimate elements of the array: $ echo \"First element: ${age[0]}\" First element: 59 $ echo \"Second element: ${age[1]}\" Second element: 63 $ size=${#age[@]} $ echo \"Last element: ${age[size-1]}\" Last element: 94 $ echo \"Penultimate element: ${age[size-2]}\" Penultimate element: 15 Replace the first value of the array for 72: $ age[0]=72 $ echo \"New array: ${age[@]}\" New array: 72 63 21 15 94 In the following example I will start assigning values to the array in the position 1 (instead of 0). That is not a problem, but the first position of my array ( index=0 ) will remain empty, and my array will have only 4 values. If I echo the item in position 0 ( echo ${ARRAY[0]} ), I will get an empty string. Since I had previously created an array with the same name ( age ), I should first unset that variable (delete it). It is a good idea to do it if you're not sure if you already used that variable name before and you want to make sure you're creating a variable from zero. Delete the variable (empty array): $ echo \"Array: ${age[@]}\" Array: 72 63 21 15 94 $ unset age $ echo \"Array: ${age[@]}\" Array: Create a new array with new elements, staring in the position 1 instead of 0: $ age[1]=63 $ age[2]=21 $ age[3]=15 $ age[4]=94 $ echo \"Array: ${age[@]}\" Array: 63 21 15 94 $ echo \"Array size: ${#age[@]}\" Array size: 4 $ echo \"age[0]: ${age[0]}\" age[0]: $ echo \"age[1]: ${age[1]}\" age[1]: 63 Usage of declare -a ARRAY=('VAL1' 'VAL2' 'VAL3' ...) It is also possible to initiate an array and assign all the values at the same time. After you declare an array with some elements, it doesn't need to stay static. You can keep adding items. To initiate the array with some values: declare -a array=('France' 'Italy' 'Germany' 'Spain' 'Canada') To read the different elements of the array: $ echo \"The element in position 0 is: ${array[0]}\" The element in position 0 is: France $ echo \"The element in position 1 is: ${array[1]}\" The element in position 1 is: Italy $ echo \"The element in position 2 is: ${array[2]}\" The element in position 2 is: Germany $ echo \"The element in position 3 is: ${array[3]}\" The element in position 3 is: Spain $ echo \"The element in position 4 is: ${array[4]}\" The element in position 4 is: Canada $ echo \"List of elements in the array: ${array[@]}\" List of elements in the array: France Italy Germany Spain Canada To get the number of elements in the array: $ echo \"The number of elements in the array is ${#array[@]}\" The number of elements in the array is 5 To add more items into the array: $ array[5]=\"Argentina\" $ array[6]=\"Finland\" $ echo \"List of elements in the array: ${array[@]}\" List of elements in the array: France Italy Germany Spain Canada Argentina Mexico $ n=${#array[@]} $ echo \"The number of elements in the array is ${n}\" The number of elements in the array is 7 Usage of read -a ARRAY Another way of creating and initializing an array is by reading a user input. The command read captures the user input and saves it in a variable. By using the flag -a , the user can input more than one word (separated by a space) and Bash will assign each word to sequential indexes of the array, starting at 0. $ read -a ARRAY Element1 Element2 Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3 Usage of IFS='DEL' read -a ARRAY If you want to use a different delimiter other than a space to split the user input into array elements, you can add IFS='DEL' before read, with DEL being any character. $ IFS='/' read -a ARRAY Element1/Element2/Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3 $ IFS='.' read -a ARRAY Element1.Element2.Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3 If the wrong delimiter is used, the array wont be split correctly: $ IFS='/' read -a ARRAY Element1.Element2.Element3 $ echo \"${ARRAY[0]}\" Element1.Element2.Element3 $ echo \"${ARRAY[1]}\" $ echo \"${ARRAY[2]}\" Usage of IFS='DEL' read -a ARRAY <<< STRING You can also split elements of a string. This is very useful when trying to access parts of a file path: $ IFS='/' read -a ARRAY <<< \"Element1/Element2/Element3\" $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: Element1 $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: Element2 $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: Element3 In the following example the delimiter is a slash ( / ). However, there are no characters before the first slash. So, the first element of the array will be empty. That empty value will still be counted when asking for the array size, and will be located in the position 0. So, home will be located in position 1 of the array instead of position 0. $ my_string=\"/home/myuser/Documents/folder/subfolder\" $ echo \"String: ${my_string}\" String: /home/myuser/Documents/folder/subfolder $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: home $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: myuser $ echo \"ARRAY[3]: ${ARRAY[3]}\" ARRAY[3]: Documents $ echo \"ARRAY[4]: ${ARRAY[4]}\" ARRAY[4]: folder $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: subfolder $ echo \"Array elements: ${ARRAY[@]}\" Array elements: home myuser Documents folder subfolder $ echo \"Array size: ${#ARRAY[@]}\" Array size: 6 In the third example there are no characters after the last slash. If the last character of the input string is the same as the delimiter, it will not add an empty character to the end of the array. So, the size of the array will be the same as if you exclude that last delimiter. $ my_string=\"/home/myuser/Documents/folder/subfolder/\" $ echo \"String: ${my_string}\" String: /home/myuser/Documents/folder/subfolder/ $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 6 However, if there is more than one repetition of the delimiter at the end of the string, then the empty space between the two delimiters is counted as an element in the array: $ my_string=\"/home/myuser/Documents/folder/subfolder//\" $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 7 $ my_string=\"/home/myuser/Documents/folder/subfolder//file.txt\" $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 8 $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: subfolder $ echo \"ARRAY[6]: ${ARRAY[6]}\" ARRAY[6]: $ echo \"ARRAY[7]: ${ARRAY[7]}\" ARRAY[7]: file.txt Usage of ARRAY=($(seq FIRST STEP SIZE)) To create an array of equally spaced or consecutive numbers, use seq . In the following examples, I will create an array of numbers that goes from 15 to 19. The distance between each number ( STEP ) will vary in each example. When the step between numbers is 1, it doesn't need to be specified. Array of equally spaced numbers (step size 0.5) from 15 to 19: $ ARRAY=($(seq 15 0.5 19)) $ echo \"Array of equally spaced numbers (step size 0.5) from 15 to 19: ${ARRAY[@]}\" Array of equally spaced numbers (step size 0.5) from 15 to 19: 15 15.5 16 16.5 17 17.5 18 18.5 19 $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: 15 $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: 15.5 $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: 16 $ echo \"ARRAY[3]: ${ARRAY[3]}\" ARRAY[3]: 16.5 $ echo \"ARRAY[4]: ${ARRAY[4]}\" ARRAY[4]: 17 $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: 17.5 $ echo \"ARRAY[6]: ${ARRAY[6]}\" ARRAY[6]: 18 $ echo \"ARRAY[7]: ${ARRAY[7]}\" ARRAY[7]: 18.5 $ echo \"ARRAY[8]: ${ARRAY[8]}\" ARRAY[8]: 19 $ echo \"Array size: ${#ARRAY[@]}\" Array size: 9 Array of equally spaced numbers (step size 2) from 1 to 10: $ ARRAY=($(seq 1 2 10)) $ # Print array $ echo \"Array of equally spaced numbers (step size 2) from 1 to 10: ${ARRAY[@]}\" Array of equally spaced numbers (step size 2) from 1 to 10: 1 3 5 7 9 $ echo \"Array size: ${#ARRAY[@]}\" Array size: 5 Array of equally spaced numbers (step size 1) from 15 to 19: $ echo \"Array of equally spaced numbers (step size 1) from 15 to 19:\" Array of equally spaced numbers (step size 1) from 15 to 19: $ ARRAY1=($(seq 15 1 19)) $ echo \"Array1 (specifying the step size): ${ARRAY1[@]}\" Array1 (specifying the step size): 15 16 17 18 19 $ ARRAY2=($(seq 15 19)) $ echo \"Array2 (not specifying the step size): ${ARRAY2[@]}\" Array2 (not specifying the step size): 15 16 17 18 19 Bash has functions that return a list of elements. For example, as you will learn in the section of file manipulation , the command ls returns the list of files in your current working directory. In these cases, instead of manually entering a list of elements between parentheses to convert into an array, you can write the function name, and its output will be saved in the array: $ # Array will contain the list of files in the current directory $ array=($(ls)) $ echo \"Array: ${array[@]}\" Array: README.md Untitled.html Untitled.ipynb bash.html content1.html content10.html content10_1.html content11.html content11_1.html content11_2.html content11_3.html content11_4.html content12.html content13.html content14.html content15.html content16.html content17.html content18.html content19.html content2.html content20.html content2_1.html content2_2.html content2_3.html content2_4.html content3.html content3_1.html content3_2.html content3_3.html content3_4.html content4.html content4_1.html content4_2.html content5.html content5_1.html content5_2.html content6.html content6_1.html content6_2.html content6_3.html content6_4.html content6_5.html content7.html content7_1.html content7_2.html content7_3.html content8.html content8_1.html content8_2.html content8_3.html content8_4.html content9.html content9_1.html content9_10.html content9_11.html content9_12.html content9_13.html content9_14.html content9_15.html content9_16.html content9_2.html content9_3.html content9_4.html content9_5.html content9_6.html content9_7.html content9_8.html content9_9.html cropped.png flipped.png flipped2.png functions.js index.html neuroimgsoft.html pwd.png resampled.png rotated1.png rotated2.png styles.css styles2.css tmp.html vi_1.png vi_2.png vi_3.png vi_4.png vi_5.png vi_6.png","title":"Arrays"},{"location":"arrays/#arrays","text":"","title":"Arrays"},{"location":"arrays/#declaring-and-assigning-values","text":"An array is a data structure that stores a group of elements. Unlike in other programming languages, in Bash you don't need to specify the type of elements that the array will contain, and you can mix different types of elements in the same array. For example, an array can contain strings and numbers. You can create and add elements to an array in different ways: Keep in mind that in Bash the first element of an array is always in INDEX =0, instead of INDEX =1. Syntax Usage ARRAY[INDEX]=VAL If ARRAY has not been initialized, it will create the array and put element VAL in the position INDEX . If ARRAY already exists, it will replace ARRAY in the position INDEX with the new value VAL . declare -a ARRAY=('VAL1' 'VAL2' 'VAL3' ...) Initializes ARRAY and puts the values inside the parenthesis into the array, respecting the same order. The array is emptied before assigning the values if it already exists. read -a ARRAY Each word that the user input is assigned to sequential indices of ARRAY . The words must be separated by spaces. The array is emptied before assigning the values if it already exists. IFS='DEL' read -a ARRAY Splits the user input using delimiter DEL , which must be a character or a space. Then, saves the different elements into ARRAY . The array is emptied before assigning the values if it already exists. IFS='DEL' read -a ARRAY <<< STRING Splits STRING using delimiter DEL , which must be a character or a space. Then, saves the different elements into ARRAY . The array is emptied before assigning the values if it already exists. ARRAY=($(seq FIRST STEP SIZE)) Creates an array of equally spaced numbers beginning with FIRST and separated by STEP . It will add SIZE numbers to ARRAY . ARRAY=$(count -digits N FIRST LAST) Creates an array of numbers, each with N number of digits, starting with FIRST and ending with LAST . If the number has less digits, it will add zeros in front (i.e. if using two digits, number 1 will be saved as 01 in the array). ARRAY=$(seq N) Creates an array of sequential numbers, starting with 1 and ending with N . ARRAY=(ELEMENT1 ELEMENT3 ...) Creates an array with the elements specified inside the parenthesis.","title":"Declaring and assigning values"},{"location":"arrays/#usage-of-arrayindex","text":"The following examples will use the syntax ${ARRAY[INDEX]} to access the element located in the position INDEX inside ARRAY . After assigning all the values to my array, I can print its contents using the expression echo ${ARRAY[@]} . I can also check the size of my array using echo ${#ARRAY[@]} . If I add an element to a position where the array already contains an element, then the old value will be replaced by the new value. In the example below, 59 was initially added to the position 0 of the array age . When another element ( 72 ) is added to the position 0, the previous value ( 59 ) is replaced. Create an array called age and add 5 elements to it: age[0]=59 age[1]=63 age[2]=21 age[3]=15 age[4]=94 Print the content of the array: $ echo \"Array: ${age[@]}\" Array: 59 63 21 15 94 Get the array size: $ echo \"Array size: ${#age[@]}\" Array size: 5 Get the first, second, last and penultimate elements of the array: $ echo \"First element: ${age[0]}\" First element: 59 $ echo \"Second element: ${age[1]}\" Second element: 63 $ size=${#age[@]} $ echo \"Last element: ${age[size-1]}\" Last element: 94 $ echo \"Penultimate element: ${age[size-2]}\" Penultimate element: 15 Replace the first value of the array for 72: $ age[0]=72 $ echo \"New array: ${age[@]}\" New array: 72 63 21 15 94 In the following example I will start assigning values to the array in the position 1 (instead of 0). That is not a problem, but the first position of my array ( index=0 ) will remain empty, and my array will have only 4 values. If I echo the item in position 0 ( echo ${ARRAY[0]} ), I will get an empty string. Since I had previously created an array with the same name ( age ), I should first unset that variable (delete it). It is a good idea to do it if you're not sure if you already used that variable name before and you want to make sure you're creating a variable from zero. Delete the variable (empty array): $ echo \"Array: ${age[@]}\" Array: 72 63 21 15 94 $ unset age $ echo \"Array: ${age[@]}\" Array: Create a new array with new elements, staring in the position 1 instead of 0: $ age[1]=63 $ age[2]=21 $ age[3]=15 $ age[4]=94 $ echo \"Array: ${age[@]}\" Array: 63 21 15 94 $ echo \"Array size: ${#age[@]}\" Array size: 4 $ echo \"age[0]: ${age[0]}\" age[0]: $ echo \"age[1]: ${age[1]}\" age[1]: 63","title":"Usage of ${ARRAY[INDEX]}"},{"location":"arrays/#usage-of-declare-a-arrayval1-val2-val3","text":"It is also possible to initiate an array and assign all the values at the same time. After you declare an array with some elements, it doesn't need to stay static. You can keep adding items. To initiate the array with some values: declare -a array=('France' 'Italy' 'Germany' 'Spain' 'Canada') To read the different elements of the array: $ echo \"The element in position 0 is: ${array[0]}\" The element in position 0 is: France $ echo \"The element in position 1 is: ${array[1]}\" The element in position 1 is: Italy $ echo \"The element in position 2 is: ${array[2]}\" The element in position 2 is: Germany $ echo \"The element in position 3 is: ${array[3]}\" The element in position 3 is: Spain $ echo \"The element in position 4 is: ${array[4]}\" The element in position 4 is: Canada $ echo \"List of elements in the array: ${array[@]}\" List of elements in the array: France Italy Germany Spain Canada To get the number of elements in the array: $ echo \"The number of elements in the array is ${#array[@]}\" The number of elements in the array is 5 To add more items into the array: $ array[5]=\"Argentina\" $ array[6]=\"Finland\" $ echo \"List of elements in the array: ${array[@]}\" List of elements in the array: France Italy Germany Spain Canada Argentina Mexico $ n=${#array[@]} $ echo \"The number of elements in the array is ${n}\" The number of elements in the array is 7","title":"Usage of declare -a ARRAY=('VAL1' 'VAL2' 'VAL3' ...)"},{"location":"arrays/#usage-of-read-a-array","text":"Another way of creating and initializing an array is by reading a user input. The command read captures the user input and saves it in a variable. By using the flag -a , the user can input more than one word (separated by a space) and Bash will assign each word to sequential indexes of the array, starting at 0. $ read -a ARRAY Element1 Element2 Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3","title":"Usage of read -a ARRAY"},{"location":"arrays/#usage-of-ifsdel-read-a-array","text":"If you want to use a different delimiter other than a space to split the user input into array elements, you can add IFS='DEL' before read, with DEL being any character. $ IFS='/' read -a ARRAY Element1/Element2/Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3 $ IFS='.' read -a ARRAY Element1.Element2.Element3 $ echo \"${ARRAY[0]}\" Element1 $ echo \"${ARRAY[1]}\" Element2 $ echo \"${ARRAY[2]}\" Element3 If the wrong delimiter is used, the array wont be split correctly: $ IFS='/' read -a ARRAY Element1.Element2.Element3 $ echo \"${ARRAY[0]}\" Element1.Element2.Element3 $ echo \"${ARRAY[1]}\" $ echo \"${ARRAY[2]}\"","title":"Usage of IFS='DEL' read -a ARRAY"},{"location":"arrays/#usage-of-ifsdel-read-a-array-string","text":"You can also split elements of a string. This is very useful when trying to access parts of a file path: $ IFS='/' read -a ARRAY <<< \"Element1/Element2/Element3\" $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: Element1 $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: Element2 $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: Element3 In the following example the delimiter is a slash ( / ). However, there are no characters before the first slash. So, the first element of the array will be empty. That empty value will still be counted when asking for the array size, and will be located in the position 0. So, home will be located in position 1 of the array instead of position 0. $ my_string=\"/home/myuser/Documents/folder/subfolder\" $ echo \"String: ${my_string}\" String: /home/myuser/Documents/folder/subfolder $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: home $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: myuser $ echo \"ARRAY[3]: ${ARRAY[3]}\" ARRAY[3]: Documents $ echo \"ARRAY[4]: ${ARRAY[4]}\" ARRAY[4]: folder $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: subfolder $ echo \"Array elements: ${ARRAY[@]}\" Array elements: home myuser Documents folder subfolder $ echo \"Array size: ${#ARRAY[@]}\" Array size: 6 In the third example there are no characters after the last slash. If the last character of the input string is the same as the delimiter, it will not add an empty character to the end of the array. So, the size of the array will be the same as if you exclude that last delimiter. $ my_string=\"/home/myuser/Documents/folder/subfolder/\" $ echo \"String: ${my_string}\" String: /home/myuser/Documents/folder/subfolder/ $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 6 However, if there is more than one repetition of the delimiter at the end of the string, then the empty space between the two delimiters is counted as an element in the array: $ my_string=\"/home/myuser/Documents/folder/subfolder//\" $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 7 $ my_string=\"/home/myuser/Documents/folder/subfolder//file.txt\" $ IFS='/' read -a ARRAY <<< \"${my_string}\" $ echo \"Array size: ${#ARRAY[@]}\" Array size: 8 $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: subfolder $ echo \"ARRAY[6]: ${ARRAY[6]}\" ARRAY[6]: $ echo \"ARRAY[7]: ${ARRAY[7]}\" ARRAY[7]: file.txt","title":"Usage of IFS='DEL' read -a ARRAY &lt;&lt;&lt; STRING"},{"location":"arrays/#usage-of-arrayseq-first-step-size","text":"To create an array of equally spaced or consecutive numbers, use seq . In the following examples, I will create an array of numbers that goes from 15 to 19. The distance between each number ( STEP ) will vary in each example. When the step between numbers is 1, it doesn't need to be specified. Array of equally spaced numbers (step size 0.5) from 15 to 19: $ ARRAY=($(seq 15 0.5 19)) $ echo \"Array of equally spaced numbers (step size 0.5) from 15 to 19: ${ARRAY[@]}\" Array of equally spaced numbers (step size 0.5) from 15 to 19: 15 15.5 16 16.5 17 17.5 18 18.5 19 $ echo \"ARRAY[0]: ${ARRAY[0]}\" ARRAY[0]: 15 $ echo \"ARRAY[1]: ${ARRAY[1]}\" ARRAY[1]: 15.5 $ echo \"ARRAY[2]: ${ARRAY[2]}\" ARRAY[2]: 16 $ echo \"ARRAY[3]: ${ARRAY[3]}\" ARRAY[3]: 16.5 $ echo \"ARRAY[4]: ${ARRAY[4]}\" ARRAY[4]: 17 $ echo \"ARRAY[5]: ${ARRAY[5]}\" ARRAY[5]: 17.5 $ echo \"ARRAY[6]: ${ARRAY[6]}\" ARRAY[6]: 18 $ echo \"ARRAY[7]: ${ARRAY[7]}\" ARRAY[7]: 18.5 $ echo \"ARRAY[8]: ${ARRAY[8]}\" ARRAY[8]: 19 $ echo \"Array size: ${#ARRAY[@]}\" Array size: 9 Array of equally spaced numbers (step size 2) from 1 to 10: $ ARRAY=($(seq 1 2 10)) $ # Print array $ echo \"Array of equally spaced numbers (step size 2) from 1 to 10: ${ARRAY[@]}\" Array of equally spaced numbers (step size 2) from 1 to 10: 1 3 5 7 9 $ echo \"Array size: ${#ARRAY[@]}\" Array size: 5 Array of equally spaced numbers (step size 1) from 15 to 19: $ echo \"Array of equally spaced numbers (step size 1) from 15 to 19:\" Array of equally spaced numbers (step size 1) from 15 to 19: $ ARRAY1=($(seq 15 1 19)) $ echo \"Array1 (specifying the step size): ${ARRAY1[@]}\" Array1 (specifying the step size): 15 16 17 18 19 $ ARRAY2=($(seq 15 19)) $ echo \"Array2 (not specifying the step size): ${ARRAY2[@]}\" Array2 (not specifying the step size): 15 16 17 18 19 Bash has functions that return a list of elements. For example, as you will learn in the section of file manipulation , the command ls returns the list of files in your current working directory. In these cases, instead of manually entering a list of elements between parentheses to convert into an array, you can write the function name, and its output will be saved in the array: $ # Array will contain the list of files in the current directory $ array=($(ls)) $ echo \"Array: ${array[@]}\" Array: README.md Untitled.html Untitled.ipynb bash.html content1.html content10.html content10_1.html content11.html content11_1.html content11_2.html content11_3.html content11_4.html content12.html content13.html content14.html content15.html content16.html content17.html content18.html content19.html content2.html content20.html content2_1.html content2_2.html content2_3.html content2_4.html content3.html content3_1.html content3_2.html content3_3.html content3_4.html content4.html content4_1.html content4_2.html content5.html content5_1.html content5_2.html content6.html content6_1.html content6_2.html content6_3.html content6_4.html content6_5.html content7.html content7_1.html content7_2.html content7_3.html content8.html content8_1.html content8_2.html content8_3.html content8_4.html content9.html content9_1.html content9_10.html content9_11.html content9_12.html content9_13.html content9_14.html content9_15.html content9_16.html content9_2.html content9_3.html content9_4.html content9_5.html content9_6.html content9_7.html content9_8.html content9_9.html cropped.png flipped.png flipped2.png functions.js index.html neuroimgsoft.html pwd.png resampled.png rotated1.png rotated2.png styles.css styles2.css tmp.html vi_1.png vi_2.png vi_3.png vi_4.png vi_5.png vi_6.png","title":"Usage of ARRAY=($(seq FIRST STEP SIZE))"},{"location":"backups/","text":"Creating backups","title":"Backups"},{"location":"backups/#creating-backups","text":"","title":"Creating backups"},{"location":"cluster/","text":"Cluster jobs","title":"Cluster jobs"},{"location":"cluster/#cluster-jobs","text":"","title":"Cluster jobs"},{"location":"condition_test/","text":"Condition-testing Variables can be used to test if a certain condition is true or false , and therefore be able to take a different course of action depending on the result of the test. For example, you might want to evaluate if a file exists to decide if you can copy it into a different folder or not. For condition-testing you will use the if command. This command has the following syntax: if [ CONDITION TO EVALUATE ] then INSTRUCTIONS THAT WILL RUN IF THE CONDITION IS TRUE elif [ OTHER CONDITION TO EVALUATE IF 1ST CONDITION IS FALSE ] then INSTRUCTIONS THAT WILL RUN IF FIRST CONDITION IS FALSE BUT SECOND IS TRUE else INSTRUCTIONS THAT WILL RUN IF ALL THE PREVIOUS CONDITIONS ARE FALSE fi The CONDITION TO EVALUATE is an expression that follows a specific syntax depending on what you want to test (checking files, string comparison, comparing numbers, or combining different expressions). Lets look at the different syntaxes used in each of these situations and at some examples that will help you understand this seemingly confusing subject. Condition-testing to check files In the following table, FILE refers to the path of the file, or to the variable that contains the path of the file. The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ -a FILE ] Tests if FILE exists. [ -d FILE ] Tests if FILE exists and is a directory. [ -e FILE ] Tests if FILE exists. [ -f FILE ] Tests if FILE exists and is a regular file. [ -g FILE ] Tests if FILE exists and its SGID bit is set. [ -h FILE ] Tests if FILE exists and is a symbolic link. [ -k FILE ] Tests if FILE exists and its sticky bit is set. [ -p FILE ] Tests if FILE exists and is a named pipe ( FIFO ). [ -r FILE ] Tests if FILE exists and is readable. [ -s FILE ] Tests if FILE exists and has a size greater than zero. [ -t FD ] Tests if file descriptor FD is open and refers to a terminal. [ -u FILE ] Tests if FILE exists and its SUID (set user ID) bit is set. [ -w FILE ] Tests if FILE exists and is writable. [ -x FILE ] Tests if FILE exists and is executable. [ -O FILE ] Tests if FILE exists and is owned by the effective user ID. [ -G FILE ] Tests if FILE exists and is owned by the effective group ID. [ -L FILE ] Tests if FILE exists and is a symbolic link. [ -N FILE ] Tests if FILE exists and has been modified since it was last read. [ -S FILE ] Tests if FILE exists and is a socket. [ FILE1 -nt FILE2 ] Tests if FILE1 has been changed more recently than FILE2 , or if FILE1 exists and FILE2 does not. [ FILE1 -ot FILE2 ] Tests if FILE1 is older than FILE2 , or is FILE2 exists and FILE1 does not. [ FILE1 -ef FILE2 ] Tests if FILE1 and FILE2 refer to the same device and inode numbers. Usage of [\u202f-a\u202fFILE\u202f] $ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"${FILE} exists\" > else > echo \"${FILE} doesn't exist\" > fi The following example shows a common mistake. Here, the quotation marks surrounding the file path are missing. Since the path has spaces, Bash gives an error: $ if [ -a /Users/MyUser/Desktop/some file name with spaces.txt ] > then > echo \"The file exists\" > else > echo \"The file doesn't exist\" > fi -bash: [: too many argument Usage of [-d FILE] $ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -d \"${FILE}\" ] > then > echo \"It is a directory.\" > else > echo \"It is a regular file.\" > fi > else > echo \"The file doesn't exist.\" > fi The following example shows a common mistake. Here, the spaces before and after the expression -a \"${FILE}\" are missing. So, Bash will give an error: $ FILE=/Users/MyUser/Desktop/someFile.txt $ if [-a \"${FILE}\"] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -d \"${FILE}\" ] > then > echo \"It is a directory.\" > else > echo \"It is a regular file.\" > fi > else > echo \"The file doesn't exist.\" > fi -bash: [-a: command not found Usage of [\u202f-f\u202fFILE\u202f] $ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -f \"${FILE}\" ] > then > echo \"It is a regular file.\" > else > echo \"It is a directory.\" > fi > else > echo \"The file doesn't exist.\" > fi Usage of [\u202f-N\u202fFILE\u202f] $ if [ -N \"/Users/MyUser/Desktop/someFile.txt\" ] > then > echo \"The file exists and has been modified since the last time it was opened.\" > else > echo \"Either the file doesn't exist, or it hasn't been modified.\" > fi Condition-testing to compare/evaluate strings When comparing strings, it is mandatory to use the quotation marks. The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ -z\u202f\"STRING\" ] Tests if the length of\u202f STRING \u202fis zero. [ -n\u202f\"STRING\" ] Tests if the length of\u202f STRING \u202fis non-zero. [ \"STRING1\" == \"STRING2\" ] Tests if the strings are equal. [ \"STRING1\" != \"STRING2\" ] Tests if the strings are not equal. [ \"STRING1\" \\< \"STRING2\" ] Tests if STRING1 \u202fsorts before\u202f STRING2 . [ \"STRING1\" \\> \"STRING2\" ] Tests if STRING1 \u202fsorts after\u202f STRING2 . Usage of [ -z\u202f\"STRING\" ] $ if [ -z \"\" ] > then > echo \"Empty string\" > fi Empty string Usage of [ -n\u202f\"STRING\" ] $ VAR=\"Some text\" $ if [ -n \"${VAR}\" ] > then > echo \"The string is not empty\" > fi The string is not empty In this example, Bash will show an error because I forgot to put the quotation marks around ${VAR} : $ VAR=\"Some text\" $ if [ -n ${VAR} ] > then > echo \"The string is not empty\" > fi -bash: [: Some: binary operator expected Usage of [ \"STRING1\" == \"STRING2\" ] $ QC=\"Good\" $ if [ \"${QC}\" == \"Good\" ] > then > echo \"Quality control good\" > else > echo \"Image has bad quality\" > fi Quality control good Usage of [ \"STRING1\" != \"STRING2\" ] $ QC=\"Good\" $ if [ \"${QC}\" != \"Good\" ] > then > echo \"Quality control is not good\" > else > echo \"Image has good quality\" > fi Image has good quality Usage of [ \"STRING1\" \\< \"STRING2\" ] In the following example, I am comparing the strings Canada with Colombia and printing the one that sorts first. Canada will be printed because the first letter of both words is the same, but the second letter in Canada comes before the second letter in Colombia . $ VAR1=\"Canada\" $ VAR2=\"Colombia\" $ if [ \"${VAR1}\" \\< \"${VAR2}\" ] > then > echo ${VAR1} > else > echo ${VAR2} > fi Canada The previous expression can be written using a shorter syntax: [ expression ] >> what_to_do_if_expression_is_true || what_to_do_if_expression_is_false $ [ \"${VAR1}\" \\< \"${VAR2}\" ] >> echo ${VAR1} || echo ${VAR2} Canada Usage of [ \"STRING1\" \\> \"STRING2\" ] $ VAR1=\"Canada\" $ VAR2=\"Colombia\" $ if [ \"${VAR1}\" \\> \"${VAR2}\" ] > then > echo ${VAR2} > else > echo ${VAR1} > fi Canada The previous expression can also be written using the shorter syntax: $ [ \"${VAR1}\" \\> \"${VAR2}\" ] >> echo ${VAR2} || echo ${VAR1} Canada Condition-testing to compare numbers The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ NUM1 -eq NUM2 ] Tests if NUM1 is equal to NUM2 . [ NUM1 -ne NUM2 ] Tests if NUM1 is not equal to NUM2 . [ NUM1 -lt NUM2 ] Tests if NUM1 is less than NUM2 . [ NUM1 -le NUM2 ] Tests if NUM1 is less than or equal to NUM2 . [ NUM1 -gt NUM2 ] Tests if NUM1 is greater than NUM2 . [ NUM1 -ge NUM2 ] Tests if NUM1 is greater than or equal to NUM2 . Usage of [ NUM1 -eq NUM2 ] $ if [ 3 -eq 3 ] > then > echo \"This makes sense, 3 equals 3.\" > fi This makes sense, 3 equals 3. The previous expression can also be written using the shorter syntax: $ [ 3 -eq 3 ] >> echo \"This makes sense, 3 equals 3.\" This makes sense, 3 equals 3. $ A=3 $ if [ \"${A}\" -eq \"3\" ] > then > echo \"This makes sense, ${A} equals 3.\" > fi This makes sense, 3 equals 3. And using the shorter syntax it would be: $ [ \"${A}\" -eq \"3\" ] >> echo \"This makes sense, ${A} equals 3.\" This makes sense, 3 equals 3. Usage of [ NUM1 -ne NUM2 ] $ A=3 $ if [ \"${A}\" -ne \"3\" ] > then > echo \"Variable A is not equal to 3\" > else > echo \"Variable A equals 3.\" > fi Variable A equals 3. Using the shorter syntax: $ [ \"${A}\" -ne \"3\" ] >> echo \"Variable A is not equal to 3\" || echo \"Variable A equals 3.\" Variable A equals 3. Usage of [ NUM1 -lt NUM2 ] $ A=3 $ if [ \"${A}\" -lt \"3\" ] > then > echo \"Variable A is less than 3\" > else > echo \"Variable A not less than 3.\" > fi Variable A is not less than 3. Using the shorter syntax: $ [ \"${A}\" -lt \"3\" ] >> echo \"Variable A is less than 3\" || echo \"Variable A not less than 3.\" Variable A is not less than 3. Usage of [ NUM1 -le NUM2 ] $ A=3 $ if [ \"${A}\" -le \"3\" ] > then > echo \"Variable A is less or equal to 3\" > else > echo \"Variable A greater than 3.\" > fi Variable A is less or equal to 3. Using the shorter syntax: $ [ \"${A}\" -le \"3\" ] >> echo \"Variable A is less or equal to 3\" || echo \"Variable A greater than 3.\" Variable A is less or equal to 3. Usage of [ NUM1 -gt NUM2 ] $ A=3 $ if [ \"${A}\" -gt \"3\" ] > then > echo \"Variable A is greater than 3.\" > else > echo \"Variable A not greater than 3.\" > fi Variable A is not greater than 3. Using the shorter syntax: $ [ \"${A}\" -gt \"3\" ] >> echo \"Variable A is greater than 3.\" || echo \"Variable A not greater than 3.\" Variable A is not greater than 3. Usage of [ NUM1 -ge NUM2 ] $ A=3 $ if [ \"${A}\" -ge \"3\" ] > then > echo \"Variable A is greater or equal to 3\" > else > echo \"Variable A less than 3.\" > fi Variable A is greater or equal to 3. Using the shorter syntax: $ [ \"${A}\" -ge \"3\" ] >> echo \"Variable A is greater or equal to 3\" || echo \"Variable A less than 3.\" Variable A is greater or equal to 3. Condition-testing to compare arrays Condition Meaning [ \"${array1[*]}\" == \"${array2[*]}\" ] Tests if array1 equals to array2 . [ \"${array1[*]}\" != \"${array2[*]}\" ] Tests if array1 is different to array2 . Usage of [ \"${array1[*]}\" == \"${array2[*]}\" ] $ arr1=(a b c) $ arr2=(a b c d) $ arr3=(a b c) $ if [ \"${arr1[*]}\" == \"${arr3[*]}\" ] > then > echo \"equal\" > else > echo \"different\" > fi equal Using the shorter syntax: $ [ \"${arr1[*]}\" == \"${arr3[*]}\" ] >> echo \"equal\" || echo \"different\" equal $ if [ \"${arr1[*]}\" == \"${arr2[*]}\" ] > then > echo \"equal\" > else > echo \"different\" > fi different Using the shorter syntax: $ [ \"${arr1[*]}\" == \"${arr2[*]}\" ] >> echo \"equal\" || echo \"different\" different [ \"${arr1[*]}\" != \"${arr2[*]}\" ]: $ if [ \"${arr1[*]}\" != \"${arr2[*]}\" ] > then > echo \"different\" > else > echo \"equal\" > fi different Using a shorter syntax: $ [ \"${arr1[*]}\" != \"${arr2[*]}\" ] >> echo \"different\" || echo \"equal\" different Combining different expressions for condition-testing Condition Meaning [ EXPR ] Tests if the expression EXPR is true . [ ! EXPR ] Tests if the expression EXPR is false . [ EXPR1 ] || [ EXPR2 ] Tests if EXPR1 or EXPR2 are true . You can add as many expressions as desired. [ EXPR1 ] && [ EXPR2 ] Tests if EXPR1 and EXPR2 are true . You can add as many expressions as desired. Usage of [ EXPR ] vs [ ! EXPR ] $ if [ 3 -eq 3 ] > then > echo \"This will be printed if the expression 3 equals 3 is true.\" > else > echo \"This will be printed if the expression is false (3 is not equal to 3).\" > fi This will be printed if the expression 3 equals 3 is true. Using a shorter syntax: $ [ 3 -eq 3 ] >> echo \"This will be printed if the expression 3 equals 3 is true.\" || echo \"This will be printed if the expression is false (3 is not equal to 3).\" This will be printed if the expression 3 equals 3 is true. $ if [ ! 3 -eq 3 ] > then > echo \"This will be printed if it is false that 3 equals 3 (so, if 3 is different than 3).\" > else > echo \"This will be printed if it is not false (it's true) that 3 equals 3.\" > fi This will be printed if it is not false (it's true) that 3 equals 3. Using a shorter syntax: $ [ ! 3 -eq 3 ] >> echo \"This will be printed if it is false that 3 equals 3 (so, if 3 is different than 3).\" || echo \"This will be printed if it is not false (it's true) that 3 equals 3.\" This will be printed if it is not false (it's true) that 3 equals 3. We learned that the expression -f FILE tests if a file exists. If we want to test if a file doesn't exist, then we just need to test if -f FILE is false . $ FILE=\"SomeFileThatExists.txt\" $ if [ -f ${FILE} ] > then > echo \"The file exist\" > fi The file exist Using a shorter syntax: $ [ -f ${FILE} ] >> echo \"The file exist\" The file exist $ FILE=\"SomeFileThatDoesntExist.txt\" $ if [ ! -f ${FILE} ] > then > echo \"The file doesn't exist\" > fi The file doesn't exist Using a shorter syntax: $ [ ! -f ${FILE} ] >> echo \"The file doesn't exist\" The file doesn't exist Usage of [ EXPR1 ] || [ EXPR2 ] $ if [ 2 -lt 3 ] || [ 4 -lt 3 ] > then > echo \"This will be echoed if any of the two expressions are true: 2<3 OR 4<3.\" > else > echo \"This will be echoed if none of the two expressions are true\" > fi This will be echoed if any of the two expressions are true: 2<3 OR 4<3. Using a shorter syntax: $ ( [ 2 -lt 3 ] || [ 4 -lt 3 ] ) && echo \"This will be echoed if any of the two expressions are true: 2<3 OR 4<3.\" || echo \"This will be echoed if none of the two expressions are true\": This will be echoed if any of the two expressions are true: 2<3 OR 4<3. Usage of [ EXPR1 ] && [ EXPR2 ] The following example tests if the two expressions are true . The second expression, opposite to the previous example, has the negation ( ! ). So, the second expression is not testing if 4 is less than 3, it is testing if 4 is NOT less than 3 (if it's equal or greater than 3). So, both of the expressions are true , because 4 is not less than 3, and 2 is less than 3. $ if [ 2 -lt 3 ] && [ ! 4 -lt 3 ] > then > echo \"This will be echoed if the two expressions are true.\" > else > echo \"This will be echoed if one of the two expressions are false, or if both are false.\" > fi This will be echoed if the two expressions are true. Using a shorter syntax: $ ( [ 2 -lt 3 ] && [ ! 4 -lt 3 ] ) && echo \"This will be echoed if the two expressions are true.\" || echo \"This will be echoed if one of the two expressions are false, or if both are false.\" This will be echoed if the two expressions are true. Using the and ( && ) and or ( || ) operands to test more than two conditions You can combine more than two expressions. In the following example, I am combining three. Because I am using the AND operator, the whole condition will test true if and only if all the three expressions are true . If one is false , then the whole expression will be false . $ if [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] > then > echo \"This will be echoed if all the three expressions are true.\" > else > echo \"This will be echoed if any of the three expressions is false.\" > fi This will be echoed if any of the three expressions is false. Let's take a look at why the whole expression evaluates false : [ 2 -lt 3 ] : This is true , 2 < 3. [ ! 4 -lt 3 ] : This is true , 4 is not less than 3. [ 4 -lt 3 ] : This is false , It is false that 4 be less than 3. [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] : This is false because one of the three expressions is false . Using a shorter syntax: $ ( [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] ) && echo \"This will be echoed if all the three expressions are true.\" || echo \"This will be echoed if any of the three expressions is false.\" The following example is very similar to the previous one, but instead of using the operator AND ( && ), we are using the operator OR ( || ). So, the whole expression will be true if ANY of the three expressions is true . Since the first two expressions are true , then the result is true . $ if [ 2 -lt 3 ] || [ ! 4 -lt 3 ] || [ 4 -lt 3 ] > then > echo \"This will be echoed if ANY of the three expressions is true.\" > else > echo \"This will be echoed if all of the three expressions are false.\" > fi This will be echoed if ANY of the three expressions is true. Using a shorter syntax: $ ( [ 2 -lt 3 ] || [ ! 4 -lt 3 ] || [ 4 -lt 3 ] ) && echo \"This will be echoed if ANY of the three expressions is true.\" || echo \"This will be echoed if all of the three expressions are false.\" This will be echoed if ANY of the three expressions is true. Combining && and || into one expression When combining both operands ( && , || ), it is better to always use parenthesis to indicate the order in which you want the operations to be evaluated. In the following example we have three files. The path of the three files are saved in the variables ${FILE1} ${FILE2} and ${FILE3} . Files ${FILE1} and ${FILE3} exist, but ${FILE2} doesn't exist. We want to evaluate the following condition: Does ${FILE3} and at least one of the other two files exists? [ -f ${FILE3} ] : This condition is true because ${FILE3} exists. [ -f ${FILE2} ] || [ -f ${FILE1} ] : This condition is true because even though ${FILE2} doesn't exist, ${FILE1} does exist. And with an OR ( || ) we only need one of the expressions to be true . ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] : This is true because both of expressions are true . $ if ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] > then > echo \"The condition is true\" > else > echo \"The condition is false\" > fi The condition is true Using a shorter syntax: ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] && echo \"The condition is true\" || echo \"The condition is false\" In the following example, we want to include a subject if it is female and age less than six or male and age greater than ten: $ GENDER=\"MALE\" $ AGE=23 $ if ( [ \"${GENDER}\" == \"FEMALE\" ] && [ \"${AGE}\" -lt \"6\" ] ) || ( [ \"${GENDER}\" == \"MALE\" ] && [ \"${AGE}\" -gt \"10\" ] ) > then > echo \"Include subject\" > else > echo \"Exclude subject\" > fi Include subject","title":"Condition testing"},{"location":"condition_test/#condition-testing","text":"Variables can be used to test if a certain condition is true or false , and therefore be able to take a different course of action depending on the result of the test. For example, you might want to evaluate if a file exists to decide if you can copy it into a different folder or not. For condition-testing you will use the if command. This command has the following syntax: if [ CONDITION TO EVALUATE ] then INSTRUCTIONS THAT WILL RUN IF THE CONDITION IS TRUE elif [ OTHER CONDITION TO EVALUATE IF 1ST CONDITION IS FALSE ] then INSTRUCTIONS THAT WILL RUN IF FIRST CONDITION IS FALSE BUT SECOND IS TRUE else INSTRUCTIONS THAT WILL RUN IF ALL THE PREVIOUS CONDITIONS ARE FALSE fi The CONDITION TO EVALUATE is an expression that follows a specific syntax depending on what you want to test (checking files, string comparison, comparing numbers, or combining different expressions). Lets look at the different syntaxes used in each of these situations and at some examples that will help you understand this seemingly confusing subject.","title":"Condition-testing"},{"location":"condition_test/#condition-testing-to-check-files","text":"In the following table, FILE refers to the path of the file, or to the variable that contains the path of the file. The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ -a FILE ] Tests if FILE exists. [ -d FILE ] Tests if FILE exists and is a directory. [ -e FILE ] Tests if FILE exists. [ -f FILE ] Tests if FILE exists and is a regular file. [ -g FILE ] Tests if FILE exists and its SGID bit is set. [ -h FILE ] Tests if FILE exists and is a symbolic link. [ -k FILE ] Tests if FILE exists and its sticky bit is set. [ -p FILE ] Tests if FILE exists and is a named pipe ( FIFO ). [ -r FILE ] Tests if FILE exists and is readable. [ -s FILE ] Tests if FILE exists and has a size greater than zero. [ -t FD ] Tests if file descriptor FD is open and refers to a terminal. [ -u FILE ] Tests if FILE exists and its SUID (set user ID) bit is set. [ -w FILE ] Tests if FILE exists and is writable. [ -x FILE ] Tests if FILE exists and is executable. [ -O FILE ] Tests if FILE exists and is owned by the effective user ID. [ -G FILE ] Tests if FILE exists and is owned by the effective group ID. [ -L FILE ] Tests if FILE exists and is a symbolic link. [ -N FILE ] Tests if FILE exists and has been modified since it was last read. [ -S FILE ] Tests if FILE exists and is a socket. [ FILE1 -nt FILE2 ] Tests if FILE1 has been changed more recently than FILE2 , or if FILE1 exists and FILE2 does not. [ FILE1 -ot FILE2 ] Tests if FILE1 is older than FILE2 , or is FILE2 exists and FILE1 does not. [ FILE1 -ef FILE2 ] Tests if FILE1 and FILE2 refer to the same device and inode numbers.","title":"Condition-testing to check files"},{"location":"condition_test/#usage-of-a-file","text":"$ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"${FILE} exists\" > else > echo \"${FILE} doesn't exist\" > fi The following example shows a common mistake. Here, the quotation marks surrounding the file path are missing. Since the path has spaces, Bash gives an error: $ if [ -a /Users/MyUser/Desktop/some file name with spaces.txt ] > then > echo \"The file exists\" > else > echo \"The file doesn't exist\" > fi -bash: [: too many argument","title":"Usage of [ -a FILE ]"},{"location":"condition_test/#usage-of-d-file","text":"$ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -d \"${FILE}\" ] > then > echo \"It is a directory.\" > else > echo \"It is a regular file.\" > fi > else > echo \"The file doesn't exist.\" > fi The following example shows a common mistake. Here, the spaces before and after the expression -a \"${FILE}\" are missing. So, Bash will give an error: $ FILE=/Users/MyUser/Desktop/someFile.txt $ if [-a \"${FILE}\"] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -d \"${FILE}\" ] > then > echo \"It is a directory.\" > else > echo \"It is a regular file.\" > fi > else > echo \"The file doesn't exist.\" > fi -bash: [-a: command not found","title":"Usage of [-d FILE]"},{"location":"condition_test/#usage-of-f-file","text":"$ FILE=/Users/MyUser/Desktop/someFile.txt $ if [ -a \"${FILE}\" ] > then > echo \"The file exists. Now I will find out if it's a directory or a regular file.\" > if [ -f \"${FILE}\" ] > then > echo \"It is a regular file.\" > else > echo \"It is a directory.\" > fi > else > echo \"The file doesn't exist.\" > fi","title":"Usage of [ -f FILE ]"},{"location":"condition_test/#usage-of-n-file","text":"$ if [ -N \"/Users/MyUser/Desktop/someFile.txt\" ] > then > echo \"The file exists and has been modified since the last time it was opened.\" > else > echo \"Either the file doesn't exist, or it hasn't been modified.\" > fi","title":"Usage of [ -N FILE ]"},{"location":"condition_test/#condition-testing-to-compareevaluate-strings","text":"When comparing strings, it is mandatory to use the quotation marks. The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ -z\u202f\"STRING\" ] Tests if the length of\u202f STRING \u202fis zero. [ -n\u202f\"STRING\" ] Tests if the length of\u202f STRING \u202fis non-zero. [ \"STRING1\" == \"STRING2\" ] Tests if the strings are equal. [ \"STRING1\" != \"STRING2\" ] Tests if the strings are not equal. [ \"STRING1\" \\< \"STRING2\" ] Tests if STRING1 \u202fsorts before\u202f STRING2 . [ \"STRING1\" \\> \"STRING2\" ] Tests if STRING1 \u202fsorts after\u202f STRING2 .","title":"Condition-testing to compare/evaluate strings"},{"location":"condition_test/#usage-of-z-string","text":"$ if [ -z \"\" ] > then > echo \"Empty string\" > fi Empty string","title":"Usage of [ -z \"STRING\" ]"},{"location":"condition_test/#usage-of-n-string","text":"$ VAR=\"Some text\" $ if [ -n \"${VAR}\" ] > then > echo \"The string is not empty\" > fi The string is not empty In this example, Bash will show an error because I forgot to put the quotation marks around ${VAR} : $ VAR=\"Some text\" $ if [ -n ${VAR} ] > then > echo \"The string is not empty\" > fi -bash: [: Some: binary operator expected","title":"Usage of [ -n \"STRING\" ]"},{"location":"condition_test/#usage-of-string1-string2","text":"$ QC=\"Good\" $ if [ \"${QC}\" == \"Good\" ] > then > echo \"Quality control good\" > else > echo \"Image has bad quality\" > fi Quality control good","title":"Usage of [ \"STRING1\" == \"STRING2\" ]"},{"location":"condition_test/#usage-of-string1-string2_1","text":"$ QC=\"Good\" $ if [ \"${QC}\" != \"Good\" ] > then > echo \"Quality control is not good\" > else > echo \"Image has good quality\" > fi Image has good quality","title":"Usage of [ \"STRING1\" != \"STRING2\" ]"},{"location":"condition_test/#usage-of-string1-string2_2","text":"In the following example, I am comparing the strings Canada with Colombia and printing the one that sorts first. Canada will be printed because the first letter of both words is the same, but the second letter in Canada comes before the second letter in Colombia . $ VAR1=\"Canada\" $ VAR2=\"Colombia\" $ if [ \"${VAR1}\" \\< \"${VAR2}\" ] > then > echo ${VAR1} > else > echo ${VAR2} > fi Canada The previous expression can be written using a shorter syntax: [ expression ] >> what_to_do_if_expression_is_true || what_to_do_if_expression_is_false $ [ \"${VAR1}\" \\< \"${VAR2}\" ] >> echo ${VAR1} || echo ${VAR2} Canada","title":"Usage of [ \"STRING1\" \\&lt; \"STRING2\" ]"},{"location":"condition_test/#usage-of-string1-string2_3","text":"$ VAR1=\"Canada\" $ VAR2=\"Colombia\" $ if [ \"${VAR1}\" \\> \"${VAR2}\" ] > then > echo ${VAR2} > else > echo ${VAR1} > fi Canada The previous expression can also be written using the shorter syntax: $ [ \"${VAR1}\" \\> \"${VAR2}\" ] >> echo ${VAR2} || echo ${VAR1} Canada","title":"Usage of [ \"STRING1\" \\&gt; \"STRING2\" ]"},{"location":"condition_test/#condition-testing-to-compare-numbers","text":"The spaces after [ and before ] are very important. If those spaces are missing, Bash will give an error. Condition Meaning [ NUM1 -eq NUM2 ] Tests if NUM1 is equal to NUM2 . [ NUM1 -ne NUM2 ] Tests if NUM1 is not equal to NUM2 . [ NUM1 -lt NUM2 ] Tests if NUM1 is less than NUM2 . [ NUM1 -le NUM2 ] Tests if NUM1 is less than or equal to NUM2 . [ NUM1 -gt NUM2 ] Tests if NUM1 is greater than NUM2 . [ NUM1 -ge NUM2 ] Tests if NUM1 is greater than or equal to NUM2 .","title":"Condition-testing to compare numbers"},{"location":"condition_test/#usage-of-num1-eq-num2","text":"$ if [ 3 -eq 3 ] > then > echo \"This makes sense, 3 equals 3.\" > fi This makes sense, 3 equals 3. The previous expression can also be written using the shorter syntax: $ [ 3 -eq 3 ] >> echo \"This makes sense, 3 equals 3.\" This makes sense, 3 equals 3. $ A=3 $ if [ \"${A}\" -eq \"3\" ] > then > echo \"This makes sense, ${A} equals 3.\" > fi This makes sense, 3 equals 3. And using the shorter syntax it would be: $ [ \"${A}\" -eq \"3\" ] >> echo \"This makes sense, ${A} equals 3.\" This makes sense, 3 equals 3.","title":"Usage of [ NUM1 -eq NUM2 ]"},{"location":"condition_test/#usage-of-num1-ne-num2","text":"$ A=3 $ if [ \"${A}\" -ne \"3\" ] > then > echo \"Variable A is not equal to 3\" > else > echo \"Variable A equals 3.\" > fi Variable A equals 3. Using the shorter syntax: $ [ \"${A}\" -ne \"3\" ] >> echo \"Variable A is not equal to 3\" || echo \"Variable A equals 3.\" Variable A equals 3.","title":"Usage of [ NUM1 -ne NUM2 ]"},{"location":"condition_test/#usage-of-num1-lt-num2","text":"$ A=3 $ if [ \"${A}\" -lt \"3\" ] > then > echo \"Variable A is less than 3\" > else > echo \"Variable A not less than 3.\" > fi Variable A is not less than 3. Using the shorter syntax: $ [ \"${A}\" -lt \"3\" ] >> echo \"Variable A is less than 3\" || echo \"Variable A not less than 3.\" Variable A is not less than 3.","title":"Usage of [ NUM1 -lt NUM2 ]"},{"location":"condition_test/#usage-of-num1-le-num2","text":"$ A=3 $ if [ \"${A}\" -le \"3\" ] > then > echo \"Variable A is less or equal to 3\" > else > echo \"Variable A greater than 3.\" > fi Variable A is less or equal to 3. Using the shorter syntax: $ [ \"${A}\" -le \"3\" ] >> echo \"Variable A is less or equal to 3\" || echo \"Variable A greater than 3.\" Variable A is less or equal to 3.","title":"Usage of [ NUM1 -le NUM2 ]"},{"location":"condition_test/#usage-of-num1-gt-num2","text":"$ A=3 $ if [ \"${A}\" -gt \"3\" ] > then > echo \"Variable A is greater than 3.\" > else > echo \"Variable A not greater than 3.\" > fi Variable A is not greater than 3. Using the shorter syntax: $ [ \"${A}\" -gt \"3\" ] >> echo \"Variable A is greater than 3.\" || echo \"Variable A not greater than 3.\" Variable A is not greater than 3.","title":"Usage of [ NUM1 -gt NUM2 ]"},{"location":"condition_test/#usage-of-num1-ge-num2","text":"$ A=3 $ if [ \"${A}\" -ge \"3\" ] > then > echo \"Variable A is greater or equal to 3\" > else > echo \"Variable A less than 3.\" > fi Variable A is greater or equal to 3. Using the shorter syntax: $ [ \"${A}\" -ge \"3\" ] >> echo \"Variable A is greater or equal to 3\" || echo \"Variable A less than 3.\" Variable A is greater or equal to 3.","title":"Usage of [ NUM1 -ge NUM2 ]"},{"location":"condition_test/#condition-testing-to-compare-arrays","text":"Condition Meaning [ \"${array1[*]}\" == \"${array2[*]}\" ] Tests if array1 equals to array2 . [ \"${array1[*]}\" != \"${array2[*]}\" ] Tests if array1 is different to array2 .","title":"Condition-testing to compare arrays"},{"location":"condition_test/#usage-of-array1-array2","text":"$ arr1=(a b c) $ arr2=(a b c d) $ arr3=(a b c) $ if [ \"${arr1[*]}\" == \"${arr3[*]}\" ] > then > echo \"equal\" > else > echo \"different\" > fi equal Using the shorter syntax: $ [ \"${arr1[*]}\" == \"${arr3[*]}\" ] >> echo \"equal\" || echo \"different\" equal $ if [ \"${arr1[*]}\" == \"${arr2[*]}\" ] > then > echo \"equal\" > else > echo \"different\" > fi different Using the shorter syntax: $ [ \"${arr1[*]}\" == \"${arr2[*]}\" ] >> echo \"equal\" || echo \"different\" different [ \"${arr1[*]}\" != \"${arr2[*]}\" ]: $ if [ \"${arr1[*]}\" != \"${arr2[*]}\" ] > then > echo \"different\" > else > echo \"equal\" > fi different Using a shorter syntax: $ [ \"${arr1[*]}\" != \"${arr2[*]}\" ] >> echo \"different\" || echo \"equal\" different","title":"Usage of [ \"${array1[*]}\" == \"${array2[*]}\" ]"},{"location":"condition_test/#combining-different-expressions-for-condition-testing","text":"Condition Meaning [ EXPR ] Tests if the expression EXPR is true . [ ! EXPR ] Tests if the expression EXPR is false . [ EXPR1 ] || [ EXPR2 ] Tests if EXPR1 or EXPR2 are true . You can add as many expressions as desired. [ EXPR1 ] && [ EXPR2 ] Tests if EXPR1 and EXPR2 are true . You can add as many expressions as desired.","title":"Combining different expressions for condition-testing"},{"location":"condition_test/#usage-of-expr-vs-expr","text":"$ if [ 3 -eq 3 ] > then > echo \"This will be printed if the expression 3 equals 3 is true.\" > else > echo \"This will be printed if the expression is false (3 is not equal to 3).\" > fi This will be printed if the expression 3 equals 3 is true. Using a shorter syntax: $ [ 3 -eq 3 ] >> echo \"This will be printed if the expression 3 equals 3 is true.\" || echo \"This will be printed if the expression is false (3 is not equal to 3).\" This will be printed if the expression 3 equals 3 is true. $ if [ ! 3 -eq 3 ] > then > echo \"This will be printed if it is false that 3 equals 3 (so, if 3 is different than 3).\" > else > echo \"This will be printed if it is not false (it's true) that 3 equals 3.\" > fi This will be printed if it is not false (it's true) that 3 equals 3. Using a shorter syntax: $ [ ! 3 -eq 3 ] >> echo \"This will be printed if it is false that 3 equals 3 (so, if 3 is different than 3).\" || echo \"This will be printed if it is not false (it's true) that 3 equals 3.\" This will be printed if it is not false (it's true) that 3 equals 3. We learned that the expression -f FILE tests if a file exists. If we want to test if a file doesn't exist, then we just need to test if -f FILE is false . $ FILE=\"SomeFileThatExists.txt\" $ if [ -f ${FILE} ] > then > echo \"The file exist\" > fi The file exist Using a shorter syntax: $ [ -f ${FILE} ] >> echo \"The file exist\" The file exist $ FILE=\"SomeFileThatDoesntExist.txt\" $ if [ ! -f ${FILE} ] > then > echo \"The file doesn't exist\" > fi The file doesn't exist Using a shorter syntax: $ [ ! -f ${FILE} ] >> echo \"The file doesn't exist\" The file doesn't exist","title":"Usage of [ EXPR ] vs [ ! EXPR ]"},{"location":"condition_test/#usage-of-expr1-expr2","text":"$ if [ 2 -lt 3 ] || [ 4 -lt 3 ] > then > echo \"This will be echoed if any of the two expressions are true: 2<3 OR 4<3.\" > else > echo \"This will be echoed if none of the two expressions are true\" > fi This will be echoed if any of the two expressions are true: 2<3 OR 4<3. Using a shorter syntax: $ ( [ 2 -lt 3 ] || [ 4 -lt 3 ] ) && echo \"This will be echoed if any of the two expressions are true: 2<3 OR 4<3.\" || echo \"This will be echoed if none of the two expressions are true\": This will be echoed if any of the two expressions are true: 2<3 OR 4<3.","title":"Usage of [ EXPR1 ] || [ EXPR2 ]"},{"location":"condition_test/#usage-of-expr1-expr2_1","text":"The following example tests if the two expressions are true . The second expression, opposite to the previous example, has the negation ( ! ). So, the second expression is not testing if 4 is less than 3, it is testing if 4 is NOT less than 3 (if it's equal or greater than 3). So, both of the expressions are true , because 4 is not less than 3, and 2 is less than 3. $ if [ 2 -lt 3 ] && [ ! 4 -lt 3 ] > then > echo \"This will be echoed if the two expressions are true.\" > else > echo \"This will be echoed if one of the two expressions are false, or if both are false.\" > fi This will be echoed if the two expressions are true. Using a shorter syntax: $ ( [ 2 -lt 3 ] && [ ! 4 -lt 3 ] ) && echo \"This will be echoed if the two expressions are true.\" || echo \"This will be echoed if one of the two expressions are false, or if both are false.\" This will be echoed if the two expressions are true.","title":"Usage of [ EXPR1 ] &amp;&amp; [ EXPR2 ]"},{"location":"condition_test/#using-the-and-and-or-operands-to-test-more-than-two-conditions","text":"You can combine more than two expressions. In the following example, I am combining three. Because I am using the AND operator, the whole condition will test true if and only if all the three expressions are true . If one is false , then the whole expression will be false . $ if [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] > then > echo \"This will be echoed if all the three expressions are true.\" > else > echo \"This will be echoed if any of the three expressions is false.\" > fi This will be echoed if any of the three expressions is false. Let's take a look at why the whole expression evaluates false : [ 2 -lt 3 ] : This is true , 2 < 3. [ ! 4 -lt 3 ] : This is true , 4 is not less than 3. [ 4 -lt 3 ] : This is false , It is false that 4 be less than 3. [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] : This is false because one of the three expressions is false . Using a shorter syntax: $ ( [ 2 -lt 3 ] && [ ! 4 -lt 3 ] && [ 4 -lt 3 ] ) && echo \"This will be echoed if all the three expressions are true.\" || echo \"This will be echoed if any of the three expressions is false.\" The following example is very similar to the previous one, but instead of using the operator AND ( && ), we are using the operator OR ( || ). So, the whole expression will be true if ANY of the three expressions is true . Since the first two expressions are true , then the result is true . $ if [ 2 -lt 3 ] || [ ! 4 -lt 3 ] || [ 4 -lt 3 ] > then > echo \"This will be echoed if ANY of the three expressions is true.\" > else > echo \"This will be echoed if all of the three expressions are false.\" > fi This will be echoed if ANY of the three expressions is true. Using a shorter syntax: $ ( [ 2 -lt 3 ] || [ ! 4 -lt 3 ] || [ 4 -lt 3 ] ) && echo \"This will be echoed if ANY of the three expressions is true.\" || echo \"This will be echoed if all of the three expressions are false.\" This will be echoed if ANY of the three expressions is true.","title":"Using the and (&amp;&amp;) and or (||) operands to test more than two conditions"},{"location":"condition_test/#combining-and-into-one-expression","text":"When combining both operands ( && , || ), it is better to always use parenthesis to indicate the order in which you want the operations to be evaluated. In the following example we have three files. The path of the three files are saved in the variables ${FILE1} ${FILE2} and ${FILE3} . Files ${FILE1} and ${FILE3} exist, but ${FILE2} doesn't exist. We want to evaluate the following condition: Does ${FILE3} and at least one of the other two files exists? [ -f ${FILE3} ] : This condition is true because ${FILE3} exists. [ -f ${FILE2} ] || [ -f ${FILE1} ] : This condition is true because even though ${FILE2} doesn't exist, ${FILE1} does exist. And with an OR ( || ) we only need one of the expressions to be true . ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] : This is true because both of expressions are true . $ if ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] > then > echo \"The condition is true\" > else > echo \"The condition is false\" > fi The condition is true Using a shorter syntax: ( [ -f ${FILE1} ] || [ -f ${FILE2} ] ) && [ -f ${FILE3} ] && echo \"The condition is true\" || echo \"The condition is false\" In the following example, we want to include a subject if it is female and age less than six or male and age greater than ten: $ GENDER=\"MALE\" $ AGE=23 $ if ( [ \"${GENDER}\" == \"FEMALE\" ] && [ \"${AGE}\" -lt \"6\" ] ) || ( [ \"${GENDER}\" == \"MALE\" ] && [ \"${AGE}\" -gt \"10\" ] ) > then > echo \"Include subject\" > else > echo \"Exclude subject\" > fi Include subject","title":"Combining &amp;&amp; and || into one expression"},{"location":"downloads/","text":"Downloading files from the web","title":"Downloading files"},{"location":"downloads/#downloading-files-from-the-web","text":"","title":"Downloading files from the web"},{"location":"files/","text":"General file manipulation Absolute paths The absolute or full path of a file specifies its unique location in the file system, its name and extension. The absolute path of every file is different and constant. It will always be the same regardless of the current directory in which you are working (unless you move the file). This path follows a hierarchy of directories where the file is located, separating each directory with the delimiting character, which is the slash for Macintosh and Linux and the backslash for Windows. For example, a text file named file.txt located in the Desktop of a Mac computer, will commonly have an absolute path similar to this: /Users/user_name/Desktop/file.txt . To find the absolute path of a file you can drag and drop it into the Terminal. For example, if this is the absolute path of a file: /Users/user_name/Desktop/SomeFolder/Subfolder/file.txt . It means that in the Desktop there is a folder called SomeFolder , inside SomeFolder there is another folder called Subfolder , and inside Subfolder is located the corresponding file, with name file and extension txt . There cannot be two files with the same name and extension inside a folder. Relative paths The relative path of a file starts from the current working directory and represents the location of a specific file relative to this directory. It is always changing as it depends on what directory you are located in the terminal. If the absolute path of a file is /Users/user_name/Desktop/file.txt and the user current working directory is the Desktop, then the relative path of the file is: file.txt or ./file.txt . ./ represents the current directory. The following relative paths represent files that are located in the current working directory: File1.txt File2.nii.gz ./File3.nii ./File4.docx The absolute path of these files will be something similar to this (for Mac users), if the current directory is the Desktop: /Users/username/Desktop/File1.txt /Users/username/Desktop/File2.nii.gz /Users/username/Desktop/File3.nii /Users/username/Desktop/File4.docx The same way that one dot represents the current directory in a relative path, two dots represent the parent directory. So, if the absolute path of my current working directory is /Users/user_name/Desktop/SomeFolder , I can refer to files located in the parent directory (Desktop) using the double dots. So, all these files are located in the Desktop (the same as SomeFolder ): ../FileA.txt ../FileB.txt ../FileC.txt Tips Absolute and relative paths are used to reference files when doing operations with them, but is better to use the absolute paths when writing scripts. That way the script will not run into issues independently of the working directory. Otherwise, you might get file not found errors. Do not use spaces or any other special characters when naming a file. It makes it harder to write the path of that file. For example, if I have a file named Some File.txt in my Desktop (on a Mac), /Users/user_name/Desktop/Some File.txt is not the absolute path. Instead, the absolute path will be /Users/user_name/Desktop/Some\\ File.txt . Paths cannot have spaces unless you use scape characters, in this case the backslash. Another example is using the dollar sign (which is a special character) inside a file name. For example, if in the Desktop there is a folder named untitled$folder , /Users/user_name/Desktop/untitled$folder is not the absolute path. Instead, the absolute path will be /Users/user_name/Desktop/untitled\\$folder . The backslash is indicating us to treat the special character ( $ ) as part of the file name and not as the beginning of a variable name (which is the normal use of $ in Bash). If we don't use the backslash before the dollar sign, Bash will try to find a variable called folder. If that variable doesn't exist, then Bash will read /Users/user_name/Desktop/untitled$folder as /Users/user_name/Desktop/untitled , replacing $folder for an empty space. If that variable exists, Bash will replace $folder by the value of the variable. In the following sections you will learn how absolute and relative paths are used to manipulate files in MacOS and Linux . Listing files The ls command Lists the files and folders inside the specified directory. If no directory is specified after ls , then it prints the contents of the current folder. If no flag is used, it lists the files in bare format (without any details such as modified date and time or permissions). Depending which flag is used (or a combination of flags), then specific information about the file will be displayed. The following table is taken from manual of the ls command as displayed in the command line. List of flags that I use more often: Flag Use -a Include directory entries whose names begin with a dot. Typically, these are configuration files for applications or hidden files. -G Enable colorized output. This option is equivalent to defining CLICOLOR in the environment. -H Symbolic links on the command line are followed. This option is assumed if none of the -F or -l options are specified. -l Force output to be one entry per line. This is the default when output is not to a terminal. -lh Use unit suffixes when displaying the information in long output: Byte, Kilobyte, Megabyte, Gigabyte, Terabyte and Petabyte, in order to reduce the number of digits to three or less using base 2 for sizes. -ln Display user and group IDs numerically, rather than converting to a user or group name in a long output. -R Recursively list subdirectories encountered. -S Sort files by size. -t Sort files by time modified (most recently modified first) before sorting by lexicographical order. Other flags: Flag Use -A List all entries except for ( . ) and ( .. ). Always set for the super-user. -B Force printing of non-printable characters in file names. -b As -B , but use C escape codes whenever possible. -C Force multi-column output; this is the default when output is to a terminal. -c Directories are listed as plain files (not searched recursively). -F Display a slash immediately after each pathname that is a directory, an asterisk after each that is executable, a @ after each symbolic link, an equal sign after each socket, a percent sign after each whiteout, and a vertical bar after each that is a FIFO. -f Output is not sorted. This option turns on the -a option. -i For each file, print the serial number. -k If the -s option is specified, print the file size allocation in kilobytes, not blocks. -L Follow all symbolic links to final target and list the file or directory the link references rather than the link itself. This option cancels the -P option. -l@ Display extended attribute keys and sizes in long output. -le Print the Access Control List (ACL) associated with the file, if present, in long output. -lg This option is only available for compatibility with POSIX; it is used to display the group name in the long format output (the owner name is suppressed). -lO Include the file flags in a long output. -lT Display complete time information for the file, including month, day, hour, minute, second, and year. -m Stream output format; list files across the page, separated by commas. -o List in long format, but omit the group id. -P If argument is a symbolic link, list the link itself rather than the object the link references. This option cancels the -H and -L options. -p Write a slash after each filename if that file is a directory. -q Force printing of non-graphic characters in file names as the interrogation character; this is the default when output is to a terminal. -r Reverse the order of the sort to reverse lexicographical order, or the oldest entries first (or largest files last, if combined with sort by size). -s Display the number of file system blocks actually used by each file, in units of 512 bytes, where partial units are rounded up to the next integer value. If the output is to a terminal, a total sum for all the file sizes is output on a line before the listing. The environment variable BLOCKSIZE overrides the unit size of 512 bytes. -u Use time of last access, instead of last modification of the file for sorting ( -t ) or long printing ( -l ) -U Use time of file creation, instead of last modification for sorting ( -t ) or long output ( -l ). -v Force unedited printing of non-graphic characters; this is the default when output is not to a terminal. -W Display whiteouts when scanning directories. -w Force raw printing of non-printable characters. This is the default when output is not to a terminal. -x The same as -C , except that the multi-column output is produced with entries sorted across, rather than down the columns. The following examples show the usage of the flags presented in the previous table and details of the results that can be obtained when using the command ls together with those flags. ls command with no flags: Show the list of the files in the working directory: $ ls Applicationshome Libraryinstaller.failurerequests Networknet Subjectsopt Usersprivate Volumessbin binmp coresusr devvar etc Show the list of files in a different directory using the absolute path of that directory: $ ls /Volumes/MyExternalDrive ArticlesMRIdata SharedFolder Show the list of files in a subfolder ( Applications ) using the relative path : $ ls Applications/ Calculator.app Calendar.app Chess.app Dashboard.app Dictionary.app EndNote X7 EndNote X8 FaceTime.app Firefox.app IBM Image Capture.app Launchpad.app MATLAB_R2014b.app ls -l : When using the flag -l , Bash will not only show the list of files but also a description for each file. The output will be organized in columns, each one with a specific meaning that I will explain in the table below. $ ls -l /Volumes/MyExternalDrive Total 0 drwxr-xr-x 22 myUser UserGroup 714 Sep 4 11:40 Articles -rw-r--r--@ 1 myUse UserGroup 51620 Jan 14 2017 CV.docx -rw-r--r-- 1 myUser UserGroup 137195 Jan 14 2017 CV.pdf drwxr-xr-x 28 myUser UserGroup 952 Sep 10 09:04 MRIdata drwxrwxrwx 5 myUser UserGroup 170 Sep 4 11:15 SharedFolder Column number Column name Meaning 1 File type + permissions See below for the explanation of the output presented in this column. 2 Link count Number of hard links to the file. Data is only removed from your drive when all hard links to the data have been removed. 3 Owner name See below for the explanation of file ownership and permissions. 4 Group name See below for the explanation of file ownership and permissions. 5 File size Number of bytes in the file. See the flag -lh to output the size of the file in human-readable format. 6 Last modified date Abbreviated month and day-of-month when the file was last modified. 7 Last modified time Abbreviated hour and minute when the file was last modified in military format (24 hours). If the file was last modified more than six months before, then the year of the last modification is displayed instead of the hour and minute. 8 File name Name of the file with its extension. File type and permissions from the ls -l command: The first column of the output printed when using the flag -l shows the file type and permissions. This column has 10 characters. Each character will be a letter or a dash. The first character describes the type of file and can be one of the following: Character File type b Block special file: provide access to hardware devices. c Character special file: provide access to hardware devices. d Directory. l Symbolic link: a file that points to another file (a shortcut). It does not contain the data in the target file; it simply contains a pointer somewhere in the file system. s Socket link: file used for communication between processes. p FIFO: special file that can be opened by various processes for exchanging data. - Regular file. The second character shows if the user listed as owner has reading permissions. It will be an r if the owner can read the file, or a - if not. The third character shows if the user listed as owner has writing permissions. It will be a w if the owner can write in the file, or a - if not. The fourth character shows if the user listed as owner has execution permissions. It will have value x if the owner can execute the file, or a - if not. The fifth character shows if the users that are part of the group have reading permissions. It will have an r if they can read, or a - if not. The sixth character shows if the users that are part of the group have writing permissions. It will have a w if they can write, or a - if not. The seventh character shows if the users that are part of the group have execution permissions. It will have a x if they can execute, or a - if not. The eight character shows if other users have reading permissions. It will have an r if they can read, or a - if not. The ninth character shows if other users have writing permissions. It will have an w if they can write, or a - if not. The tenth character shows if other users have execution permissions. It will have a x if they can execute, or a - if not. To change the permissions of a file you would use the chmod command. This command has the following syntax: chmod <num_for_owner><num_for_group><num_for_others> <file> <num_for_owner> is a number to change the owner permissions. <num_for_group> is a number to change the group permissions. <num_for_others> is a number to change the permissions of other users. These numbers can be one of the following: Number Characters in ls -l Meaning 7 rwx Give full permissions (read, write and execute). 6 rw- Give read and write permissions, but not execute. 5 r-x Give read and execute permissions, but not write. 4 r-- Give only read permissions. 3 -wx Give write and execute permissions, but not read. 2 -w- Give only write permissions. 1 --x Give only execute permissions. 0 --- Give no permissions. For example if you run chmod 775 myfile , the owner and group will have full permissions, other users will be able to read and execute but not write. If you run chmod 744 myfile , the owner will have full permissions, users belonging to the group and other users will only be able to read, but they wont be able to write or execute the file. Human readable file size with ls -lh : The information displayed in the 5th column (file size) when using ls -l is difficult to interpret by a human. In order to see this information in a human-readable format, it is only necessary to add an h to the -l flag. $ ls -lh /Volumes/MyExternalDrive Total 0 drwxr-xr-x 22 myUser UserGroup 714B Sep 4 11:40 Articles -rw-r--r--@ 1 myUser UserGroup 50K Jan 14 2017 CV.docx -rw-r--r-- 1 myUser UserGroup 134K Jan 14 2017 CV.pdf drwxr-xr-x 28 myUser UserGroup 952B Sep 10 09:04 MRIdata drwxrwxrwx 5 myUser UserGroup 170B Sep 4 11:15 SharedFolder When using the -lh flag, the size of the file will be followed by a letter which represents the units: Letter Unit number of bytes per unit B Bytes 2^0 K Kilobytes 2^10 M Megabytes 2^20 G Gigabytes 2^30 T Terabytes 2^40 P Perabytes 2^50 Using multiple flags: Most of the flags can be combined, except for the following group of flags which override each other (either partially or fully). If used together, only the last one specified will be used. -1 , -C , -x , and -l -c and -u -B , -b , -w , and -q -H , -L and -P The example below combines -lh , -o , and -r to print the information in long format, using human readable file sizes ( -lh ), omitting the group id ( -o ) and in reverse lexicographical order ( -r ): $ ls -lhor /Volumes/MyExternalDrive Total 0 drwxrwxrwx 5 myUser 170B Sep 4 11:15 SharedFolder drwxr-xr-x 28 myUser 952B Sep 10 09:05 MRIdata -rw-r--r-- 1 myUser 134K Jan14 2017 CV.pdf -rw-r--r--@ 1 myUser 50K Jan 14 2017 CV.docx drwxr-xr-x 22 myUser 714B Sep 4 11:40 Articles Listing files using patterns You can print information about a group of files based on patterns using wildcards. Wildcard Meaning * Matches any number of characters. ? Matches any single character. [character_class] Marches any character that is a member o the specified character class. See below for a list of Character Classes. [!character_class] Marches any character that is NOT a member of the specified character class. Character Classes: [alnum] : alphanumeric characters. [alpha] : alphabetic characters. [digit] : numerals. [upper] : uppercase alphabetic characters. [lower] : lowercase alphabetic characters. Examples: Pattern MAtches AB* List all the filenames that begin with \"AB\". *AB List all the filenames that end with \"AB\". AB*.txt List all the filenames that begin with \"AB\" and end with \".txt\". AB??? List all the filenames that begin with \"AB\" and are followed by exactly three characters. [aA]* List all the filenames that begin with \"a\" or \"A\". [aA]?.txt List all the filenames that begin with \"a\" or \"A\" and are followed by one character and \".txt\". [[:upper:]]* List any filenames that begin with an uppercase letter. [![:upper:]]* List any filenames that do not begin with an uppercase letter. $ ls /Volumes/MyDrive/MyFolder/Articles/p* /Volumes/MyDrive/MyFolder/Articles/patel and shen.pdf /Volumes/MyDrive/MyFolder/Articles/perez 2013.pdf /Volumes/MyDrive/MyFolder/Articles/pnas-0502843102.pdf /Volumes/MyDrive/MyFolder/Articles/pnas.201604898.pdf /Volumes/MyDrive/MyFolder/Articles/pnas01522-0696.pdf /Volumes/MyDrive/MyFolder/Articles/poldrack ROI analysis.pdf /Volumes/MyDrive/MyFolder/Articles/pone.0088419.pdf /Volumes/MyDrive/MyFolder/Articles/pone.0113807.pdf /Volumes/MyDrive/MyFolder/Articles/pq004724.pdf /Volumes/MyDrive/MyFolder/Articles/pq008939.pdf /Volumes/MyDrive/MyFolder/Articles/precuneus.pdf /Volumes/MyDrive/MyFolder/Articles/prefrontalCortex.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]* /Volumes/MyExternalDrive/Shared/Articles/patel and shen.pdf /Volumes/MyExternalDrive/Shared/Articles/perez 2013.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas-0502843102.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas.201604898.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas01522-0696.pdf /Volumes/MyExternalDrive/Shared/Articles/poldrack ROI analysis.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0088419.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0113807.pdf /Volumes/MyExternalDrive/Shared/Articles/pq004724.pdf /Volumes/MyExternalDrive/Shared/Articles/pq008939.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf /Volumes/MyExternalDrive/Shared/Articles/prefrontalCortex.pdf /Volumes/MyExternalDrive/Shared/Articles/raz 2004.pdf /Volumes/MyExternalDrive/Shared/Articles/read1_Brain-2006-Ciccarelli-1859-71.pdf /Volumes/MyExternalDrive/Shared/Articles/read2_6165.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]*.pdf /Volumes/MyExternalDrive/Shared/Articles/patel and shen.pdf /Volumes/MyExternalDrive/Shared/Articles/perez 2013.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas-0502843102.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas.201604898.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas01522-0696.pdf /Volumes/MyExternalDrive/Shared/Articles/poldrack ROI analysis.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0088419.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0113807.pdf /Volumes/MyExternalDrive/Shared/Articles/pq004724.pdf /Volumes/MyExternalDrive/Shared/Articles/pq008939.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf /Volumes/MyExternalDrive/Shared/Articles/prefrontalCortex.pdf /Volumes/MyExternalDrive/Shared/Articles/raz 2004.pdf /Volumes/MyExternalDrive/Shared/Articles/read1_Brain-2006-Ciccarelli-1859-71.pdf /Volumes/MyExternalDrive/Shared/Articles/read2_6165.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]????????.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf Working directory The pwd command This command prints the absolute path of the current working directory. The cd command Option Usage cd ~ Goes to the home directory. cd dir Goes to dir , which is a sub directory located in the current directory. cd /dir Goes to dir , which is a sub directory located in the home directory. cd .. Goes to the parent directory. cd - Goes to the previous directory. cd ~username Goes to the user home directory cd changes the current working directory. The syntax is cd new_path , where new_path can be the absolute or relative path of the new working directory. Absolute paths are file locations with respect to the home directory and start with / . Relative paths are file locations with respect to the current directory. Two points ( .. ) represent the parent directory. If my current working directory is /Users/user_name/Desktop/SomeFolder , after typing cd .. the new working directory will be /Users/user_name/Desktop (one folder up). If you type again cd .. , now the working directory will be /Users/user_name (another folder up), etc. $ pwd /Users/user_name/Desktop/SomeFolder $ cd .. $ pwd /Users/user_name/Desktop $ cd .. $ pwd /Users/user_name $ cd .. $ pwd /Users $ cd .. $ pwd / / represents the home directory and you cannot go up any more folders. In this example, I am using the absolute path of a folder to jump from my current directory to that folder: $ pwd /Users/user_name/Desktop/SomeFolder $ cd /Volumes/Shared $ pwd /Volumes/Shared In this example, I go to the parent directory of my parent directory ( ../.. ): $ pwd /Users/user_name/Desktop/SomeFolder $ cd ../.. $ pwd /Users/user_name If inside my current directory ( /Users/user_name/Desktop/SomeFolder ) there is another folder, I can go to that folder using its relative path: $ pwd /Users/user_name/Desktop/SomeFolder $ cd AnotherFolder /Users/user_name/Desktop/SomeFolder/AnotherFolder $ pwd /Users/user_name/Desktop/SomeFolder $ cd ./AnotherFolder /Users/user_name/Desktop/SomeFolder/AnotherFolder In this example, the first working directory is /Volumes/Shared , then I jump to /Volumes/Shared/Articles using the command cd . Finally, I go back to the first working directory ( /Volumes/Shared ) using cd - . $ pwd /Volumes/Shared $ cd Articles $ pwd /Volumes/Shared/Articles $ cd - $ pwd /Volumes/Shared Other commands The cp command Syntax: cp source target If you specify a folder as a target in the cp command, it will copy the file with the same name. If you specify a regular file as a target, it will rename the file in the destination (not in the source, the source file will stay untouched). The source file need not have the same extension. For example, the following command will copy the file /Users/MyUser/Desktop/subjectFolder/534534.bvals into the folder /Volumes/MyExternalDrive , it will also rename it and delete the extension: cp /Users/MyUser/Desktop/subjectFolder/534534.bvals /Volumes/MyExternalDrive/bvals . Caution! If a file with the same name exists in the source, it will be re-written and this action cannot be undone. The mv command Syntax: mv source target The mv command works the same way as the cp command. The difference is that the source file is moved instead of copied and ceases to exist in the source location. The following example renames file1.txt to file2.txt in the current folder: $ ls Applications Library Volumes bin test1.txt $ mv test1.txt test2.txt $ ls Applications Library Volumes bin test2.txt In the following example we are moving a file test1.txt from one directory ( /Users/MyUser/ ) to another ( /Volumes/MyExternalDrive ): $ ls /Volumes/MyDrive $ ls /Users/MyUser/Desktop test1.txt $ mv /Users/MyUser/Desktop/test1.txt /Volumes/MyDrive $ ls /Volumes/MyDrive test1.txt $ ls /Users/MyUser/Desktop The rm command Syntax: rm file or rm -r folder The rm command permanently deletes a file or a folder and all its contents. For example, to delete file text1.txt in the current directory, one would use rm text1.txt . And to remove the folder myfolder and all its contents, one would use rm -r myfolder . These are the flags that you can use: Flag Action -f Forces deletion without any confirmation. -i Requires confirmation before deleting each file. -r Deletes a directory and all its contents recursively. -d Removes empty directories. The mkdir command Syntax: mkdir folder Creates a new directory if it doesn't exist. One can use a relative or an absolute path. mkdir myfolder will create a folder named myfolder in the current directory. mkdir ~/Desktop/myfolder will create a folder named myfolder in the Desktop. The touch command Syntax: touch filename The main use of this command is to create an empty file with the corresponding name. One can create multiple files at the same time, for example: touch file1.txt file2.txt file3.txt will create 3 empty text files. But it can also be used for other things depending on which flag you use: Flag Use Example -a Change the access time of a file to the current date and time. touch -a file1.txt -m Update the modification time of a file to the current date and time. touch -m file1.txt -d DATE Update the modification time of a file to DATE . touch -d \"2025-01-20 10:33\" myfile.txt -r reference_file Update the modification time of a file to the one of reference_file . touch -r myscript.sh myfile.txt changes the times of myfile.txt to those of myscript.sh The find command This command is used to locate files and data in the system. Finding a specific file In the example below 2>/dev/null silences permission errors. This search is case sensitive. It will search for a file named file.txt starting in /Path/to/start/search/ . find /Path/to/start/search/ -name \"file.txt\" 2>/dev/null The search in the example below is the same as the one above but with a case insensitive search, thanks to the -iname flag. find /Path/to/start/search/ -iname \"file.txt\" 2>/dev/null Finding a file using patterns One could use -name instead of -iname to make it case sensitive. Here we are searching for files that contain the string file in their name, followed by one character and the .txt extension. They can have any or no characters before file . find /Path/to/start/search/ -iname \"*file?.txt\" 2>/dev/null Listing the contents of a directory recursively In the following example, we list the content of /Path/to/start/search/ and of all directories inside it and save the info in file.txt . find /Path/to/start/search/ -ls Manipulate the output of find One could use the output of find to do something, for example, search if any of the files contain certain text, or execute a command on each of those files. To achieve this, we use the flag -exec . The expression must have a \\; or a + at the end. If the expression ends with \\; , the command or commands after exec will be executed of each output file of find separately. The semicolon is escaped because we don't want Bash to interpret it. If the expression ends with + , all the outputs of find will be concatenated and passed as a whole string to the command being executed, and this command will only be run once on this string. Examples: Use file on the output files of find : You could use any shell command instead of file . find /Path/to/start/search/ -name \"*.txt\" -exec file {} \\; Use basename on the output files of find : find /Path/to/start/search/ -name \"*.txt\" -exec file {} \\; Use grep to process the output of find : find /Path/to/start/search/ -name \"*.txt\" -exec grep grep_flags {} \\; Run a function on the output files of find : function my_function(){ commands } export -f my_function find /Path/to/start/search/ -name \"*.txt\" -exec bash -c \"my_function {}\" \\; If I know that some of the output files of find will have spaces or other special character, I should change the last line of the example above to the following (put escaped quotation marks around the brackets): find /Path/to/start/search/ -name \"*.txt\" -exec bash -c \"my_function \\\"{}\\\"\" \\; Search by type Get the list of directories inside /Path/to/start/search/ : find /Path/to/start/search/ -type d Get the list of regular files inside /Path/to/start/search/ : find /Path/to/start/search/ -type f Get the list of symbolic links inside /Path/to/start/search/ : find /Path/to/start/search/ -type l Get the list of files and symbolic links: find /Path/to/start/search/ -type f,l Limit the depth of the search Descend only one directory: find -maxdepth 1 /Path/to/start/search/ -type d Descend two directories: find -maxdepth 2 /Path/to/start/search/ -type d To search all the flags and options of find , type man find in your command line. Many more things can be done with this command.","title":"File manipulation"},{"location":"files/#general-file-manipulation","text":"","title":"General file manipulation"},{"location":"files/#absolute-paths","text":"The absolute or full path of a file specifies its unique location in the file system, its name and extension. The absolute path of every file is different and constant. It will always be the same regardless of the current directory in which you are working (unless you move the file). This path follows a hierarchy of directories where the file is located, separating each directory with the delimiting character, which is the slash for Macintosh and Linux and the backslash for Windows. For example, a text file named file.txt located in the Desktop of a Mac computer, will commonly have an absolute path similar to this: /Users/user_name/Desktop/file.txt . To find the absolute path of a file you can drag and drop it into the Terminal. For example, if this is the absolute path of a file: /Users/user_name/Desktop/SomeFolder/Subfolder/file.txt . It means that in the Desktop there is a folder called SomeFolder , inside SomeFolder there is another folder called Subfolder , and inside Subfolder is located the corresponding file, with name file and extension txt . There cannot be two files with the same name and extension inside a folder.","title":"Absolute paths"},{"location":"files/#relative-paths","text":"The relative path of a file starts from the current working directory and represents the location of a specific file relative to this directory. It is always changing as it depends on what directory you are located in the terminal. If the absolute path of a file is /Users/user_name/Desktop/file.txt and the user current working directory is the Desktop, then the relative path of the file is: file.txt or ./file.txt . ./ represents the current directory. The following relative paths represent files that are located in the current working directory: File1.txt File2.nii.gz ./File3.nii ./File4.docx The absolute path of these files will be something similar to this (for Mac users), if the current directory is the Desktop: /Users/username/Desktop/File1.txt /Users/username/Desktop/File2.nii.gz /Users/username/Desktop/File3.nii /Users/username/Desktop/File4.docx The same way that one dot represents the current directory in a relative path, two dots represent the parent directory. So, if the absolute path of my current working directory is /Users/user_name/Desktop/SomeFolder , I can refer to files located in the parent directory (Desktop) using the double dots. So, all these files are located in the Desktop (the same as SomeFolder ): ../FileA.txt ../FileB.txt ../FileC.txt","title":"Relative paths"},{"location":"files/#tips","text":"Absolute and relative paths are used to reference files when doing operations with them, but is better to use the absolute paths when writing scripts. That way the script will not run into issues independently of the working directory. Otherwise, you might get file not found errors. Do not use spaces or any other special characters when naming a file. It makes it harder to write the path of that file. For example, if I have a file named Some File.txt in my Desktop (on a Mac), /Users/user_name/Desktop/Some File.txt is not the absolute path. Instead, the absolute path will be /Users/user_name/Desktop/Some\\ File.txt . Paths cannot have spaces unless you use scape characters, in this case the backslash. Another example is using the dollar sign (which is a special character) inside a file name. For example, if in the Desktop there is a folder named untitled$folder , /Users/user_name/Desktop/untitled$folder is not the absolute path. Instead, the absolute path will be /Users/user_name/Desktop/untitled\\$folder . The backslash is indicating us to treat the special character ( $ ) as part of the file name and not as the beginning of a variable name (which is the normal use of $ in Bash). If we don't use the backslash before the dollar sign, Bash will try to find a variable called folder. If that variable doesn't exist, then Bash will read /Users/user_name/Desktop/untitled$folder as /Users/user_name/Desktop/untitled , replacing $folder for an empty space. If that variable exists, Bash will replace $folder by the value of the variable. In the following sections you will learn how absolute and relative paths are used to manipulate files in MacOS and Linux .","title":"Tips"},{"location":"files/#listing-files","text":"","title":"Listing files"},{"location":"files/#the-ls-command","text":"Lists the files and folders inside the specified directory. If no directory is specified after ls , then it prints the contents of the current folder. If no flag is used, it lists the files in bare format (without any details such as modified date and time or permissions). Depending which flag is used (or a combination of flags), then specific information about the file will be displayed. The following table is taken from manual of the ls command as displayed in the command line. List of flags that I use more often: Flag Use -a Include directory entries whose names begin with a dot. Typically, these are configuration files for applications or hidden files. -G Enable colorized output. This option is equivalent to defining CLICOLOR in the environment. -H Symbolic links on the command line are followed. This option is assumed if none of the -F or -l options are specified. -l Force output to be one entry per line. This is the default when output is not to a terminal. -lh Use unit suffixes when displaying the information in long output: Byte, Kilobyte, Megabyte, Gigabyte, Terabyte and Petabyte, in order to reduce the number of digits to three or less using base 2 for sizes. -ln Display user and group IDs numerically, rather than converting to a user or group name in a long output. -R Recursively list subdirectories encountered. -S Sort files by size. -t Sort files by time modified (most recently modified first) before sorting by lexicographical order. Other flags: Flag Use -A List all entries except for ( . ) and ( .. ). Always set for the super-user. -B Force printing of non-printable characters in file names. -b As -B , but use C escape codes whenever possible. -C Force multi-column output; this is the default when output is to a terminal. -c Directories are listed as plain files (not searched recursively). -F Display a slash immediately after each pathname that is a directory, an asterisk after each that is executable, a @ after each symbolic link, an equal sign after each socket, a percent sign after each whiteout, and a vertical bar after each that is a FIFO. -f Output is not sorted. This option turns on the -a option. -i For each file, print the serial number. -k If the -s option is specified, print the file size allocation in kilobytes, not blocks. -L Follow all symbolic links to final target and list the file or directory the link references rather than the link itself. This option cancels the -P option. -l@ Display extended attribute keys and sizes in long output. -le Print the Access Control List (ACL) associated with the file, if present, in long output. -lg This option is only available for compatibility with POSIX; it is used to display the group name in the long format output (the owner name is suppressed). -lO Include the file flags in a long output. -lT Display complete time information for the file, including month, day, hour, minute, second, and year. -m Stream output format; list files across the page, separated by commas. -o List in long format, but omit the group id. -P If argument is a symbolic link, list the link itself rather than the object the link references. This option cancels the -H and -L options. -p Write a slash after each filename if that file is a directory. -q Force printing of non-graphic characters in file names as the interrogation character; this is the default when output is to a terminal. -r Reverse the order of the sort to reverse lexicographical order, or the oldest entries first (or largest files last, if combined with sort by size). -s Display the number of file system blocks actually used by each file, in units of 512 bytes, where partial units are rounded up to the next integer value. If the output is to a terminal, a total sum for all the file sizes is output on a line before the listing. The environment variable BLOCKSIZE overrides the unit size of 512 bytes. -u Use time of last access, instead of last modification of the file for sorting ( -t ) or long printing ( -l ) -U Use time of file creation, instead of last modification for sorting ( -t ) or long output ( -l ). -v Force unedited printing of non-graphic characters; this is the default when output is not to a terminal. -W Display whiteouts when scanning directories. -w Force raw printing of non-printable characters. This is the default when output is not to a terminal. -x The same as -C , except that the multi-column output is produced with entries sorted across, rather than down the columns. The following examples show the usage of the flags presented in the previous table and details of the results that can be obtained when using the command ls together with those flags. ls command with no flags: Show the list of the files in the working directory: $ ls Applicationshome Libraryinstaller.failurerequests Networknet Subjectsopt Usersprivate Volumessbin binmp coresusr devvar etc Show the list of files in a different directory using the absolute path of that directory: $ ls /Volumes/MyExternalDrive ArticlesMRIdata SharedFolder Show the list of files in a subfolder ( Applications ) using the relative path : $ ls Applications/ Calculator.app Calendar.app Chess.app Dashboard.app Dictionary.app EndNote X7 EndNote X8 FaceTime.app Firefox.app IBM Image Capture.app Launchpad.app MATLAB_R2014b.app ls -l : When using the flag -l , Bash will not only show the list of files but also a description for each file. The output will be organized in columns, each one with a specific meaning that I will explain in the table below. $ ls -l /Volumes/MyExternalDrive Total 0 drwxr-xr-x 22 myUser UserGroup 714 Sep 4 11:40 Articles -rw-r--r--@ 1 myUse UserGroup 51620 Jan 14 2017 CV.docx -rw-r--r-- 1 myUser UserGroup 137195 Jan 14 2017 CV.pdf drwxr-xr-x 28 myUser UserGroup 952 Sep 10 09:04 MRIdata drwxrwxrwx 5 myUser UserGroup 170 Sep 4 11:15 SharedFolder Column number Column name Meaning 1 File type + permissions See below for the explanation of the output presented in this column. 2 Link count Number of hard links to the file. Data is only removed from your drive when all hard links to the data have been removed. 3 Owner name See below for the explanation of file ownership and permissions. 4 Group name See below for the explanation of file ownership and permissions. 5 File size Number of bytes in the file. See the flag -lh to output the size of the file in human-readable format. 6 Last modified date Abbreviated month and day-of-month when the file was last modified. 7 Last modified time Abbreviated hour and minute when the file was last modified in military format (24 hours). If the file was last modified more than six months before, then the year of the last modification is displayed instead of the hour and minute. 8 File name Name of the file with its extension. File type and permissions from the ls -l command: The first column of the output printed when using the flag -l shows the file type and permissions. This column has 10 characters. Each character will be a letter or a dash. The first character describes the type of file and can be one of the following: Character File type b Block special file: provide access to hardware devices. c Character special file: provide access to hardware devices. d Directory. l Symbolic link: a file that points to another file (a shortcut). It does not contain the data in the target file; it simply contains a pointer somewhere in the file system. s Socket link: file used for communication between processes. p FIFO: special file that can be opened by various processes for exchanging data. - Regular file. The second character shows if the user listed as owner has reading permissions. It will be an r if the owner can read the file, or a - if not. The third character shows if the user listed as owner has writing permissions. It will be a w if the owner can write in the file, or a - if not. The fourth character shows if the user listed as owner has execution permissions. It will have value x if the owner can execute the file, or a - if not. The fifth character shows if the users that are part of the group have reading permissions. It will have an r if they can read, or a - if not. The sixth character shows if the users that are part of the group have writing permissions. It will have a w if they can write, or a - if not. The seventh character shows if the users that are part of the group have execution permissions. It will have a x if they can execute, or a - if not. The eight character shows if other users have reading permissions. It will have an r if they can read, or a - if not. The ninth character shows if other users have writing permissions. It will have an w if they can write, or a - if not. The tenth character shows if other users have execution permissions. It will have a x if they can execute, or a - if not. To change the permissions of a file you would use the chmod command. This command has the following syntax: chmod <num_for_owner><num_for_group><num_for_others> <file> <num_for_owner> is a number to change the owner permissions. <num_for_group> is a number to change the group permissions. <num_for_others> is a number to change the permissions of other users. These numbers can be one of the following: Number Characters in ls -l Meaning 7 rwx Give full permissions (read, write and execute). 6 rw- Give read and write permissions, but not execute. 5 r-x Give read and execute permissions, but not write. 4 r-- Give only read permissions. 3 -wx Give write and execute permissions, but not read. 2 -w- Give only write permissions. 1 --x Give only execute permissions. 0 --- Give no permissions. For example if you run chmod 775 myfile , the owner and group will have full permissions, other users will be able to read and execute but not write. If you run chmod 744 myfile , the owner will have full permissions, users belonging to the group and other users will only be able to read, but they wont be able to write or execute the file. Human readable file size with ls -lh : The information displayed in the 5th column (file size) when using ls -l is difficult to interpret by a human. In order to see this information in a human-readable format, it is only necessary to add an h to the -l flag. $ ls -lh /Volumes/MyExternalDrive Total 0 drwxr-xr-x 22 myUser UserGroup 714B Sep 4 11:40 Articles -rw-r--r--@ 1 myUser UserGroup 50K Jan 14 2017 CV.docx -rw-r--r-- 1 myUser UserGroup 134K Jan 14 2017 CV.pdf drwxr-xr-x 28 myUser UserGroup 952B Sep 10 09:04 MRIdata drwxrwxrwx 5 myUser UserGroup 170B Sep 4 11:15 SharedFolder When using the -lh flag, the size of the file will be followed by a letter which represents the units: Letter Unit number of bytes per unit B Bytes 2^0 K Kilobytes 2^10 M Megabytes 2^20 G Gigabytes 2^30 T Terabytes 2^40 P Perabytes 2^50 Using multiple flags: Most of the flags can be combined, except for the following group of flags which override each other (either partially or fully). If used together, only the last one specified will be used. -1 , -C , -x , and -l -c and -u -B , -b , -w , and -q -H , -L and -P The example below combines -lh , -o , and -r to print the information in long format, using human readable file sizes ( -lh ), omitting the group id ( -o ) and in reverse lexicographical order ( -r ): $ ls -lhor /Volumes/MyExternalDrive Total 0 drwxrwxrwx 5 myUser 170B Sep 4 11:15 SharedFolder drwxr-xr-x 28 myUser 952B Sep 10 09:05 MRIdata -rw-r--r-- 1 myUser 134K Jan14 2017 CV.pdf -rw-r--r--@ 1 myUser 50K Jan 14 2017 CV.docx drwxr-xr-x 22 myUser 714B Sep 4 11:40 Articles","title":"The ls command"},{"location":"files/#listing-files-using-patterns","text":"You can print information about a group of files based on patterns using wildcards. Wildcard Meaning * Matches any number of characters. ? Matches any single character. [character_class] Marches any character that is a member o the specified character class. See below for a list of Character Classes. [!character_class] Marches any character that is NOT a member of the specified character class. Character Classes: [alnum] : alphanumeric characters. [alpha] : alphabetic characters. [digit] : numerals. [upper] : uppercase alphabetic characters. [lower] : lowercase alphabetic characters. Examples: Pattern MAtches AB* List all the filenames that begin with \"AB\". *AB List all the filenames that end with \"AB\". AB*.txt List all the filenames that begin with \"AB\" and end with \".txt\". AB??? List all the filenames that begin with \"AB\" and are followed by exactly three characters. [aA]* List all the filenames that begin with \"a\" or \"A\". [aA]?.txt List all the filenames that begin with \"a\" or \"A\" and are followed by one character and \".txt\". [[:upper:]]* List any filenames that begin with an uppercase letter. [![:upper:]]* List any filenames that do not begin with an uppercase letter. $ ls /Volumes/MyDrive/MyFolder/Articles/p* /Volumes/MyDrive/MyFolder/Articles/patel and shen.pdf /Volumes/MyDrive/MyFolder/Articles/perez 2013.pdf /Volumes/MyDrive/MyFolder/Articles/pnas-0502843102.pdf /Volumes/MyDrive/MyFolder/Articles/pnas.201604898.pdf /Volumes/MyDrive/MyFolder/Articles/pnas01522-0696.pdf /Volumes/MyDrive/MyFolder/Articles/poldrack ROI analysis.pdf /Volumes/MyDrive/MyFolder/Articles/pone.0088419.pdf /Volumes/MyDrive/MyFolder/Articles/pone.0113807.pdf /Volumes/MyDrive/MyFolder/Articles/pq004724.pdf /Volumes/MyDrive/MyFolder/Articles/pq008939.pdf /Volumes/MyDrive/MyFolder/Articles/precuneus.pdf /Volumes/MyDrive/MyFolder/Articles/prefrontalCortex.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]* /Volumes/MyExternalDrive/Shared/Articles/patel and shen.pdf /Volumes/MyExternalDrive/Shared/Articles/perez 2013.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas-0502843102.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas.201604898.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas01522-0696.pdf /Volumes/MyExternalDrive/Shared/Articles/poldrack ROI analysis.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0088419.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0113807.pdf /Volumes/MyExternalDrive/Shared/Articles/pq004724.pdf /Volumes/MyExternalDrive/Shared/Articles/pq008939.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf /Volumes/MyExternalDrive/Shared/Articles/prefrontalCortex.pdf /Volumes/MyExternalDrive/Shared/Articles/raz 2004.pdf /Volumes/MyExternalDrive/Shared/Articles/read1_Brain-2006-Ciccarelli-1859-71.pdf /Volumes/MyExternalDrive/Shared/Articles/read2_6165.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]*.pdf /Volumes/MyExternalDrive/Shared/Articles/patel and shen.pdf /Volumes/MyExternalDrive/Shared/Articles/perez 2013.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas-0502843102.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas.201604898.pdf /Volumes/MyExternalDrive/Shared/Articles/pnas01522-0696.pdf /Volumes/MyExternalDrive/Shared/Articles/poldrack ROI analysis.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0088419.pdf /Volumes/MyExternalDrive/Shared/Articles/pone.0113807.pdf /Volumes/MyExternalDrive/Shared/Articles/pq004724.pdf /Volumes/MyExternalDrive/Shared/Articles/pq008939.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf /Volumes/MyExternalDrive/Shared/Articles/prefrontalCortex.pdf /Volumes/MyExternalDrive/Shared/Articles/raz 2004.pdf /Volumes/MyExternalDrive/Shared/Articles/read1_Brain-2006-Ciccarelli-1859-71.pdf /Volumes/MyExternalDrive/Shared/Articles/read2_6165.pdf $ ls /Volumes/MyExternalDrive/Shared/Articles/[pr]????????.pdf /Volumes/MyExternalDrive/Shared/Articles/precuneus.pdf","title":"Listing files using patterns"},{"location":"files/#working-directory","text":"","title":"Working directory"},{"location":"files/#the-pwd-command","text":"This command prints the absolute path of the current working directory.","title":"The pwd command"},{"location":"files/#the-cd-command","text":"Option Usage cd ~ Goes to the home directory. cd dir Goes to dir , which is a sub directory located in the current directory. cd /dir Goes to dir , which is a sub directory located in the home directory. cd .. Goes to the parent directory. cd - Goes to the previous directory. cd ~username Goes to the user home directory cd changes the current working directory. The syntax is cd new_path , where new_path can be the absolute or relative path of the new working directory. Absolute paths are file locations with respect to the home directory and start with / . Relative paths are file locations with respect to the current directory. Two points ( .. ) represent the parent directory. If my current working directory is /Users/user_name/Desktop/SomeFolder , after typing cd .. the new working directory will be /Users/user_name/Desktop (one folder up). If you type again cd .. , now the working directory will be /Users/user_name (another folder up), etc. $ pwd /Users/user_name/Desktop/SomeFolder $ cd .. $ pwd /Users/user_name/Desktop $ cd .. $ pwd /Users/user_name $ cd .. $ pwd /Users $ cd .. $ pwd / / represents the home directory and you cannot go up any more folders. In this example, I am using the absolute path of a folder to jump from my current directory to that folder: $ pwd /Users/user_name/Desktop/SomeFolder $ cd /Volumes/Shared $ pwd /Volumes/Shared In this example, I go to the parent directory of my parent directory ( ../.. ): $ pwd /Users/user_name/Desktop/SomeFolder $ cd ../.. $ pwd /Users/user_name If inside my current directory ( /Users/user_name/Desktop/SomeFolder ) there is another folder, I can go to that folder using its relative path: $ pwd /Users/user_name/Desktop/SomeFolder $ cd AnotherFolder /Users/user_name/Desktop/SomeFolder/AnotherFolder $ pwd /Users/user_name/Desktop/SomeFolder $ cd ./AnotherFolder /Users/user_name/Desktop/SomeFolder/AnotherFolder In this example, the first working directory is /Volumes/Shared , then I jump to /Volumes/Shared/Articles using the command cd . Finally, I go back to the first working directory ( /Volumes/Shared ) using cd - . $ pwd /Volumes/Shared $ cd Articles $ pwd /Volumes/Shared/Articles $ cd - $ pwd /Volumes/Shared","title":"The cd command"},{"location":"files/#other-commands","text":"","title":"Other commands"},{"location":"files/#the-cp-command","text":"Syntax: cp source target If you specify a folder as a target in the cp command, it will copy the file with the same name. If you specify a regular file as a target, it will rename the file in the destination (not in the source, the source file will stay untouched). The source file need not have the same extension. For example, the following command will copy the file /Users/MyUser/Desktop/subjectFolder/534534.bvals into the folder /Volumes/MyExternalDrive , it will also rename it and delete the extension: cp /Users/MyUser/Desktop/subjectFolder/534534.bvals /Volumes/MyExternalDrive/bvals . Caution! If a file with the same name exists in the source, it will be re-written and this action cannot be undone.","title":"The cp command"},{"location":"files/#the-mv-command","text":"Syntax: mv source target The mv command works the same way as the cp command. The difference is that the source file is moved instead of copied and ceases to exist in the source location. The following example renames file1.txt to file2.txt in the current folder: $ ls Applications Library Volumes bin test1.txt $ mv test1.txt test2.txt $ ls Applications Library Volumes bin test2.txt In the following example we are moving a file test1.txt from one directory ( /Users/MyUser/ ) to another ( /Volumes/MyExternalDrive ): $ ls /Volumes/MyDrive $ ls /Users/MyUser/Desktop test1.txt $ mv /Users/MyUser/Desktop/test1.txt /Volumes/MyDrive $ ls /Volumes/MyDrive test1.txt $ ls /Users/MyUser/Desktop","title":"The mv command"},{"location":"files/#the-rm-command","text":"Syntax: rm file or rm -r folder The rm command permanently deletes a file or a folder and all its contents. For example, to delete file text1.txt in the current directory, one would use rm text1.txt . And to remove the folder myfolder and all its contents, one would use rm -r myfolder . These are the flags that you can use: Flag Action -f Forces deletion without any confirmation. -i Requires confirmation before deleting each file. -r Deletes a directory and all its contents recursively. -d Removes empty directories.","title":"The rm command"},{"location":"files/#the-mkdir-command","text":"Syntax: mkdir folder Creates a new directory if it doesn't exist. One can use a relative or an absolute path. mkdir myfolder will create a folder named myfolder in the current directory. mkdir ~/Desktop/myfolder will create a folder named myfolder in the Desktop.","title":"The mkdir command"},{"location":"files/#the-touch-command","text":"Syntax: touch filename The main use of this command is to create an empty file with the corresponding name. One can create multiple files at the same time, for example: touch file1.txt file2.txt file3.txt will create 3 empty text files. But it can also be used for other things depending on which flag you use: Flag Use Example -a Change the access time of a file to the current date and time. touch -a file1.txt -m Update the modification time of a file to the current date and time. touch -m file1.txt -d DATE Update the modification time of a file to DATE . touch -d \"2025-01-20 10:33\" myfile.txt -r reference_file Update the modification time of a file to the one of reference_file . touch -r myscript.sh myfile.txt changes the times of myfile.txt to those of myscript.sh","title":"The touch command"},{"location":"files/#the-find-command","text":"This command is used to locate files and data in the system.","title":"The find command"},{"location":"files/#finding-a-specific-file","text":"In the example below 2>/dev/null silences permission errors. This search is case sensitive. It will search for a file named file.txt starting in /Path/to/start/search/ . find /Path/to/start/search/ -name \"file.txt\" 2>/dev/null The search in the example below is the same as the one above but with a case insensitive search, thanks to the -iname flag. find /Path/to/start/search/ -iname \"file.txt\" 2>/dev/null","title":"Finding a specific file"},{"location":"files/#finding-a-file-using-patterns","text":"One could use -name instead of -iname to make it case sensitive. Here we are searching for files that contain the string file in their name, followed by one character and the .txt extension. They can have any or no characters before file . find /Path/to/start/search/ -iname \"*file?.txt\" 2>/dev/null","title":"Finding a file using patterns"},{"location":"files/#listing-the-contents-of-a-directory-recursively","text":"In the following example, we list the content of /Path/to/start/search/ and of all directories inside it and save the info in file.txt . find /Path/to/start/search/ -ls","title":"Listing the contents of a directory recursively"},{"location":"files/#manipulate-the-output-of-find","text":"One could use the output of find to do something, for example, search if any of the files contain certain text, or execute a command on each of those files. To achieve this, we use the flag -exec . The expression must have a \\; or a + at the end. If the expression ends with \\; , the command or commands after exec will be executed of each output file of find separately. The semicolon is escaped because we don't want Bash to interpret it. If the expression ends with + , all the outputs of find will be concatenated and passed as a whole string to the command being executed, and this command will only be run once on this string. Examples: Use file on the output files of find : You could use any shell command instead of file . find /Path/to/start/search/ -name \"*.txt\" -exec file {} \\; Use basename on the output files of find : find /Path/to/start/search/ -name \"*.txt\" -exec file {} \\; Use grep to process the output of find : find /Path/to/start/search/ -name \"*.txt\" -exec grep grep_flags {} \\; Run a function on the output files of find : function my_function(){ commands } export -f my_function find /Path/to/start/search/ -name \"*.txt\" -exec bash -c \"my_function {}\" \\; If I know that some of the output files of find will have spaces or other special character, I should change the last line of the example above to the following (put escaped quotation marks around the brackets): find /Path/to/start/search/ -name \"*.txt\" -exec bash -c \"my_function \\\"{}\\\"\" \\;","title":"Manipulate the output of find"},{"location":"files/#search-by-type","text":"Get the list of directories inside /Path/to/start/search/ : find /Path/to/start/search/ -type d Get the list of regular files inside /Path/to/start/search/ : find /Path/to/start/search/ -type f Get the list of symbolic links inside /Path/to/start/search/ : find /Path/to/start/search/ -type l Get the list of files and symbolic links: find /Path/to/start/search/ -type f,l","title":"Search by type"},{"location":"files/#limit-the-depth-of-the-search","text":"Descend only one directory: find -maxdepth 1 /Path/to/start/search/ -type d Descend two directories: find -maxdepth 2 /Path/to/start/search/ -type d To search all the flags and options of find , type man find in your command line. Many more things can be done with this command.","title":"Limit the depth of the search"},{"location":"img_files/","text":"Manipulating image files ImageMagick (linux, Mac) Installation Go to the ImageMagic installation page for detailed instructions for different operating systems. Utilities ImageMagick has a list of utilities that can be used for different purposes. The following table presents a summary of those. Then, I will show some examples for each of these utilities. These examples will help you better understand how to use them. When specifying a color in any ImageMagick command, you can use the name of any recognized color , the RGB value, or the Hex value. When specifying a shape to draw on an image, you can use any of the valid shapes . Utility Use Syntax Links magick This command now replaces convert , which is deprecated. Change image format, blur, crop, draw on, flip, merge, resample, and more. Writes output on a new file. magick [input-options] input-file(s) [output-options] output-file Man page , Documentation identify Obtain information about an image. identify [options] input-file Man page , Documentation mogrify Resize an image, blur, crop, draw on, flip, merge, resample, and more. Re-writes original file. mogrify [options] input-file Man page , Documentation composite Overlaps one image over another. composite [ options ... ] change-file base-file [ mask-file ] output-image Man page , Documentation montage Combines different images, adds border, frame, and much more. montage input-file[s] [options] output-file Man page , Documentation compare Compare two images. compare input-file input-file [options] output-file Man page , Documentation stream Writes the pixel components of an img a row at a time into different storage formats. compare input-file input-file [options] output-file Man page , Documentation display Displays an image or image sequence. display [options] input-file Man page , Documentation animate Animates an image sequence. animate [options] input-file Man page , Documentation import Saves any visible window as an img file. Captures a single window, the entire screen, or any rectangular portion of the screen. import [options] output-file Man page , Documentation conjure Interprets and executes scripts written in the Magick Scripting Language (MSL). conjure [options] script.msl Man page , Documentation Examples In the following examples we will use this image: magick Syntax: magick [input-option] input-file [output-option] output-file Changing the color of pixels: In the following example we are replacing all pixels that have a distance of at most 50%, 60% and 100% from 255 in the blue value of their RGB: magick grandma.jpg -fuzz 50% -fill \"red\" -opaque \"blue\" grandma_50.jpg magick grandma.jpg -fuzz 60% -fill \"red\" -opaque \"blue\" grandma_60.jpg magick grandma.jpg -fuzz 100% -fill \"red\" -opaque \"blue\" grandma_100.jpg Meaning of used options: fuzz : Distance from 255 in those pixels to be matched. 50% means any pixel with blue value between 127.5 (50% of 255) and 255. 60% means any pixel with blue value between 102 and 255. 60% of 255 is 153, and 255-153=102. Any pixel with blue value within this range will be at most 60% away from being 100% blue. 100% means any pixel with blue value at most 100% away from being 100% blue, this includes all pixels in the image. opaque : Color to be replaced. See the list of recognized colors . Output with 50% of fuzz: Output with 60% of fuzz: Output with 100% of fuzz: You can also change the color of pixels in a specific area: magick grandma.jpg -fill \"rgb(255,250,250)\" -draw \"rectangle 0,300 200,350\" grandma_rect.jpg Meaning of used options: fill : Color to fill the form. See the list of recognized colors . draw : Shape to draw. See list of valid shapes and their parameters . Output: Add text over the rectangle drawn on the image above: magick grandma_rect.jpg -font helvetica -fill black -pointsize 15 -draw \"text 0,315 'Grandma\\nand\\nbaby'\" grandma_rect_txt.png Meaning of used options: font : Font for the text. To see the list of all available fonts type magick -list font . fill : Color to fill the form, in this case the text. See the list of recognized colors . pointsize : Text size. draw : Shape to draw. See list of valid shapes and their parameters . Output: Concatenate images horizontally: In the following example I will concatenate some images ( grandma.jpg grandma_50.jpg grandma_100.jpg ) horizontally, add a border, and flip the image along the horizontal axis. magick grandma.jpg grandma_50.jpg grandma_100.jpg +append -resize x300 -bordercolor black -border 10x15 -flip horizontal.png Meaning of used options: resize : Force the output file to have a height of 300 pixels. If the input images have different heights, then this parameter is recommended. Otherwise, the output will have the same height as the input files if this parameter is not used. bordercolor : Color of the border. See the list of recognized colors . border : Add a border with the specified thickness. In this case we are adding a border with a thickness of 10 pixels on the left and right and 15 pixels on the top and bottom. flip : I'm flipping the output image along the horizontal axis . To flip the image along the vertical axis, use -flop . Make sure to insert the flip flag after +append to apply the flip to the output instead of any of the input files. See example below on how to apply flip or flop to the input instead of output files. Output: Concatenate images vertically: In the following example I will concatenate some images ( grandma.jpg and grandma_50.jpg ) horizontally. Before the concatenation, I will flip the first input file along the vertical axis and transform the color space to Gray. magick grandma.jpg -colorspace Gray -flop grandma_50.jpg -append -resize 300x vertical.png Meaning of used options: colorspace : Color space to apply to the input image. It will apply to any input image specified before the flag, in this case grandma.jpg . If we wanted the whole output file to be on Gray scale, we would add the flag at the end of all input images. Available color spaces: sRGB , RGB , Gray , HSV , HSB , HSL , LAB , LCH , CMYK , XYZ , YUV , YCbCr , AdobeRGB , plus others. flop : I'm flipping the input image (grandma.jpg) along the vertical axis . To flip the image along the horizontal axis, use flip . resize : Force the output file to have a width of 300 pixels. If the input images have different widths, then this parameter is recommended. Otherwise, the output will have the same width as the input files if this parameter is not used. Output: Detect edges: In the following example I will detect edges in the image generated in the example above using two methods: the standard edge detection with the -edge flag, and the Canny Edge detection with smoothing using -canny . -canny is more sophisticated and allows for modifying the radius, sigma and threshold for filtering out edges. magick vertical.png -edge 2 edges.png magick vertical.png -canny 0x1+10%+30% edges2.png Meaning of used options: -edge 2 : Apply an edge of radius 2. To make the edges thicker, increment the value of 2 , or to make them thinner, give a value of 1 . -canny 0x1+10%+30% : Apply Canny Edge Detection with smoothing. The arguments here set the radius to 0 (auto-determined) and sigma to 1. Increase sigma for more smoothing. 10% and 30% are the lower and upper percentage thresholds for edge detection. Play around with these values to filter out weaker edges and highlight more important ones. Increasing the upper percentage will remove more edges. Output using -edge : Output using -canny : identify mogrify composite montage compare stream display animate import conjure ImageMagick shapes Shape Syntax Notes Point point x,y Specified by an ordered pair of integer coordinates. Line line x0,y0 x1,y1 Requires a start and end point. Rectangle rectangle x0,y0 x1,y1 Specified by the pair of points at the upper left and lower right corners. Round rectangle roundRectangle x0,y0, x1,y1 wc,hc Takes same corner points as rectangle , followed by the width and height of the rounded corners to be removed. Arc arc x0,y0 x1,y1 a0,a1 Requires two corners used to create a rectangle , followed by the start and end angles of the arc in degrees. Ellipse ellipse x0,y0 rx,ry a0,a1 Requires the center point, the horizontal and vertical radius, and the start and end angles in degrees. Circle circle x0,y0 x1,y1 Give the center and any point on the perimeter. Can make a disk (filled) or circle (unfilled). Polyline polyline x0,y0 ... xn,yn Requires three or more points to define their perimeters. This is simply a polygon in which the final point is not stroked to the start point. Polygon polygon x0,y0 ... xn,yn Requires three or more points to define their perimeters. Bezier bezier x0,y0 ... xn,yn Creates a spline curve and requires three or points to define its shape. Path path specification represents an outline of an object, defined in terms of moveto (set a new current point), lineto (draw a straight line), curveto (draw a Bezier curve), arc (elliptical or circular arc) and closepath (close the current shape by drawing a line to the last moveto ) elements. Image image operator x0,y0 w,h filename Used to composite an image with another image. Text text x,y text_to_display Add text in coordinates x,y of image. ImageMagick color list Color name RGB Hex snow1 rgb(255,250,250) #FFFAFA snow2 rgb(238,233,233) #EEE9E9 RosyBrown1 rgb(255,193,193) #FFC1C1 RosyBrown2 rgb(238,180,180) #EEB4B4 snow3 rgb(205,201,201) #CDC9C9 LightCoral rgb(240,128,128) #F08080 IndianRed1 rgb(255,106,106) #FF6A6A RosyBrown3 rgb(205,155,155) #CD9B9B IndianRed2 rgb(238,99,99) #EE6363 RosyBrown rgb(188,143,143) #BC8F8F brown1 rgb(255,64,64) #FF4040 firebrick1 rgb(255,48,48) #FF3030 brown2 rgb(238,59,59) #EE3B3B IndianRed rgb(205,92,92) #CD5C5C IndianRed3 rgb(205,85,85) #CD5555 firebrick2 rgb(238,44,44) #EE2C2C snow4 rgb(139,137,137) #8B8989 brown3 rgb(205,51,51) #CD3333 red rgb(255,0,0) #FF0000 red1 rgb(255,0,0) #FF0000 RosyBrown4 rgb(139,105,105) #8B6969 firebrick3 rgb(205,38,38) #CD2626 red2 rgb(238,0,0) #EE0000 firebrick rgb(178,34,34) #B22222 brown rgb(165,42,42) #A52A2A red3 rgb(205,0,0) #CD0000 IndianRed4 rgb(139,58,58) #8B3A3A brown4 rgb(139,35,35) #8B2323 firebrick4 rgb(139,26,26) #8B1A1A DarkRed rgb(139,0,0) #8B0000 red4 rgb(139,0,0) #8B0000 maroon(SVGcompliance) rgb(128,0,0) #800000 LightPink1 rgb(255,174,185) #FFAEB9 LightPink3 rgb(205,140,149) #CD8C95 LightPink4 rgb(139,95,101) #8B5F65 LightPink2 rgb(238,162,173) #EEA2AD LightPink rgb(255,182,193) #FFB6C1 pink rgb(255,192,203) #FFC0CB crimson rgb(220,20,60) #DC143C pink1 rgb(255,181,197) #FFB5C5 pink2 rgb(238,169,184) #EEA9B8 pink3 rgb(205,145,158) #CD919E pink4 rgb(139,99,108) #8B636C PaleVioletRed4 rgb(139,71,93) #8B475D PaleVioletRed rgb(219,112,147) #DB7093 PaleVioletRed2 rgb(238,121,159) #EE799F PaleVioletRed1 rgb(255,130,171) #FF82AB PaleVioletRed3 rgb(205,104,137) #CD6889 LavenderBlush rgb(255,240,245) #FFF0F5 LavenderBlush1 rgb(255,240,245) #FFF0F5 LavenderBlush3 rgb(205,193,197) #CDC1C5 LavenderBlush2 rgb(238,224,229) #EEE0E5 LavenderBlush4 rgb(139,131,134) #8B8386 maroon(X11compliance) rgb(176,48,96) #B03060 HotPink3 rgb(205,96,144) #CD6090 VioletRed3 rgb(205,50,120) #CD3278 VioletRed1 rgb(255,62,150) #FF3E96 VioletRed2 rgb(238,58,140) #EE3A8C VioletRed4 rgb(139,34,82) #8B2252 HotPink2 rgb(238,106,167) #EE6AA7 HotPink1 rgb(255,110,180) #FF6EB4 HotPink4 rgb(139,58,98) #8B3A62 HotPink rgb(255,105,180) #FF69B4 DeepPink rgb(255,20,147) #FF1493 DeepPink1 rgb(255,20,147) #FF1493 DeepPink2 rgb(238,18,137) #EE1289 DeepPink3 rgb(205,16,118) #CD1076 DeepPink4 rgb(139,10,80) #8B0A50 maroon1 rgb(255,52,179) #FF34B3 maroon2 rgb(238,48,167) #EE30A7 maroon3 rgb(205,41,144) #CD2990 maroon4 rgb(139,28,98) #8B1C62 MediumVioletRed rgb(199,21,133) #C71585 VioletRed rgb(208,32,144) #D02090 orchid2 rgb(238,122,233) #EE7AE9 orchid rgb(218,112,214) #DA70D6 orchid1 rgb(255,131,250) #FF83FA orchid3 rgb(205,105,201) #CD69C9 orchid4 rgb(139,71,137) #8B4789 thistle1 rgb(255,225,255) #FFE1FF thistle2 rgb(238,210,238) #EED2EE plum1 rgb(255,187,255) #FFBBFF plum2 rgb(238,174,238) #EEAEEE thistle rgb(216,191,216) #D8BFD8 thistle3 rgb(205,181,205) #CDB5CD plum rgb(221,160,221) #DDA0DD violet rgb(238,130,238) #EE82EE plum3 rgb(205,150,205) #CD96CD thistle4 rgb(139,123,139) #8B7B8B fuchsia rgb(255,0,255) #FF00FF magenta rgb(255,0,255) #FF00FF magenta1 rgb(255,0,255) #FF00FF plum4 rgb(139,102,139) #8B668B magenta2 rgb(238,0,238) #EE00EE magenta3 rgb(205,0,205) #CD00CD DarkMagenta rgb(139,0,139) #8B008B magenta4 rgb(139,0,139) #8B008B purple(SVGcompliance) rgb(128,0,128) #800080 MediumOrchid rgb(186,85,211) #BA55D3 MediumOrchid1 rgb(224,102,255) #E066FF MediumOrchid2 rgb(209,95,238) #D15FEE MediumOrchid3 rgb(180,82,205) #B452CD MediumOrchid4 rgb(122,55,139) #7A378B DarkViolet rgb(148,0,211) #9400D3 DarkOrchid rgb(153,50,204) #9932CC DarkOrchid1 rgb(191,62,255) #BF3EFF DarkOrchid3 rgb(154,50,205) #9A32CD DarkOrchid2 rgb(178,58,238) #B23AEE DarkOrchid4 rgb(104,34,139) #68228B purple(X11compliance) rgb(160,32,240) #A020F0 indigo rgb(75,0,130) #4B0082 BlueViolet rgb(138,43,226) #8A2BE2 purple2 rgb(145,44,238) #912CEE purple3 rgb(125,38,205) #7D26CD purple4 rgb(85,26,139) #551A8B purple1 rgb(155,48,255) #9B30FF MediumPurple rgb(147,112,219) #9370DB MediumPurple1 rgb(171,130,255) #AB82FF MediumPurple2 rgb(159,121,238) #9F79EE MediumPurple3 rgb(137,104,205) #8968CD MediumPurple4 rgb(93,71,139) #5D478B DarkSlateBlue rgb(72,61,139) #483D8B LightSlateBlue rgb(132,112,255) #8470FF MediumSlateBlue rgb(123,104,238) #7B68EE SlateBlue rgb(106,90,205) #6A5ACD SlateBlue1 rgb(131,111,255) #836FFF SlateBlue2 rgb(122,103,238) #7A67EE SlateBlue3 rgb(105,89,205) #6959CD SlateBlue4 rgb(71,60,139) #473C8B GhostWhite rgb(248,248,255) #F8F8FF lavender rgb(230,230,250) #E6E6FA blue rgb(0,0,255) #0000FF blue1 rgb(0,0,255) #0000FF blue2 rgb(0,0,238) #0000EE blue3 rgb(0,0,205) #0000CD MediumBlue rgb(0,0,205) #0000CD blue4 rgb(0,0,139) #00008B DarkBlue rgb(0,0,139) #00008B MidnightBlue rgb(25,25,112) #191970 navy rgb(0,0,128) #000080 NavyBlue rgb(0,0,128) #000080 RoyalBlue rgb(65,105,225) #4169E1 RoyalBlue1 rgb(72,118,255) #4876FF RoyalBlue2 rgb(67,110,238) #436EEE RoyalBlue3 rgb(58,95,205) #3A5FCD RoyalBlue4 rgb(39,64,139) #27408B CornflowerBlue rgb(100,149,237) #6495ED LightSteelBlue rgb(176,196,222) #B0C4DE LightSteelBlue1 rgb(202,225,255) #CAE1FF LightSteelBlue2 rgb(188,210,238) #BCD2EE LightSteelBlue3 rgb(162,181,205) #A2B5CD LightSteelBlue4 rgb(110,123,139) #6E7B8B SlateGray4 rgb(108,123,139) #6C7B8B SlateGray1 rgb(198,226,255) #C6E2FF SlateGray2 rgb(185,211,238) #B9D3EE SlateGray3 rgb(159,182,205) #9FB6CD LightSlateGray rgb(119,136,153) #778899 LightSlateGrey rgb(119,136,153) #778899 SlateGray rgb(112,128,144) #708090 SlateGrey rgb(112,128,144) #708090 DodgerBlue rgb(30,144,255) #1E90FF DodgerBlue1 rgb(30,144,255) #1E90FF DodgerBlue2 rgb(28,134,238) #1C86EE DodgerBlue4 rgb(16,78,139) #104E8B DodgerBlue3 rgb(24,116,205) #1874CD AliceBlue rgb(240,248,255) #F0F8FF SteelBlue4 rgb(54,100,139) #36648B SteelBlue rgb(70,130,180) #4682B4 SteelBlue1 rgb(99,184,255) #63B8FF SteelBlue2 rgb(92,172,238) #5CACEE SteelBlue3 rgb(79,148,205) #4F94CD SkyBlue4 rgb(74,112,139) #4A708B SkyBlue1 rgb(135,206,255) #87CEFF SkyBlue2 rgb(126,192,238) #7EC0EE SkyBlue3 rgb(108,166,205) #6CA6CD LightSkyBlue rgb(135,206,250) #87CEFA LightSkyBlue4 rgb(96,123,139) #607B8B LightSkyBlue1 rgb(176,226,255) #B0E2FF LightSkyBlue2 rgb(164,211,238) #A4D3EE LightSkyBlue3 rgb(141,182,205) #8DB6CD SkyBlue rgb(135,206,235) #87CEEB LightBlue3 rgb(154,192,205) #9AC0CD DeepSkyBlue rgb(0,191,255) #00BFFF DeepSkyBlue1 rgb(0,191,255) #00BFFF DeepSkyBlue2 rgb(0,178,238) #00B2EE DeepSkyBlue4 rgb(0,104,139) #00688B DeepSkyBlue3 rgb(0,154,205) #009ACD LightBlue1 rgb(191,239,255) #BFEFFF LightBlue2 rgb(178,223,238) #B2DFEE LightBlue rgb(173,216,230) #ADD8E6 LightBlue4 rgb(104,131,139) #68838B PowderBlue rgb(176,224,230) #B0E0E6 CadetBlue1 rgb(152,245,255) #98F5FF CadetBlue2 rgb(142,229,238) #8EE5EE CadetBlue3 rgb(122,197,205) #7AC5CD CadetBlue4 rgb(83,134,139) #53868B turquoise1 rgb(0,245,255) #00F5FF turquoise2 rgb(0,229,238) #00E5EE turquoise3 rgb(0,197,205) #00C5CD turquoise4 rgb(0,134,139) #00868B cadetblue rgb(95,158,160) #5F9EA0 CadetBlue rgb(95,158,160) #5F9EA0 DarkTurquoise rgb(0,206,209) #00CED1 azure rgb(240,255,255) #F0FFFF azure1 rgb(240,255,255) #F0FFFF LightCyan rgb(224,255,255) #E0FFFF LightCyan1 rgb(224,255,255) #E0FFFF azure2 rgb(224,238,238) #E0EEEE LightCyan2 rgb(209,238,238) #D1EEEE PaleTurquoise1 rgb(187,255,255) #BBFFFF PaleTurquoise rgb(175,238,238) #AFEEEE PaleTurquoise2 rgb(174,238,238) #AEEEEE DarkSlateGray1 rgb(151,255,255) #97FFFF azure3 rgb(193,205,205) #C1CDCD LightCyan3 rgb(180,205,205) #B4CDCD DarkSlateGray2 rgb(141,238,238) #8DEEEE PaleTurquoise3 rgb(150,205,205) #96CDCD DarkSlateGray3 rgb(121,205,205) #79CDCD azure4 rgb(131,139,139) #838B8B LightCyan4 rgb(122,139,139) #7A8B8B aqua rgb(0,255,255) #00FFFF cyan rgb(0,255,255) #00FFFF cyan1 rgb(0,255,255) #00FFFF PaleTurquoise4 rgb(102,139,139) #668B8B cyan2 rgb(0,238,238) #00EEEE DarkSlateGray4 rgb(82,139,139) #528B8B cyan3 rgb(0,205,205) #00CDCD cyan4 rgb(0,139,139) #008B8B DarkCyan rgb(0,139,139) #008B8B teal rgb(0,128,128) #008080 DarkSlateGray rgb(47,79,79) #2F4F4F DarkSlateGrey rgb(47,79,79) #2F4F4F MediumTurquoise rgb(72,209,204) #48D1CC LightSeaGreen rgb(32,178,170) #20B2AA turquoise rgb(64,224,208) #40E0D0 aquamarine4 rgb(69,139,116) #458B74 aquamarine rgb(127,255,212) #7FFFD4 aquamarine1 rgb(127,255,212) #7FFFD4 aquamarine2 rgb(118,238,198) #76EEC6 aquamarine3 rgb(102,205,170) #66CDAA MediumAquamarine rgb(102,205,170) #66CDAA MediumSpringGreen rgb(0,250,154) #00FA9A MintCream rgb(245,255,250) #F5FFFA SpringGreen rgb(0,255,127) #00FF7F SpringGreen1 rgb(0,255,127) #00FF7F SpringGreen2 rgb(0,238,118) #00EE76 SpringGreen3 rgb(0,205,102) #00CD66 SpringGreen4 rgb(0,139,69) #008B45 MediumSeaGreen rgb(60,179,113) #3CB371 SeaGreen rgb(46,139,87) #2E8B57 SeaGreen3 rgb(67,205,128) #43CD80 SeaGreen1 rgb(84,255,159) #54FF9F SeaGreen4 rgb(46,139,87) #2E8B57 SeaGreen2 rgb(78,238,148) #4EEE94 MediumForestGreen rgb(50,129,75) #32814B honeydew rgb(240,255,240) #F0FFF0 honeydew1 rgb(240,255,240) #F0FFF0 honeydew2 rgb(224,238,224) #E0EEE0 DarkSeaGreen1 rgb(193,255,193) #C1FFC1 DarkSeaGreen2 rgb(180,238,180) #B4EEB4 PaleGreen1 rgb(154,255,154) #9AFF9A PaleGreen rgb(152,251,152) #98FB98 honeydew3 rgb(193,205,193) #C1CDC1 LightGreen rgb(144,238,144) #90EE90 PaleGreen2 rgb(144,238,144) #90EE90 DarkSeaGreen3 rgb(155,205,155) #9BCD9B DarkSeaGreen rgb(143,188,143) #8FBC8F PaleGreen3 rgb(124,205,124) #7CCD7C honeydew4 rgb(131,139,131) #838B83 green1 rgb(0,255,0) #00FF00 lime rgb(0,255,0) #00FF00 LimeGreen rgb(50,205,50) #32CD32 DarkSeaGreen4 rgb(105,139,105) #698B69 green2 rgb(0,238,0) #00EE00 PaleGreen4 rgb(84,139,84) #548B54 green3 rgb(0,205,0) #00CD00 ForestGreen rgb(34,139,34) #228B22 green4 rgb(0,139,0) #008B00 green rgb(0,128,0) #008000 DarkGreen rgb(0,100,0) #006400 LawnGreen rgb(124,252,0) #7CFC00 chartreuse rgb(127,255,0) #7FFF00 chartreuse1 rgb(127,255,0) #7FFF00 chartreuse2 rgb(118,238,0) #76EE00 chartreuse3 rgb(102,205,0) #66CD00 chartreuse4 rgb(69,139,0) #458B00 GreenYellow rgb(173,255,47) #ADFF2F DarkOliveGreen3 rgb(162,205,90) #A2CD5A DarkOliveGreen1 rgb(202,255,112) #CAFF70 DarkOliveGreen2 rgb(188,238,104) #BCEE68 DarkOliveGreen4 rgb(110,139,61) #6E8B3D DarkOliveGreen rgb(85,107,47) #556B2F OliveDrab rgb(107,142,35) #6B8E23 OliveDrab1 rgb(192,255,62) #C0FF3E OliveDrab2 rgb(179,238,58) #B3EE3A OliveDrab3 rgb(154,205,50) #9ACD32 YellowGreen rgb(154,205,50) #9ACD32 OliveDrab4 rgb(105,139,34) #698B22 ivory rgb(255,255,240) #FFFFF0 ivory1 rgb(255,255,240) #FFFFF0 LightYellow rgb(255,255,224) #FFFFE0 LightYellow1 rgb(255,255,224) #FFFFE0 beige rgb(245,245,220) #F5F5DC ivory2 rgb(238,238,224) #EEEEE0 LightGoldenrodYellow rgb(250,250,210) #FAFAD2 LightYellow2 rgb(238,238,209) #EEEED1 ivory3 rgb(205,205,193) #CDCDC1 LightYellow3 rgb(205,205,180) #CDCDB4 ivory4 rgb(139,139,131) #8B8B83 LightYellow4 rgb(139,139,122) #8B8B7A yellow rgb(255,255,0) #FFFF00 yellow1 rgb(255,255,0) #FFFF00 yellow2 rgb(238,238,0) #EEEE00 yellow3 rgb(205,205,0) #CDCD00 yellow4 rgb(139,139,0) #8B8B00 olive rgb(128,128,0) #808000 DarkKhaki rgb(189,183,107) #BDB76B khaki2 rgb(238,230,133) #EEE685 LemonChiffon4 rgb(139,137,112) #8B8970 khaki1 rgb(255,246,143) #FFF68F khaki3 rgb(205,198,115) #CDC673 khaki4 rgb(139,134,78) #8B864E PaleGoldenrod rgb(238,232,170) #EEE8AA LemonChiffon rgb(255,250,205) #FFFACD LemonChiffon1 rgb(255,250,205) #FFFACD khaki rgb(240,230,140) #F0E68C LemonChiffon3 rgb(205,201,165) #CDC9A5 LemonChiffon2 rgb(238,233,191) #EEE9BF MediumGoldenRod rgb(209,193,102) #D1C166 cornsilk4 rgb(139,136,120) #8B8878 gold rgb(255,215,0) #FFD700 gold1 rgb(255,215,0) #FFD700 gold2 rgb(238,201,0) #EEC900 gold3 rgb(205,173,0) #CDAD00 gold4 rgb(139,117,0) #8B7500 LightGoldenrod rgb(238,221,130) #EEDD82 LightGoldenrod4 rgb(139,129,76) #8B814C LightGoldenrod1 rgb(255,236,139) #FFEC8B LightGoldenrod3 rgb(205,190,112) #CDBE70 LightGoldenrod2 rgb(238,220,130) #EEDC82 cornsilk3 rgb(205,200,177) #CDC8B1 cornsilk2 rgb(238,232,205) #EEE8CD cornsilk rgb(255,248,220) #FFF8DC cornsilk1 rgb(255,248,220) #FFF8DC goldenrod rgb(218,165,32) #DAA520 goldenrod1 rgb(255,193,37) #FFC125 goldenrod2 rgb(238,180,34) #EEB422 goldenrod3 rgb(205,155,29) #CD9B1D goldenrod4 rgb(139,105,20) #8B6914 DarkGoldenrod rgb(184,134,11) #B8860B DarkGoldenrod1 rgb(255,185,15) #FFB90F DarkGoldenrod2 rgb(238,173,14) #EEAD0E DarkGoldenrod3 rgb(205,149,12) #CD950C DarkGoldenrod4 rgb(139,101,8) #8B6508 FloralWhite rgb(255,250,240) #FFFAF0 wheat2 rgb(238,216,174) #EED8AE OldLace rgb(253,245,230) #FDF5E6 wheat rgb(245,222,179) #F5DEB3 wheat1 rgb(255,231,186) #FFE7BA wheat3 rgb(205,186,150) #CDBA96 orange rgb(255,165,0) #FFA500 orange1 rgb(255,165,0) #FFA500 orange2 rgb(238,154,0) #EE9A00 orange3 rgb(205,133,0) #CD8500 orange4 rgb(139,90,0) #8B5A00 wheat4 rgb(139,126,102) #8B7E66 moccasin rgb(255,228,181) #FFE4B5 PapayaWhip rgb(255,239,213) #FFEFD5 NavajoWhite3 rgb(205,179,139) #CDB38B BlanchedAlmond rgb(255,235,205) #FFEBCD NavajoWhite rgb(255,222,173) #FFDEAD NavajoWhite1 rgb(255,222,173) #FFDEAD NavajoWhite2 rgb(238,207,161) #EECFA1 NavajoWhite4 rgb(139,121,94) #8B795E AntiqueWhite4 rgb(139,131,120) #8B8378 AntiqueWhite rgb(250,235,215) #FAEBD7 tan rgb(210,180,140) #D2B48C bisque4 rgb(139,125,107) #8B7D6B burlywood rgb(222,184,135) #DEB887 AntiqueWhite2 rgb(238,223,204) #EEDFCC burlywood1 rgb(255,211,155) #FFD39B burlywood3 rgb(205,170,125) #CDAA7D burlywood2 rgb(238,197,145) #EEC591 AntiqueWhite1 rgb(255,239,219) #FFEFDB burlywood4 rgb(139,115,85) #8B7355 AntiqueWhite3 rgb(205,192,176) #CDC0B0 DarkOrange rgb(255,140,0) #FF8C00 bisque2 rgb(238,213,183) #EED5B7 bisque rgb(255,228,196) #FFE4C4 bisque1 rgb(255,228,196) #FFE4C4 bisque3 rgb(205,183,158) #CDB79E DarkOrange1 rgb(255,127,0) #FF7F00 linen rgb(250,240,230) #FAF0E6 DarkOrange2 rgb(238,118,0) #EE7600 DarkOrange3 rgb(205,102,0) #CD6600 DarkOrange4 rgb(139,69,0) #8B4500 peru rgb(205,133,63) #CD853F tan1 rgb(255,165,79) #FFA54F tan2 rgb(238,154,73) #EE9A49 tan3 rgb(205,133,63) #CD853F tan4 rgb(139,90,43) #8B5A2B PeachPuff rgb(255,218,185) #FFDAB9 PeachPuff1 rgb(255,218,185) #FFDAB9 PeachPuff4 rgb(139,119,101) #8B7765 PeachPuff2 rgb(238,203,173) #EECBAD PeachPuff3 rgb(205,175,149) #CDAF95 SandyBrown rgb(244,164,96) #F4A460 seashell4 rgb(139,134,130) #8B8682 seashell2 rgb(238,229,222) #EEE5DE seashell3 rgb(205,197,191) #CDC5BF chocolate rgb(210,105,30) #D2691E chocolate1 rgb(255,127,36) #FF7F24 chocolate2 rgb(238,118,33) #EE7621 chocolate3 rgb(205,102,29) #CD661D chocolate4 rgb(139,69,19) #8B4513 SaddleBrown rgb(139,69,19) #8B4513 seashell rgb(255,245,238) #FFF5EE seashell1 rgb(255,245,238) #FFF5EE sienna4 rgb(139,71,38) #8B4726 sienna rgb(160,82,45) #A0522D sienna1 rgb(255,130,71) #FF8247 sienna2 rgb(238,121,66) #EE7942 sienna3 rgb(205,104,57) #CD6839 LightSalmon3 rgb(205,129,98) #CD8162 LightSalmon rgb(255,160,122) #FFA07A LightSalmon1 rgb(255,160,122) #FFA07A LightSalmon4 rgb(139,87,66) #8B5742 LightSalmon2 rgb(238,149,114) #EE9572 coral rgb(255,127,80) #FF7F50 OrangeRed rgb(255,69,0) #FF4500 OrangeRed1 rgb(255,69,0) #FF4500 OrangeRed2 rgb(238,64,0) #EE4000 OrangeRed3 rgb(205,55,0) #CD3700 OrangeRed4 rgb(139,37,0) #8B2500 DarkSalmon rgb(233,150,122) #E9967A salmon1 rgb(255,140,105) #FF8C69 salmon2 rgb(238,130,98) #EE8262 salmon3 rgb(205,112,84) #CD7054 salmon4 rgb(139,76,57) #8B4C39 coral1 rgb(255,114,86) #FF7256 coral2 rgb(238,106,80) #EE6A50 coral3 rgb(205,91,69) #CD5B45 coral4 rgb(139,62,47) #8B3E2F tomato4 rgb(139,54,38) #8B3626 tomato rgb(255,99,71) #FF6347 tomato1 rgb(255,99,71) #FF6347 tomato2 rgb(238,92,66) #EE5C42 tomato3 rgb(205,79,57) #CD4F39 MistyRose4 rgb(139,125,123) #8B7D7B MistyRose2 rgb(238,213,210) #EED5D2 MistyRose rgb(255,228,225) #FFE4E1 MistyRose1 rgb(255,228,225) #FFE4E1 salmon rgb(250,128,114) #FA8072 MistyRose3 rgb(205,183,181) #CDB7B5 white rgb(255,255,255) #FFFFFF gray100 rgb(255,255,255) #FFFFFF grey100 rgb(255,255,255) #FFFFFF grey100 rgb(255,255,255) #FFFFFF gray99 rgb(252,252,252) #FCFCFC grey99 rgb(252,252,252) #FCFCFC gray98 rgb(250,250,250) #FAFAFA grey98 rgb(250,250,250) #FAFAFA gray97 rgb(247,247,247) #F7F7F7 grey97 rgb(247,247,247) #F7F7F7 gray96 rgb(245,245,245) #F5F5F5 grey96 rgb(245,245,245) #F5F5F5 WhiteSmoke rgb(245,245,245) #F5F5F5 gray95 rgb(242,242,242) #F2F2F2 grey95 rgb(242,242,242) #F2F2F2 gray94 rgb(240,240,240) #F0F0F0 grey94 rgb(240,240,240) #F0F0F0 gray93 rgb(237,237,237) #EDEDED grey93 rgb(237,237,237) #EDEDED gray92 rgb(235,235,235) #EBEBEB grey92 rgb(235,235,235) #EBEBEB gray91 rgb(232,232,232) #E8E8E8 grey91 rgb(232,232,232) #E8E8E8 gray90 rgb(229,229,229) #E5E5E5 grey90 rgb(229,229,229) #E5E5E5 gray89 rgb(227,227,227) #E3E3E3 grey89 rgb(227,227,227) #E3E3E3 gray88 rgb(224,224,224) #E0E0E0 grey88 rgb(224,224,224) #E0E0E0 gray87 rgb(222,222,222) #DEDEDE grey87 rgb(222,222,222) #DEDEDE gainsboro rgb(220,220,220) #DCDCDC gray86 rgb(219,219,219) #DBDBDB grey86 rgb(219,219,219) #DBDBDB gray85 rgb(217,217,217) #D9D9D9 grey85 rgb(217,217,217) #D9D9D9 gray84 rgb(214,214,214) #D6D6D6 grey84 rgb(214,214,214) #D6D6D6 gray83 rgb(212,212,212) #D4D4D4 grey83 rgb(212,212,212) #D4D4D4 LightGray rgb(211,211,211) #D3D3D3 LightGrey rgb(211,211,211) #D3D3D3 gray82 rgb(209,209,209) #D1D1D1 grey82 rgb(209,209,209) #D1D1D1 gray81 rgb(207,207,207) #CFCFCF grey81 rgb(207,207,207) #CFCFCF gray80 rgb(204,204,204) #CCCCCC grey80 rgb(204,204,204) #CCCCCC gray79 rgb(201,201,201) #C9C9C9 grey79 rgb(201,201,201) #C9C9C9 gray78 rgb(199,199,199) #C7C7C7 grey78 rgb(199,199,199) #C7C7C7 gray77 rgb(196,196,196) #C4C4C4 grey77 rgb(196,196,196) #C4C4C4 gray76 rgb(194,194,194) #C2C2C2 grey76 rgb(194,194,194) #C2C2C2 silver rgb(192,192,192) #C0C0C0 gray75 rgb(191,191,191) #BFBFBF grey75 rgb(191,191,191) #BFBFBF gray74 rgb(189,189,189) #BDBDBD grey74 rgb(189,189,189) #BDBDBD gray73 rgb(186,186,186) #BABABA grey73 rgb(186,186,186) #BABABA gray72 rgb(184,184,184) #B8B8B8 grey72 rgb(184,184,184) #B8B8B8 gray71 rgb(181,181,181) #B5B5B5 grey71 rgb(181,181,181) #B5B5B5 gray70 rgb(179,179,179) #B3B3B3 grey70 rgb(179,179,179) #B3B3B3 gray69 rgb(176,176,176) #B0B0B0 grey69 rgb(176,176,176) #B0B0B0 gray68 rgb(173,173,173) #ADADAD grey68 rgb(173,173,173) #ADADAD gray67 rgb(171,171,171) #ABABAB grey67 rgb(171,171,171) #ABABAB DarkGray rgb(169,169,169) #A9A9A9 DarkGrey rgb(169,169,169) #A9A9A9 gray66 rgb(168,168,168) #A8A8A8 grey66 rgb(168,168,168) #A8A8A8 gray65 rgb(166,166,166) #A6A6A6 grey65 rgb(166,166,166) #A6A6A6 gray64 rgb(163,163,163) #A3A3A3 grey64 rgb(163,163,163) #A3A3A3 gray63 rgb(161,161,161) #A1A1A1 grey63 rgb(161,161,161) #A1A1A1 gray62 rgb(158,158,158) #9E9E9E grey62 rgb(158,158,158) #9E9E9E gray61 rgb(156,156,156) #9C9C9C grey61 rgb(156,156,156) #9C9C9C gray60 rgb(153,153,153) #999999 grey60 rgb(153,153,153) #999999 gray59 rgb(150,150,150) #969696 grey59 rgb(150,150,150) #969696 gray58 rgb(148,148,148) #949494 grey58 rgb(148,148,148) #949494 gray57 rgb(145,145,145) #919191 grey57 rgb(145,145,145) #919191 gray56 rgb(143,143,143) #8F8F8F grey56 rgb(143,143,143) #8F8F8F gray55 rgb(140,140,140) #8C8C8C grey55 rgb(140,140,140) #8C8C8C gray54 rgb(138,138,138) #8A8A8A grey54 rgb(138,138,138) #8A8A8A gray53 rgb(135,135,135) #878787 grey53 rgb(135,135,135) #878787 gray52 rgb(133,133,133) #858585 gray51 rgb(130,130,130) #828282 fractal rgb(128,128,128) #808080 gray50 rgb(127,127,127) #7F7F7F gray rgb(126,126,126) #7E7E7E grey49 rgb(125,125,125) #7D7D7D gray47 rgb(120,120,120) #787878 gray46 rgb(117,117,117) #757575 gray45 rgb(115,115,115) #737373 gray44 rgb(112,112,112) #707070 gray43 rgb(110,110,110) #6E6E6E gray42 rgb(107,107,107) #6B6B6B DimGrey rgb(105,105,105) #696969 gray39 rgb(99,99,99) #636363 gray38 rgb(97,97,97) #616161 gray37 rgb(94,94,94) #5E5E5E gray36 rgb(92,92,92) #5C5C5C gray35 rgb(89,89,89) #595959 gray34 rgb(87,87,87) #575757 gray33 rgb(84,84,84) #545454 gray32 rgb(82,82,82) #525252 gray31 rgb(79,79,79) #4F4F4F gray30 rgb(77,77,77) #4D4D4D gray29 rgb(74,74,74) #4A4A4A gray28 rgb(71,71,71) #474747 gray27 rgb(69,69,69) #454545 gray26 rgb(66,66,66) #424242 gray25 rgb(64,64,64) #404040 gray24 rgb(61,61,61) #3D3D3D gray23 rgb(59,59,59) #3B3B3B gray22 rgb(56,56,56) #383838 gray21 rgb(54,54,54) #363636 gray20 rgb(51,51,51) #333333 gray19 rgb(48,48,48) #303030 gray18 rgb(46,46,46) #2E2E2E gray17 rgb(43,43,43) #2B2B2B gray16 rgb(41,41,41) #292929 gray15 rgb(38,38,38) #262626 gray14 rgb(36,36,36) #242424 gray13 rgb(33,33,33) #212121 gray12 rgb(31,31,31) #1F1F1F gray11 rgb(28,28,28) #1C1C1C gray10 rgb(26,26,26) #1A1A1A gray9 rgb(23,23,23) #171717 gray8 rgb(20,20,20) #141414 gray7 rgb(18,18,18) #121212 gray6 rgb(15,15,15) #0F0F0F gray5 rgb(13,13,13) #0D0D0D gray4 rgb(10,10,10) #0A0A0A gray3 rgb(8,8,8) #080808 gray2 rgb(5,5,5) #050505 gray1 rgb(3,3,3) #030303 black rgb(0,0,0) #000000 gray0 rgb(0,0,0) #000000 opaque rgb(0,0,0) #000000 none rgba(0,0,0,0.0) #00000000 transparent rgba(0,0,0,0.0) #00000000 sips (Mac) Usage: sips [flags] inputFile [--out outputFile] Image modification flags: Flag Meaning -s key value Set the value for a key (see table below for the available keys and acceptable values). -r degreesCW Rotate an image several degrees clockwise. -f option Flip the image using one of the following two options: horizontal or vertical. -c pixelsH pixelsW Crop image to fit specified size. pixelsH indicates the new height in number of pixels, pixelsW indicates the new width in number of pixels. -z pixelsH pixelsW Resample image at specified size. Image aspect ratio may be altered. pixelsH indicate the new height in number of pixels, pixelsW indicate the new width in number of pixels. -Z pixelsWH Resample image so height and width aren't greater than specified. --resampleWidth pixelsW Resample image to specified width. pixelsW indicate the new width in number of pixels. --resampleHeight pixelsH Resample image to specified height. pixelsH indicate the new height in number of pixels. -o Optimize color for sharing. -p pixelsH pixelsW Add padding to the image. Use --padColor hexcolor to select the padding color as hexadecimal number. If you want to modify one image to match the properties of another image (for example have one image match the height of another image), you can use the flag -g key or --getProperty key on the image that you want to match. Where key is one of the following properties: Profile property keys Usage dpiHeight Height in dpi (printer dots per inch). dpiWidth Width in dpi (printer dots per inch). pixelHeight Height in number of pixels. pixelWidth Width in number of pixels. format Image format. Acceptable values for this key: jpeg , tiff , png , gif , jp2 , pict , bmp , qtif , psd , sgi , tga , pdf . formatOptions Quality of the new image. Acceptable values for this key: low , normal , high , best , or some percentage. samplesPerPixel Samples per pixel. bitsPerSample Bits per sample. software Software use to create the image. description Description. copyright Copyright. version Version. platform Platform where file was created. quality Acceptable values for this key: normal, draft, best. renderingIntent Acceptable values for this key: perceptual, relative, saturation, absolute. creator Creator of the file. For the examples below I will be using the following image, taken from the following article, which I published long time ago: link to article . Convert AutismArticle1.png to pdf. $ sips -s format pdf AutismArticle1.png --out AutismArticle1.pdf /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.pdf Rotate AutismArticle1.png 45 degrees clock-wise. $ sips -r 45 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Rotate AutismArticle1.png 45 degrees counter-clock-wise. $ sips -r -45 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test2.png Result image: Flip AutismArticle1.png horizontally. $ sips -f horizontal AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Flip AutismArticle1.png vertically. $ sips -f vertical AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Crop AutismArticle1.png to fit a new size that be 1/4 of its original height and 1/4 of its original weight: The first step is to obtain the current width and height using sips with the flags --getProperty pixelWidth and --getProperty pixelHeight . Then, divide the two numbers by four. And finally use sips with the -c flag to crop the file. $ sips --getProperty pixelHeight AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png pixelHeight: 440 $ sips --getProperty pixelWidth AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png pixelWidth: 727 $ echo \"440/4\" | bc -l 110.00000000000000000000 $ echo \"727/4\" | bc -l 181.75000000000000000000 $ sips -c 110 181 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Resample image to 110x181: $ sips -z 110 181 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png $ sips --getProperty pixelHeight test.png /Users/monica/Desktop/Backup/images_presentations/test.png pixelHeight: 110 $ sips --getProperty pixelWidth test.png /Users/monica/Desktop/Backup/images_presentations/test.png pixelWidth: 181 Result image:","title":"Image files"},{"location":"img_files/#manipulating-image-files","text":"","title":"Manipulating image files"},{"location":"img_files/#imagemagick-linux-mac","text":"","title":"ImageMagick (linux, Mac)"},{"location":"img_files/#installation","text":"Go to the ImageMagic installation page for detailed instructions for different operating systems.","title":"Installation"},{"location":"img_files/#utilities","text":"ImageMagick has a list of utilities that can be used for different purposes. The following table presents a summary of those. Then, I will show some examples for each of these utilities. These examples will help you better understand how to use them. When specifying a color in any ImageMagick command, you can use the name of any recognized color , the RGB value, or the Hex value. When specifying a shape to draw on an image, you can use any of the valid shapes . Utility Use Syntax Links magick This command now replaces convert , which is deprecated. Change image format, blur, crop, draw on, flip, merge, resample, and more. Writes output on a new file. magick [input-options] input-file(s) [output-options] output-file Man page , Documentation identify Obtain information about an image. identify [options] input-file Man page , Documentation mogrify Resize an image, blur, crop, draw on, flip, merge, resample, and more. Re-writes original file. mogrify [options] input-file Man page , Documentation composite Overlaps one image over another. composite [ options ... ] change-file base-file [ mask-file ] output-image Man page , Documentation montage Combines different images, adds border, frame, and much more. montage input-file[s] [options] output-file Man page , Documentation compare Compare two images. compare input-file input-file [options] output-file Man page , Documentation stream Writes the pixel components of an img a row at a time into different storage formats. compare input-file input-file [options] output-file Man page , Documentation display Displays an image or image sequence. display [options] input-file Man page , Documentation animate Animates an image sequence. animate [options] input-file Man page , Documentation import Saves any visible window as an img file. Captures a single window, the entire screen, or any rectangular portion of the screen. import [options] output-file Man page , Documentation conjure Interprets and executes scripts written in the Magick Scripting Language (MSL). conjure [options] script.msl Man page , Documentation","title":"Utilities"},{"location":"img_files/#examples","text":"In the following examples we will use this image:","title":"Examples"},{"location":"img_files/#magick","text":"Syntax: magick [input-option] input-file [output-option] output-file Changing the color of pixels: In the following example we are replacing all pixels that have a distance of at most 50%, 60% and 100% from 255 in the blue value of their RGB: magick grandma.jpg -fuzz 50% -fill \"red\" -opaque \"blue\" grandma_50.jpg magick grandma.jpg -fuzz 60% -fill \"red\" -opaque \"blue\" grandma_60.jpg magick grandma.jpg -fuzz 100% -fill \"red\" -opaque \"blue\" grandma_100.jpg Meaning of used options: fuzz : Distance from 255 in those pixels to be matched. 50% means any pixel with blue value between 127.5 (50% of 255) and 255. 60% means any pixel with blue value between 102 and 255. 60% of 255 is 153, and 255-153=102. Any pixel with blue value within this range will be at most 60% away from being 100% blue. 100% means any pixel with blue value at most 100% away from being 100% blue, this includes all pixels in the image. opaque : Color to be replaced. See the list of recognized colors . Output with 50% of fuzz: Output with 60% of fuzz: Output with 100% of fuzz: You can also change the color of pixels in a specific area: magick grandma.jpg -fill \"rgb(255,250,250)\" -draw \"rectangle 0,300 200,350\" grandma_rect.jpg Meaning of used options: fill : Color to fill the form. See the list of recognized colors . draw : Shape to draw. See list of valid shapes and their parameters . Output: Add text over the rectangle drawn on the image above: magick grandma_rect.jpg -font helvetica -fill black -pointsize 15 -draw \"text 0,315 'Grandma\\nand\\nbaby'\" grandma_rect_txt.png Meaning of used options: font : Font for the text. To see the list of all available fonts type magick -list font . fill : Color to fill the form, in this case the text. See the list of recognized colors . pointsize : Text size. draw : Shape to draw. See list of valid shapes and their parameters . Output: Concatenate images horizontally: In the following example I will concatenate some images ( grandma.jpg grandma_50.jpg grandma_100.jpg ) horizontally, add a border, and flip the image along the horizontal axis. magick grandma.jpg grandma_50.jpg grandma_100.jpg +append -resize x300 -bordercolor black -border 10x15 -flip horizontal.png Meaning of used options: resize : Force the output file to have a height of 300 pixels. If the input images have different heights, then this parameter is recommended. Otherwise, the output will have the same height as the input files if this parameter is not used. bordercolor : Color of the border. See the list of recognized colors . border : Add a border with the specified thickness. In this case we are adding a border with a thickness of 10 pixels on the left and right and 15 pixels on the top and bottom. flip : I'm flipping the output image along the horizontal axis . To flip the image along the vertical axis, use -flop . Make sure to insert the flip flag after +append to apply the flip to the output instead of any of the input files. See example below on how to apply flip or flop to the input instead of output files. Output: Concatenate images vertically: In the following example I will concatenate some images ( grandma.jpg and grandma_50.jpg ) horizontally. Before the concatenation, I will flip the first input file along the vertical axis and transform the color space to Gray. magick grandma.jpg -colorspace Gray -flop grandma_50.jpg -append -resize 300x vertical.png Meaning of used options: colorspace : Color space to apply to the input image. It will apply to any input image specified before the flag, in this case grandma.jpg . If we wanted the whole output file to be on Gray scale, we would add the flag at the end of all input images. Available color spaces: sRGB , RGB , Gray , HSV , HSB , HSL , LAB , LCH , CMYK , XYZ , YUV , YCbCr , AdobeRGB , plus others. flop : I'm flipping the input image (grandma.jpg) along the vertical axis . To flip the image along the horizontal axis, use flip . resize : Force the output file to have a width of 300 pixels. If the input images have different widths, then this parameter is recommended. Otherwise, the output will have the same width as the input files if this parameter is not used. Output: Detect edges: In the following example I will detect edges in the image generated in the example above using two methods: the standard edge detection with the -edge flag, and the Canny Edge detection with smoothing using -canny . -canny is more sophisticated and allows for modifying the radius, sigma and threshold for filtering out edges. magick vertical.png -edge 2 edges.png magick vertical.png -canny 0x1+10%+30% edges2.png Meaning of used options: -edge 2 : Apply an edge of radius 2. To make the edges thicker, increment the value of 2 , or to make them thinner, give a value of 1 . -canny 0x1+10%+30% : Apply Canny Edge Detection with smoothing. The arguments here set the radius to 0 (auto-determined) and sigma to 1. Increase sigma for more smoothing. 10% and 30% are the lower and upper percentage thresholds for edge detection. Play around with these values to filter out weaker edges and highlight more important ones. Increasing the upper percentage will remove more edges. Output using -edge : Output using -canny :","title":"magick"},{"location":"img_files/#identify","text":"","title":"identify"},{"location":"img_files/#mogrify","text":"","title":"mogrify"},{"location":"img_files/#composite","text":"","title":"composite"},{"location":"img_files/#montage","text":"","title":"montage"},{"location":"img_files/#compare","text":"","title":"compare"},{"location":"img_files/#stream","text":"","title":"stream"},{"location":"img_files/#display","text":"","title":"display"},{"location":"img_files/#animate","text":"","title":"animate"},{"location":"img_files/#import","text":"","title":"import"},{"location":"img_files/#conjure","text":"","title":"conjure"},{"location":"img_files/#imagemagick-shapes","text":"Shape Syntax Notes Point point x,y Specified by an ordered pair of integer coordinates. Line line x0,y0 x1,y1 Requires a start and end point. Rectangle rectangle x0,y0 x1,y1 Specified by the pair of points at the upper left and lower right corners. Round rectangle roundRectangle x0,y0, x1,y1 wc,hc Takes same corner points as rectangle , followed by the width and height of the rounded corners to be removed. Arc arc x0,y0 x1,y1 a0,a1 Requires two corners used to create a rectangle , followed by the start and end angles of the arc in degrees. Ellipse ellipse x0,y0 rx,ry a0,a1 Requires the center point, the horizontal and vertical radius, and the start and end angles in degrees. Circle circle x0,y0 x1,y1 Give the center and any point on the perimeter. Can make a disk (filled) or circle (unfilled). Polyline polyline x0,y0 ... xn,yn Requires three or more points to define their perimeters. This is simply a polygon in which the final point is not stroked to the start point. Polygon polygon x0,y0 ... xn,yn Requires three or more points to define their perimeters. Bezier bezier x0,y0 ... xn,yn Creates a spline curve and requires three or points to define its shape. Path path specification represents an outline of an object, defined in terms of moveto (set a new current point), lineto (draw a straight line), curveto (draw a Bezier curve), arc (elliptical or circular arc) and closepath (close the current shape by drawing a line to the last moveto ) elements. Image image operator x0,y0 w,h filename Used to composite an image with another image. Text text x,y text_to_display Add text in coordinates x,y of image.","title":"ImageMagick shapes"},{"location":"img_files/#imagemagick-color-list","text":"Color name RGB Hex snow1 rgb(255,250,250) #FFFAFA snow2 rgb(238,233,233) #EEE9E9 RosyBrown1 rgb(255,193,193) #FFC1C1 RosyBrown2 rgb(238,180,180) #EEB4B4 snow3 rgb(205,201,201) #CDC9C9 LightCoral rgb(240,128,128) #F08080 IndianRed1 rgb(255,106,106) #FF6A6A RosyBrown3 rgb(205,155,155) #CD9B9B IndianRed2 rgb(238,99,99) #EE6363 RosyBrown rgb(188,143,143) #BC8F8F brown1 rgb(255,64,64) #FF4040 firebrick1 rgb(255,48,48) #FF3030 brown2 rgb(238,59,59) #EE3B3B IndianRed rgb(205,92,92) #CD5C5C IndianRed3 rgb(205,85,85) #CD5555 firebrick2 rgb(238,44,44) #EE2C2C snow4 rgb(139,137,137) #8B8989 brown3 rgb(205,51,51) #CD3333 red rgb(255,0,0) #FF0000 red1 rgb(255,0,0) #FF0000 RosyBrown4 rgb(139,105,105) #8B6969 firebrick3 rgb(205,38,38) #CD2626 red2 rgb(238,0,0) #EE0000 firebrick rgb(178,34,34) #B22222 brown rgb(165,42,42) #A52A2A red3 rgb(205,0,0) #CD0000 IndianRed4 rgb(139,58,58) #8B3A3A brown4 rgb(139,35,35) #8B2323 firebrick4 rgb(139,26,26) #8B1A1A DarkRed rgb(139,0,0) #8B0000 red4 rgb(139,0,0) #8B0000 maroon(SVGcompliance) rgb(128,0,0) #800000 LightPink1 rgb(255,174,185) #FFAEB9 LightPink3 rgb(205,140,149) #CD8C95 LightPink4 rgb(139,95,101) #8B5F65 LightPink2 rgb(238,162,173) #EEA2AD LightPink rgb(255,182,193) #FFB6C1 pink rgb(255,192,203) #FFC0CB crimson rgb(220,20,60) #DC143C pink1 rgb(255,181,197) #FFB5C5 pink2 rgb(238,169,184) #EEA9B8 pink3 rgb(205,145,158) #CD919E pink4 rgb(139,99,108) #8B636C PaleVioletRed4 rgb(139,71,93) #8B475D PaleVioletRed rgb(219,112,147) #DB7093 PaleVioletRed2 rgb(238,121,159) #EE799F PaleVioletRed1 rgb(255,130,171) #FF82AB PaleVioletRed3 rgb(205,104,137) #CD6889 LavenderBlush rgb(255,240,245) #FFF0F5 LavenderBlush1 rgb(255,240,245) #FFF0F5 LavenderBlush3 rgb(205,193,197) #CDC1C5 LavenderBlush2 rgb(238,224,229) #EEE0E5 LavenderBlush4 rgb(139,131,134) #8B8386 maroon(X11compliance) rgb(176,48,96) #B03060 HotPink3 rgb(205,96,144) #CD6090 VioletRed3 rgb(205,50,120) #CD3278 VioletRed1 rgb(255,62,150) #FF3E96 VioletRed2 rgb(238,58,140) #EE3A8C VioletRed4 rgb(139,34,82) #8B2252 HotPink2 rgb(238,106,167) #EE6AA7 HotPink1 rgb(255,110,180) #FF6EB4 HotPink4 rgb(139,58,98) #8B3A62 HotPink rgb(255,105,180) #FF69B4 DeepPink rgb(255,20,147) #FF1493 DeepPink1 rgb(255,20,147) #FF1493 DeepPink2 rgb(238,18,137) #EE1289 DeepPink3 rgb(205,16,118) #CD1076 DeepPink4 rgb(139,10,80) #8B0A50 maroon1 rgb(255,52,179) #FF34B3 maroon2 rgb(238,48,167) #EE30A7 maroon3 rgb(205,41,144) #CD2990 maroon4 rgb(139,28,98) #8B1C62 MediumVioletRed rgb(199,21,133) #C71585 VioletRed rgb(208,32,144) #D02090 orchid2 rgb(238,122,233) #EE7AE9 orchid rgb(218,112,214) #DA70D6 orchid1 rgb(255,131,250) #FF83FA orchid3 rgb(205,105,201) #CD69C9 orchid4 rgb(139,71,137) #8B4789 thistle1 rgb(255,225,255) #FFE1FF thistle2 rgb(238,210,238) #EED2EE plum1 rgb(255,187,255) #FFBBFF plum2 rgb(238,174,238) #EEAEEE thistle rgb(216,191,216) #D8BFD8 thistle3 rgb(205,181,205) #CDB5CD plum rgb(221,160,221) #DDA0DD violet rgb(238,130,238) #EE82EE plum3 rgb(205,150,205) #CD96CD thistle4 rgb(139,123,139) #8B7B8B fuchsia rgb(255,0,255) #FF00FF magenta rgb(255,0,255) #FF00FF magenta1 rgb(255,0,255) #FF00FF plum4 rgb(139,102,139) #8B668B magenta2 rgb(238,0,238) #EE00EE magenta3 rgb(205,0,205) #CD00CD DarkMagenta rgb(139,0,139) #8B008B magenta4 rgb(139,0,139) #8B008B purple(SVGcompliance) rgb(128,0,128) #800080 MediumOrchid rgb(186,85,211) #BA55D3 MediumOrchid1 rgb(224,102,255) #E066FF MediumOrchid2 rgb(209,95,238) #D15FEE MediumOrchid3 rgb(180,82,205) #B452CD MediumOrchid4 rgb(122,55,139) #7A378B DarkViolet rgb(148,0,211) #9400D3 DarkOrchid rgb(153,50,204) #9932CC DarkOrchid1 rgb(191,62,255) #BF3EFF DarkOrchid3 rgb(154,50,205) #9A32CD DarkOrchid2 rgb(178,58,238) #B23AEE DarkOrchid4 rgb(104,34,139) #68228B purple(X11compliance) rgb(160,32,240) #A020F0 indigo rgb(75,0,130) #4B0082 BlueViolet rgb(138,43,226) #8A2BE2 purple2 rgb(145,44,238) #912CEE purple3 rgb(125,38,205) #7D26CD purple4 rgb(85,26,139) #551A8B purple1 rgb(155,48,255) #9B30FF MediumPurple rgb(147,112,219) #9370DB MediumPurple1 rgb(171,130,255) #AB82FF MediumPurple2 rgb(159,121,238) #9F79EE MediumPurple3 rgb(137,104,205) #8968CD MediumPurple4 rgb(93,71,139) #5D478B DarkSlateBlue rgb(72,61,139) #483D8B LightSlateBlue rgb(132,112,255) #8470FF MediumSlateBlue rgb(123,104,238) #7B68EE SlateBlue rgb(106,90,205) #6A5ACD SlateBlue1 rgb(131,111,255) #836FFF SlateBlue2 rgb(122,103,238) #7A67EE SlateBlue3 rgb(105,89,205) #6959CD SlateBlue4 rgb(71,60,139) #473C8B GhostWhite rgb(248,248,255) #F8F8FF lavender rgb(230,230,250) #E6E6FA blue rgb(0,0,255) #0000FF blue1 rgb(0,0,255) #0000FF blue2 rgb(0,0,238) #0000EE blue3 rgb(0,0,205) #0000CD MediumBlue rgb(0,0,205) #0000CD blue4 rgb(0,0,139) #00008B DarkBlue rgb(0,0,139) #00008B MidnightBlue rgb(25,25,112) #191970 navy rgb(0,0,128) #000080 NavyBlue rgb(0,0,128) #000080 RoyalBlue rgb(65,105,225) #4169E1 RoyalBlue1 rgb(72,118,255) #4876FF RoyalBlue2 rgb(67,110,238) #436EEE RoyalBlue3 rgb(58,95,205) #3A5FCD RoyalBlue4 rgb(39,64,139) #27408B CornflowerBlue rgb(100,149,237) #6495ED LightSteelBlue rgb(176,196,222) #B0C4DE LightSteelBlue1 rgb(202,225,255) #CAE1FF LightSteelBlue2 rgb(188,210,238) #BCD2EE LightSteelBlue3 rgb(162,181,205) #A2B5CD LightSteelBlue4 rgb(110,123,139) #6E7B8B SlateGray4 rgb(108,123,139) #6C7B8B SlateGray1 rgb(198,226,255) #C6E2FF SlateGray2 rgb(185,211,238) #B9D3EE SlateGray3 rgb(159,182,205) #9FB6CD LightSlateGray rgb(119,136,153) #778899 LightSlateGrey rgb(119,136,153) #778899 SlateGray rgb(112,128,144) #708090 SlateGrey rgb(112,128,144) #708090 DodgerBlue rgb(30,144,255) #1E90FF DodgerBlue1 rgb(30,144,255) #1E90FF DodgerBlue2 rgb(28,134,238) #1C86EE DodgerBlue4 rgb(16,78,139) #104E8B DodgerBlue3 rgb(24,116,205) #1874CD AliceBlue rgb(240,248,255) #F0F8FF SteelBlue4 rgb(54,100,139) #36648B SteelBlue rgb(70,130,180) #4682B4 SteelBlue1 rgb(99,184,255) #63B8FF SteelBlue2 rgb(92,172,238) #5CACEE SteelBlue3 rgb(79,148,205) #4F94CD SkyBlue4 rgb(74,112,139) #4A708B SkyBlue1 rgb(135,206,255) #87CEFF SkyBlue2 rgb(126,192,238) #7EC0EE SkyBlue3 rgb(108,166,205) #6CA6CD LightSkyBlue rgb(135,206,250) #87CEFA LightSkyBlue4 rgb(96,123,139) #607B8B LightSkyBlue1 rgb(176,226,255) #B0E2FF LightSkyBlue2 rgb(164,211,238) #A4D3EE LightSkyBlue3 rgb(141,182,205) #8DB6CD SkyBlue rgb(135,206,235) #87CEEB LightBlue3 rgb(154,192,205) #9AC0CD DeepSkyBlue rgb(0,191,255) #00BFFF DeepSkyBlue1 rgb(0,191,255) #00BFFF DeepSkyBlue2 rgb(0,178,238) #00B2EE DeepSkyBlue4 rgb(0,104,139) #00688B DeepSkyBlue3 rgb(0,154,205) #009ACD LightBlue1 rgb(191,239,255) #BFEFFF LightBlue2 rgb(178,223,238) #B2DFEE LightBlue rgb(173,216,230) #ADD8E6 LightBlue4 rgb(104,131,139) #68838B PowderBlue rgb(176,224,230) #B0E0E6 CadetBlue1 rgb(152,245,255) #98F5FF CadetBlue2 rgb(142,229,238) #8EE5EE CadetBlue3 rgb(122,197,205) #7AC5CD CadetBlue4 rgb(83,134,139) #53868B turquoise1 rgb(0,245,255) #00F5FF turquoise2 rgb(0,229,238) #00E5EE turquoise3 rgb(0,197,205) #00C5CD turquoise4 rgb(0,134,139) #00868B cadetblue rgb(95,158,160) #5F9EA0 CadetBlue rgb(95,158,160) #5F9EA0 DarkTurquoise rgb(0,206,209) #00CED1 azure rgb(240,255,255) #F0FFFF azure1 rgb(240,255,255) #F0FFFF LightCyan rgb(224,255,255) #E0FFFF LightCyan1 rgb(224,255,255) #E0FFFF azure2 rgb(224,238,238) #E0EEEE LightCyan2 rgb(209,238,238) #D1EEEE PaleTurquoise1 rgb(187,255,255) #BBFFFF PaleTurquoise rgb(175,238,238) #AFEEEE PaleTurquoise2 rgb(174,238,238) #AEEEEE DarkSlateGray1 rgb(151,255,255) #97FFFF azure3 rgb(193,205,205) #C1CDCD LightCyan3 rgb(180,205,205) #B4CDCD DarkSlateGray2 rgb(141,238,238) #8DEEEE PaleTurquoise3 rgb(150,205,205) #96CDCD DarkSlateGray3 rgb(121,205,205) #79CDCD azure4 rgb(131,139,139) #838B8B LightCyan4 rgb(122,139,139) #7A8B8B aqua rgb(0,255,255) #00FFFF cyan rgb(0,255,255) #00FFFF cyan1 rgb(0,255,255) #00FFFF PaleTurquoise4 rgb(102,139,139) #668B8B cyan2 rgb(0,238,238) #00EEEE DarkSlateGray4 rgb(82,139,139) #528B8B cyan3 rgb(0,205,205) #00CDCD cyan4 rgb(0,139,139) #008B8B DarkCyan rgb(0,139,139) #008B8B teal rgb(0,128,128) #008080 DarkSlateGray rgb(47,79,79) #2F4F4F DarkSlateGrey rgb(47,79,79) #2F4F4F MediumTurquoise rgb(72,209,204) #48D1CC LightSeaGreen rgb(32,178,170) #20B2AA turquoise rgb(64,224,208) #40E0D0 aquamarine4 rgb(69,139,116) #458B74 aquamarine rgb(127,255,212) #7FFFD4 aquamarine1 rgb(127,255,212) #7FFFD4 aquamarine2 rgb(118,238,198) #76EEC6 aquamarine3 rgb(102,205,170) #66CDAA MediumAquamarine rgb(102,205,170) #66CDAA MediumSpringGreen rgb(0,250,154) #00FA9A MintCream rgb(245,255,250) #F5FFFA SpringGreen rgb(0,255,127) #00FF7F SpringGreen1 rgb(0,255,127) #00FF7F SpringGreen2 rgb(0,238,118) #00EE76 SpringGreen3 rgb(0,205,102) #00CD66 SpringGreen4 rgb(0,139,69) #008B45 MediumSeaGreen rgb(60,179,113) #3CB371 SeaGreen rgb(46,139,87) #2E8B57 SeaGreen3 rgb(67,205,128) #43CD80 SeaGreen1 rgb(84,255,159) #54FF9F SeaGreen4 rgb(46,139,87) #2E8B57 SeaGreen2 rgb(78,238,148) #4EEE94 MediumForestGreen rgb(50,129,75) #32814B honeydew rgb(240,255,240) #F0FFF0 honeydew1 rgb(240,255,240) #F0FFF0 honeydew2 rgb(224,238,224) #E0EEE0 DarkSeaGreen1 rgb(193,255,193) #C1FFC1 DarkSeaGreen2 rgb(180,238,180) #B4EEB4 PaleGreen1 rgb(154,255,154) #9AFF9A PaleGreen rgb(152,251,152) #98FB98 honeydew3 rgb(193,205,193) #C1CDC1 LightGreen rgb(144,238,144) #90EE90 PaleGreen2 rgb(144,238,144) #90EE90 DarkSeaGreen3 rgb(155,205,155) #9BCD9B DarkSeaGreen rgb(143,188,143) #8FBC8F PaleGreen3 rgb(124,205,124) #7CCD7C honeydew4 rgb(131,139,131) #838B83 green1 rgb(0,255,0) #00FF00 lime rgb(0,255,0) #00FF00 LimeGreen rgb(50,205,50) #32CD32 DarkSeaGreen4 rgb(105,139,105) #698B69 green2 rgb(0,238,0) #00EE00 PaleGreen4 rgb(84,139,84) #548B54 green3 rgb(0,205,0) #00CD00 ForestGreen rgb(34,139,34) #228B22 green4 rgb(0,139,0) #008B00 green rgb(0,128,0) #008000 DarkGreen rgb(0,100,0) #006400 LawnGreen rgb(124,252,0) #7CFC00 chartreuse rgb(127,255,0) #7FFF00 chartreuse1 rgb(127,255,0) #7FFF00 chartreuse2 rgb(118,238,0) #76EE00 chartreuse3 rgb(102,205,0) #66CD00 chartreuse4 rgb(69,139,0) #458B00 GreenYellow rgb(173,255,47) #ADFF2F DarkOliveGreen3 rgb(162,205,90) #A2CD5A DarkOliveGreen1 rgb(202,255,112) #CAFF70 DarkOliveGreen2 rgb(188,238,104) #BCEE68 DarkOliveGreen4 rgb(110,139,61) #6E8B3D DarkOliveGreen rgb(85,107,47) #556B2F OliveDrab rgb(107,142,35) #6B8E23 OliveDrab1 rgb(192,255,62) #C0FF3E OliveDrab2 rgb(179,238,58) #B3EE3A OliveDrab3 rgb(154,205,50) #9ACD32 YellowGreen rgb(154,205,50) #9ACD32 OliveDrab4 rgb(105,139,34) #698B22 ivory rgb(255,255,240) #FFFFF0 ivory1 rgb(255,255,240) #FFFFF0 LightYellow rgb(255,255,224) #FFFFE0 LightYellow1 rgb(255,255,224) #FFFFE0 beige rgb(245,245,220) #F5F5DC ivory2 rgb(238,238,224) #EEEEE0 LightGoldenrodYellow rgb(250,250,210) #FAFAD2 LightYellow2 rgb(238,238,209) #EEEED1 ivory3 rgb(205,205,193) #CDCDC1 LightYellow3 rgb(205,205,180) #CDCDB4 ivory4 rgb(139,139,131) #8B8B83 LightYellow4 rgb(139,139,122) #8B8B7A yellow rgb(255,255,0) #FFFF00 yellow1 rgb(255,255,0) #FFFF00 yellow2 rgb(238,238,0) #EEEE00 yellow3 rgb(205,205,0) #CDCD00 yellow4 rgb(139,139,0) #8B8B00 olive rgb(128,128,0) #808000 DarkKhaki rgb(189,183,107) #BDB76B khaki2 rgb(238,230,133) #EEE685 LemonChiffon4 rgb(139,137,112) #8B8970 khaki1 rgb(255,246,143) #FFF68F khaki3 rgb(205,198,115) #CDC673 khaki4 rgb(139,134,78) #8B864E PaleGoldenrod rgb(238,232,170) #EEE8AA LemonChiffon rgb(255,250,205) #FFFACD LemonChiffon1 rgb(255,250,205) #FFFACD khaki rgb(240,230,140) #F0E68C LemonChiffon3 rgb(205,201,165) #CDC9A5 LemonChiffon2 rgb(238,233,191) #EEE9BF MediumGoldenRod rgb(209,193,102) #D1C166 cornsilk4 rgb(139,136,120) #8B8878 gold rgb(255,215,0) #FFD700 gold1 rgb(255,215,0) #FFD700 gold2 rgb(238,201,0) #EEC900 gold3 rgb(205,173,0) #CDAD00 gold4 rgb(139,117,0) #8B7500 LightGoldenrod rgb(238,221,130) #EEDD82 LightGoldenrod4 rgb(139,129,76) #8B814C LightGoldenrod1 rgb(255,236,139) #FFEC8B LightGoldenrod3 rgb(205,190,112) #CDBE70 LightGoldenrod2 rgb(238,220,130) #EEDC82 cornsilk3 rgb(205,200,177) #CDC8B1 cornsilk2 rgb(238,232,205) #EEE8CD cornsilk rgb(255,248,220) #FFF8DC cornsilk1 rgb(255,248,220) #FFF8DC goldenrod rgb(218,165,32) #DAA520 goldenrod1 rgb(255,193,37) #FFC125 goldenrod2 rgb(238,180,34) #EEB422 goldenrod3 rgb(205,155,29) #CD9B1D goldenrod4 rgb(139,105,20) #8B6914 DarkGoldenrod rgb(184,134,11) #B8860B DarkGoldenrod1 rgb(255,185,15) #FFB90F DarkGoldenrod2 rgb(238,173,14) #EEAD0E DarkGoldenrod3 rgb(205,149,12) #CD950C DarkGoldenrod4 rgb(139,101,8) #8B6508 FloralWhite rgb(255,250,240) #FFFAF0 wheat2 rgb(238,216,174) #EED8AE OldLace rgb(253,245,230) #FDF5E6 wheat rgb(245,222,179) #F5DEB3 wheat1 rgb(255,231,186) #FFE7BA wheat3 rgb(205,186,150) #CDBA96 orange rgb(255,165,0) #FFA500 orange1 rgb(255,165,0) #FFA500 orange2 rgb(238,154,0) #EE9A00 orange3 rgb(205,133,0) #CD8500 orange4 rgb(139,90,0) #8B5A00 wheat4 rgb(139,126,102) #8B7E66 moccasin rgb(255,228,181) #FFE4B5 PapayaWhip rgb(255,239,213) #FFEFD5 NavajoWhite3 rgb(205,179,139) #CDB38B BlanchedAlmond rgb(255,235,205) #FFEBCD NavajoWhite rgb(255,222,173) #FFDEAD NavajoWhite1 rgb(255,222,173) #FFDEAD NavajoWhite2 rgb(238,207,161) #EECFA1 NavajoWhite4 rgb(139,121,94) #8B795E AntiqueWhite4 rgb(139,131,120) #8B8378 AntiqueWhite rgb(250,235,215) #FAEBD7 tan rgb(210,180,140) #D2B48C bisque4 rgb(139,125,107) #8B7D6B burlywood rgb(222,184,135) #DEB887 AntiqueWhite2 rgb(238,223,204) #EEDFCC burlywood1 rgb(255,211,155) #FFD39B burlywood3 rgb(205,170,125) #CDAA7D burlywood2 rgb(238,197,145) #EEC591 AntiqueWhite1 rgb(255,239,219) #FFEFDB burlywood4 rgb(139,115,85) #8B7355 AntiqueWhite3 rgb(205,192,176) #CDC0B0 DarkOrange rgb(255,140,0) #FF8C00 bisque2 rgb(238,213,183) #EED5B7 bisque rgb(255,228,196) #FFE4C4 bisque1 rgb(255,228,196) #FFE4C4 bisque3 rgb(205,183,158) #CDB79E DarkOrange1 rgb(255,127,0) #FF7F00 linen rgb(250,240,230) #FAF0E6 DarkOrange2 rgb(238,118,0) #EE7600 DarkOrange3 rgb(205,102,0) #CD6600 DarkOrange4 rgb(139,69,0) #8B4500 peru rgb(205,133,63) #CD853F tan1 rgb(255,165,79) #FFA54F tan2 rgb(238,154,73) #EE9A49 tan3 rgb(205,133,63) #CD853F tan4 rgb(139,90,43) #8B5A2B PeachPuff rgb(255,218,185) #FFDAB9 PeachPuff1 rgb(255,218,185) #FFDAB9 PeachPuff4 rgb(139,119,101) #8B7765 PeachPuff2 rgb(238,203,173) #EECBAD PeachPuff3 rgb(205,175,149) #CDAF95 SandyBrown rgb(244,164,96) #F4A460 seashell4 rgb(139,134,130) #8B8682 seashell2 rgb(238,229,222) #EEE5DE seashell3 rgb(205,197,191) #CDC5BF chocolate rgb(210,105,30) #D2691E chocolate1 rgb(255,127,36) #FF7F24 chocolate2 rgb(238,118,33) #EE7621 chocolate3 rgb(205,102,29) #CD661D chocolate4 rgb(139,69,19) #8B4513 SaddleBrown rgb(139,69,19) #8B4513 seashell rgb(255,245,238) #FFF5EE seashell1 rgb(255,245,238) #FFF5EE sienna4 rgb(139,71,38) #8B4726 sienna rgb(160,82,45) #A0522D sienna1 rgb(255,130,71) #FF8247 sienna2 rgb(238,121,66) #EE7942 sienna3 rgb(205,104,57) #CD6839 LightSalmon3 rgb(205,129,98) #CD8162 LightSalmon rgb(255,160,122) #FFA07A LightSalmon1 rgb(255,160,122) #FFA07A LightSalmon4 rgb(139,87,66) #8B5742 LightSalmon2 rgb(238,149,114) #EE9572 coral rgb(255,127,80) #FF7F50 OrangeRed rgb(255,69,0) #FF4500 OrangeRed1 rgb(255,69,0) #FF4500 OrangeRed2 rgb(238,64,0) #EE4000 OrangeRed3 rgb(205,55,0) #CD3700 OrangeRed4 rgb(139,37,0) #8B2500 DarkSalmon rgb(233,150,122) #E9967A salmon1 rgb(255,140,105) #FF8C69 salmon2 rgb(238,130,98) #EE8262 salmon3 rgb(205,112,84) #CD7054 salmon4 rgb(139,76,57) #8B4C39 coral1 rgb(255,114,86) #FF7256 coral2 rgb(238,106,80) #EE6A50 coral3 rgb(205,91,69) #CD5B45 coral4 rgb(139,62,47) #8B3E2F tomato4 rgb(139,54,38) #8B3626 tomato rgb(255,99,71) #FF6347 tomato1 rgb(255,99,71) #FF6347 tomato2 rgb(238,92,66) #EE5C42 tomato3 rgb(205,79,57) #CD4F39 MistyRose4 rgb(139,125,123) #8B7D7B MistyRose2 rgb(238,213,210) #EED5D2 MistyRose rgb(255,228,225) #FFE4E1 MistyRose1 rgb(255,228,225) #FFE4E1 salmon rgb(250,128,114) #FA8072 MistyRose3 rgb(205,183,181) #CDB7B5 white rgb(255,255,255) #FFFFFF gray100 rgb(255,255,255) #FFFFFF grey100 rgb(255,255,255) #FFFFFF grey100 rgb(255,255,255) #FFFFFF gray99 rgb(252,252,252) #FCFCFC grey99 rgb(252,252,252) #FCFCFC gray98 rgb(250,250,250) #FAFAFA grey98 rgb(250,250,250) #FAFAFA gray97 rgb(247,247,247) #F7F7F7 grey97 rgb(247,247,247) #F7F7F7 gray96 rgb(245,245,245) #F5F5F5 grey96 rgb(245,245,245) #F5F5F5 WhiteSmoke rgb(245,245,245) #F5F5F5 gray95 rgb(242,242,242) #F2F2F2 grey95 rgb(242,242,242) #F2F2F2 gray94 rgb(240,240,240) #F0F0F0 grey94 rgb(240,240,240) #F0F0F0 gray93 rgb(237,237,237) #EDEDED grey93 rgb(237,237,237) #EDEDED gray92 rgb(235,235,235) #EBEBEB grey92 rgb(235,235,235) #EBEBEB gray91 rgb(232,232,232) #E8E8E8 grey91 rgb(232,232,232) #E8E8E8 gray90 rgb(229,229,229) #E5E5E5 grey90 rgb(229,229,229) #E5E5E5 gray89 rgb(227,227,227) #E3E3E3 grey89 rgb(227,227,227) #E3E3E3 gray88 rgb(224,224,224) #E0E0E0 grey88 rgb(224,224,224) #E0E0E0 gray87 rgb(222,222,222) #DEDEDE grey87 rgb(222,222,222) #DEDEDE gainsboro rgb(220,220,220) #DCDCDC gray86 rgb(219,219,219) #DBDBDB grey86 rgb(219,219,219) #DBDBDB gray85 rgb(217,217,217) #D9D9D9 grey85 rgb(217,217,217) #D9D9D9 gray84 rgb(214,214,214) #D6D6D6 grey84 rgb(214,214,214) #D6D6D6 gray83 rgb(212,212,212) #D4D4D4 grey83 rgb(212,212,212) #D4D4D4 LightGray rgb(211,211,211) #D3D3D3 LightGrey rgb(211,211,211) #D3D3D3 gray82 rgb(209,209,209) #D1D1D1 grey82 rgb(209,209,209) #D1D1D1 gray81 rgb(207,207,207) #CFCFCF grey81 rgb(207,207,207) #CFCFCF gray80 rgb(204,204,204) #CCCCCC grey80 rgb(204,204,204) #CCCCCC gray79 rgb(201,201,201) #C9C9C9 grey79 rgb(201,201,201) #C9C9C9 gray78 rgb(199,199,199) #C7C7C7 grey78 rgb(199,199,199) #C7C7C7 gray77 rgb(196,196,196) #C4C4C4 grey77 rgb(196,196,196) #C4C4C4 gray76 rgb(194,194,194) #C2C2C2 grey76 rgb(194,194,194) #C2C2C2 silver rgb(192,192,192) #C0C0C0 gray75 rgb(191,191,191) #BFBFBF grey75 rgb(191,191,191) #BFBFBF gray74 rgb(189,189,189) #BDBDBD grey74 rgb(189,189,189) #BDBDBD gray73 rgb(186,186,186) #BABABA grey73 rgb(186,186,186) #BABABA gray72 rgb(184,184,184) #B8B8B8 grey72 rgb(184,184,184) #B8B8B8 gray71 rgb(181,181,181) #B5B5B5 grey71 rgb(181,181,181) #B5B5B5 gray70 rgb(179,179,179) #B3B3B3 grey70 rgb(179,179,179) #B3B3B3 gray69 rgb(176,176,176) #B0B0B0 grey69 rgb(176,176,176) #B0B0B0 gray68 rgb(173,173,173) #ADADAD grey68 rgb(173,173,173) #ADADAD gray67 rgb(171,171,171) #ABABAB grey67 rgb(171,171,171) #ABABAB DarkGray rgb(169,169,169) #A9A9A9 DarkGrey rgb(169,169,169) #A9A9A9 gray66 rgb(168,168,168) #A8A8A8 grey66 rgb(168,168,168) #A8A8A8 gray65 rgb(166,166,166) #A6A6A6 grey65 rgb(166,166,166) #A6A6A6 gray64 rgb(163,163,163) #A3A3A3 grey64 rgb(163,163,163) #A3A3A3 gray63 rgb(161,161,161) #A1A1A1 grey63 rgb(161,161,161) #A1A1A1 gray62 rgb(158,158,158) #9E9E9E grey62 rgb(158,158,158) #9E9E9E gray61 rgb(156,156,156) #9C9C9C grey61 rgb(156,156,156) #9C9C9C gray60 rgb(153,153,153) #999999 grey60 rgb(153,153,153) #999999 gray59 rgb(150,150,150) #969696 grey59 rgb(150,150,150) #969696 gray58 rgb(148,148,148) #949494 grey58 rgb(148,148,148) #949494 gray57 rgb(145,145,145) #919191 grey57 rgb(145,145,145) #919191 gray56 rgb(143,143,143) #8F8F8F grey56 rgb(143,143,143) #8F8F8F gray55 rgb(140,140,140) #8C8C8C grey55 rgb(140,140,140) #8C8C8C gray54 rgb(138,138,138) #8A8A8A grey54 rgb(138,138,138) #8A8A8A gray53 rgb(135,135,135) #878787 grey53 rgb(135,135,135) #878787 gray52 rgb(133,133,133) #858585 gray51 rgb(130,130,130) #828282 fractal rgb(128,128,128) #808080 gray50 rgb(127,127,127) #7F7F7F gray rgb(126,126,126) #7E7E7E grey49 rgb(125,125,125) #7D7D7D gray47 rgb(120,120,120) #787878 gray46 rgb(117,117,117) #757575 gray45 rgb(115,115,115) #737373 gray44 rgb(112,112,112) #707070 gray43 rgb(110,110,110) #6E6E6E gray42 rgb(107,107,107) #6B6B6B DimGrey rgb(105,105,105) #696969 gray39 rgb(99,99,99) #636363 gray38 rgb(97,97,97) #616161 gray37 rgb(94,94,94) #5E5E5E gray36 rgb(92,92,92) #5C5C5C gray35 rgb(89,89,89) #595959 gray34 rgb(87,87,87) #575757 gray33 rgb(84,84,84) #545454 gray32 rgb(82,82,82) #525252 gray31 rgb(79,79,79) #4F4F4F gray30 rgb(77,77,77) #4D4D4D gray29 rgb(74,74,74) #4A4A4A gray28 rgb(71,71,71) #474747 gray27 rgb(69,69,69) #454545 gray26 rgb(66,66,66) #424242 gray25 rgb(64,64,64) #404040 gray24 rgb(61,61,61) #3D3D3D gray23 rgb(59,59,59) #3B3B3B gray22 rgb(56,56,56) #383838 gray21 rgb(54,54,54) #363636 gray20 rgb(51,51,51) #333333 gray19 rgb(48,48,48) #303030 gray18 rgb(46,46,46) #2E2E2E gray17 rgb(43,43,43) #2B2B2B gray16 rgb(41,41,41) #292929 gray15 rgb(38,38,38) #262626 gray14 rgb(36,36,36) #242424 gray13 rgb(33,33,33) #212121 gray12 rgb(31,31,31) #1F1F1F gray11 rgb(28,28,28) #1C1C1C gray10 rgb(26,26,26) #1A1A1A gray9 rgb(23,23,23) #171717 gray8 rgb(20,20,20) #141414 gray7 rgb(18,18,18) #121212 gray6 rgb(15,15,15) #0F0F0F gray5 rgb(13,13,13) #0D0D0D gray4 rgb(10,10,10) #0A0A0A gray3 rgb(8,8,8) #080808 gray2 rgb(5,5,5) #050505 gray1 rgb(3,3,3) #030303 black rgb(0,0,0) #000000 gray0 rgb(0,0,0) #000000 opaque rgb(0,0,0) #000000 none rgba(0,0,0,0.0) #00000000 transparent rgba(0,0,0,0.0) #00000000","title":"ImageMagick color list"},{"location":"img_files/#sips-mac","text":"Usage: sips [flags] inputFile [--out outputFile] Image modification flags: Flag Meaning -s key value Set the value for a key (see table below for the available keys and acceptable values). -r degreesCW Rotate an image several degrees clockwise. -f option Flip the image using one of the following two options: horizontal or vertical. -c pixelsH pixelsW Crop image to fit specified size. pixelsH indicates the new height in number of pixels, pixelsW indicates the new width in number of pixels. -z pixelsH pixelsW Resample image at specified size. Image aspect ratio may be altered. pixelsH indicate the new height in number of pixels, pixelsW indicate the new width in number of pixels. -Z pixelsWH Resample image so height and width aren't greater than specified. --resampleWidth pixelsW Resample image to specified width. pixelsW indicate the new width in number of pixels. --resampleHeight pixelsH Resample image to specified height. pixelsH indicate the new height in number of pixels. -o Optimize color for sharing. -p pixelsH pixelsW Add padding to the image. Use --padColor hexcolor to select the padding color as hexadecimal number. If you want to modify one image to match the properties of another image (for example have one image match the height of another image), you can use the flag -g key or --getProperty key on the image that you want to match. Where key is one of the following properties: Profile property keys Usage dpiHeight Height in dpi (printer dots per inch). dpiWidth Width in dpi (printer dots per inch). pixelHeight Height in number of pixels. pixelWidth Width in number of pixels. format Image format. Acceptable values for this key: jpeg , tiff , png , gif , jp2 , pict , bmp , qtif , psd , sgi , tga , pdf . formatOptions Quality of the new image. Acceptable values for this key: low , normal , high , best , or some percentage. samplesPerPixel Samples per pixel. bitsPerSample Bits per sample. software Software use to create the image. description Description. copyright Copyright. version Version. platform Platform where file was created. quality Acceptable values for this key: normal, draft, best. renderingIntent Acceptable values for this key: perceptual, relative, saturation, absolute. creator Creator of the file. For the examples below I will be using the following image, taken from the following article, which I published long time ago: link to article . Convert AutismArticle1.png to pdf. $ sips -s format pdf AutismArticle1.png --out AutismArticle1.pdf /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.pdf Rotate AutismArticle1.png 45 degrees clock-wise. $ sips -r 45 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Rotate AutismArticle1.png 45 degrees counter-clock-wise. $ sips -r -45 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test2.png Result image: Flip AutismArticle1.png horizontally. $ sips -f horizontal AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Flip AutismArticle1.png vertically. $ sips -f vertical AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Crop AutismArticle1.png to fit a new size that be 1/4 of its original height and 1/4 of its original weight: The first step is to obtain the current width and height using sips with the flags --getProperty pixelWidth and --getProperty pixelHeight . Then, divide the two numbers by four. And finally use sips with the -c flag to crop the file. $ sips --getProperty pixelHeight AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png pixelHeight: 440 $ sips --getProperty pixelWidth AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png pixelWidth: 727 $ echo \"440/4\" | bc -l 110.00000000000000000000 $ echo \"727/4\" | bc -l 181.75000000000000000000 $ sips -c 110 181 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png Result image: Resample image to 110x181: $ sips -z 110 181 AutismArticle1.png --out test.png /Users/monica/Desktop/Backup/images_presentations/AutismArticle1.png /Users/monica/Desktop/Backup/images_presentations/test.png $ sips --getProperty pixelHeight test.png /Users/monica/Desktop/Backup/images_presentations/test.png pixelHeight: 110 $ sips --getProperty pixelWidth test.png /Users/monica/Desktop/Backup/images_presentations/test.png pixelWidth: 181 Result image:","title":"sips (Mac)"},{"location":"iteration/","text":"Iteration Iteration is the repetition of commands on a list of items. For example, you might use iteration to manipulate in the same way a long list of files. It saves time because instead of typing the same command 100 times to do the same thing on 100 files, you type it just one time inside a loop. You will use loops (as well as condition-testing) in almost every script that you write. Command Use Syntax for For iterating over a series of items within a list (array). for item in list; do; commands; done for For iterating through an index. for ((i=1; i<=64; i+=1)); do; commands; done while For iterating while a control expression (condition) is true . while condition; do; commands; done The for loop Array of words In the following example we have an array with a list of subjects: declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') If we want to print the ID of each subject within the list without using a loop, we would have to type 5 different commands: $ echo ${ARRAY[0]} SUBJ0 $ echo ${ARRAY[1]} SUBJ9 $ echo ${ARRAY[2]} SUBJ3 $ echo ${ARRAY[3]} SUBJ4 $ echo ${ARRAY[4]} SUBJ3 If instead we use a loop, we just need to write the command one time. In this example, with only five subjects, so it doesn\u2019t save too many lines of code. But normally you will be working with many more items than five. $ for ID in ${ARRAY[@]} > do > echo ${ID} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 The previous for loop iterates through every item in ${ARRAY[@]} (the items that would be listed if you typed echo ${ARRAY[@]}) ), and assign each item to the variable ID during the corresponding loop. So, the loop will run 5 times. The first time it runs it will assign the value SUBJ0 to variable ID , the second loop will assign value SUBJ9 to variable ID , etc. $ num=0 $ for ID in ${ARRAY[@]} > do > echo \"Subject number ${num} is ${ID}\" > ((num++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3 Using patterns As we learned in the arrays section , you can use patterns to create arrays. You can also use patterns to list files that have a similar path except for a few words or letters. For example, if you have a folder located in the following path: /Users/MyUserName/Desktop/MyProjectFolder . Inside this folder you have 100 files named very similarly: DTI_SUBJ1.nii.gz, DTI_SUBJ2.nii.gz, DTI_SUBJ3.nii.gz, DTI_SUBJ4.nii.gz, DTI_SUBJ5.nii.gz, ..., DTI_SUBJ100.nii.gz Then, you could print the list of all those files by simply typing: echo /Users/MyUserName/Desktop/MyProjectFolder/DTI_SUBJ*.nii.gz . This command matches all the file paths that contain any number of characters in the position where the asterisk is located. Let's look at another example. Suppose that you have information for a list of subjects organized the following way: Your main subjects is folder located in this path: /Users/MyUserName/Desktop/MyProjectFolder Inside that folder you have one folder per subject: /Users/MyUserName/Desktop/MyProjectFolder/Subject1 , /Users/MyUserName/Desktop/MyProjectFolder/Subject2 , ..., /Users/MyUserName/Desktop/MyProjectFolder/Subject100 Inside each subject folder, you have the following files: DTI.nii.gz , ANAT.nii.gz , LGN.nii.gz If you wanted to obtain the list of paths for the DTI.nii.gz files of all subjects, you could type: echo /Users/MyUserName/Desktop/MyProjectFolder/Subject*/DTI.nii.gz . Because the path of these files is the same except for the subject number, you can create the pattern by substituting the part that changes by an asterisk. When using the asterisk, it will select all files that contain any amount of characters in that position. But if you want to restrict the search to a specific amount of characters, you could also use the interrogation mark. For example, let's suppose you have a main folder located in the following path: /MyComputer/MyUser/MyDocuments/MyFolder . And inside that folder you have 100 files named: myFile001.txt , myFile002.txt , ..., myFile100.txt You want to iterate through the files myFile001.txt to myFile009.txt . All those files have the exact same path and name except for exactly one character. So, you can replace that character by an interrogation mark: $ for f in /MyComputer/MyUser/MyDocuments/MyFolder/myFile00?.txt > do > echo $f > done /MyComputer/MyUser/MyDocuments/MyFolder/myFile001.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile002.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile003.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile004.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile005.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile006.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile007.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile008.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile009.txt You could choose to print the results into a file instead of the command prompt. This can be achieved using the symbol >> . After running the following loop, you will not see any output in the command line, the path of the nine files will be saved to output.txt : The command cat ${maindir}output.txt prints the content of this output file. $ maindir=/MyComputer/MyUser/MyDocuments/MyFolder/ $ for f in ${maindir}myFile00?.txt > do > echo $f >> ${maindir}output.txt > done $ cat ${maindir}output.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile001.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile002.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile003.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile004.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile005.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile006.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile007.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile008.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile009.txt Iterating through files To know the current directory in which you are located in the command line, type pwd . In the following example we want to we want to perform some action on all the files inside the current directory. To get the list of those files we use the ls . $ pwd /path/to/my/current/directory $ for f in $( ls ) > do > echo \"Do something with this file: ${f}\" > done From for to while Every loop that you write using for can also be written with while . The results will be the same, but sometimes one of them will be more efficient and easier to code than the other. You should use the for command when you want to iterate through all the elements of an array. You should use the for command when iterating through the indices of an array (either all or a subset of them). You should use the while command when you want to iterate through a limited number of elements within the array. You should use the while command when you want to iterate through more than one array or while several conditions should be met . The following example shows how a for loop can be converted into a while loop. The objective of this piece of code is to print the elements of an array. Using for : declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') $ for E in ${ARRAY[@]} > do > echo ${E} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 Using while : $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo ${ARRAY[${i}]} > ((i++)) > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 OR: $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo ${ARRAY[$((i++))]} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 In the previous example both loops iterate through the elements of an array and print them in the terminal. However, there are some important differences: The for loop automatically stops when iteration reaches the end of the array. The while loop stops when the condition ( [ ${i} -lt ${SIZE} ] ) evaluates false . This means that it will iterate as long as variable i is less than ( -lt ) SIZE . In the while loop, variable i contains the index of each item during the iteration and variable SIZE contains the size of the array. For this reason ((i++)) is included inside the while loop. ((i++)) increments the value of i in 1 on each iteration. If you didn't include this, Bash would iterate forever , because you wouldn't be increasing the value of i , and it would always equal zero. Hence, it would never be less than the size of the array. So, the condition that the while evaluates will never be false . Since while iterates as long as that condition is true , it would iterate forever. In the for loop each element of the array is saved in variable E . However, you don't have to assign each value to the variable, it is done automatically. In the while loop the element in the position i is referenced with ${ARRAY[${i}]} . In this case we want to iterate through all the elements of ARRAY . So, it makes more sense to use the for loop. Below is another example on how to print the elements of an array and their position within the array using for and while : Using for : $ declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') $ i=0 $ for ID in ${ARRAY[@]} > do > echo \"Subject number ${i} is ${ID}\" > ((i++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3 Using while : $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo \"Subject number ${i} is ${ARRAY[$i]}\" > ((i++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3 Previously we learned that the following loop would echo the path of all the files in the current directory: $ for f in $( ls ) > do > echo \"Do something with this file: ${f}\" > done In this case, it makes more sense to use the for loop. However, if instead of echoing all the files inside the current directory you wanted to echo only the first five files, then you should use the while loop: $ i=0 $ ARRAY=($( ls )) $ while [ ${i} -le 4 ] > do > echo ${ARRAY[${i}]} > ((i++)) > done In the following example we rename all the files in the current directory that end in .nii.gz: $ ls 10132423423.nii.gz 25675756756.nii.gz 36787686767.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz $ i=1 $ for f in ./*.nii.gz > do > mv ${f} Subject_${i}.nii.gz > ((i++)) > done $ ls Subject_1.nii.gz Subject_2.nii.gz Subject_3.nii.gz Subject_4.nii.gz Subject_5.nii.gz Subject_6.nii.gz In the following example we rename the first three files in the current directory that end in .nii.gz: $ ls 10132423423.nii.gz 25675756756.nii.gz 36787686767.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz $ i=0 $ ARRAY=($( ls ./*.nii.gz )) $ while [ ${i} -le 2 ] > do > mv ${ARRAY[${i}]} ./Subject_$((++i)).nii.gz > done $ ls Subject_1.nii.gz Subject_2.nii.gz Subject_3.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz The while loop Multiple arrays As previously mentioned, when you are iterating through more than one array you should use while instead of for . Iterating through two arrays In the following example we have two arrays ( ID and VISIT ), which contain a list of subject IDs and visit numbers respectively. The loop iterates through both arrays (until it reaches the end of one or the other) and saves the information extracted from both arrays into a text file. Then, it prints the content of the text file ( test.txt ) using cat , which will be explained in detail in the following chapter ( File manipulation ). This while loop will run as long as the two conditions ( [ ${i} -lt ${SIZE_ID} ] and [ ${i} -lt ${SIZE_VISIT} ] ) are true . So, as the value of i be greater than SIZE_ID or SIZE_VISIT , it will stop. It is important to not forget the line ((i++)) . Otherwise, it will loop forever (you can always break a loop with Control + C). $ declare -a ID=('SUBJ0' 'SUBJ1' 'SUBJ2' 'SUBJ3' 'SUBJ4' 'SUBJ5' 'SUBJ6') $ declare -a VISIT=('V1' 'V1' 'V2' 'V1' 'V2' 'V2' 'V3') $ SIZE_ID=${#ID[@]} $ SIZE_VISIT=${#VISIT[@]} $ i=0 $ while [ ${i} -lt ${SIZE_ID} ] && [ ${i} -lt ${SIZE_VISIT} ] > do > echo \"${ID[${i}]}_${VISIT[${i}]}\" >> test.txt > ((i++)) > done $ cat test.txt SUBJ0_V1 SUBJ1_V1 SUBJ2_V2 SUBJ3_V1 SUBJ4_V2 SUBJ5_V2 SUBJ6_V3 Inverting an array In this example initially there is only one array, but after the code is executed there will be two arrays. The second array will be the inversion of the first one. The code will iterate starting at the end of the array and finishing at the beginning. In each iteration it will copy the current value into the new array. It will start adding items at the beginning of the new array (in the index 0). For this purpose, there will be two variables: Variable i will be initialized with value $(( ${#ARRAY[@]} \u2013 1 )) (the size of the initial array minus one). It will represent the position in which the loop is iterating in the original array. In each loop, i will decrease its value in 1 until it reaches 0. It is initialized with value equal to the size of the array minus one because the first index of an array is 0 and the last one is the size of the array minus one. Variable j will be initialized with value 0. It will represent the position in which the loop is iterating in the inverted array. In each loop, j will increase its value until it reaches the size of the original array. Values of i : 9, 8, 7, 6, 5, 4, 3, 2, 1, 0. Order of values in the original array: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Values of j : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Order of values in the inverted array: 10, 9, 8, 7, 6, 5, 4, 3, 2, 1. $ declare -a ARRAY=('1' '2' '3' '4' '5' '6' '7' '8' '9' '10') $ i=$(( ${#ARRAY[@]} - 1 )) $ j=0 $ while [ ${i} -ge 0 ] > do > echo \"Copying element in position ${i} from the original array into position ${j} of the new array...\" > INV_ARRAY[$((j++))]=${ARRAY[$((i--))]} > done Copying element in position 9 from the original array into position 0 of the new array... Copying element in position 8 from the original array into position 1 of the new array... Copying element in position 7 from the original array into position 2 of the new array... Copying element in position 6 from the original array into position 3 of the new array... Copying element in position 5 from the original array into position 4 of the new array... Copying element in position 4 from the original array into position 5 of the new array... Copying element in position 3 from the original array into position 6 of the new array... Copying element in position 2 from the original array into position 7 of the new array... Copying element in position 1 from the original array into position 8 of the new array... Copying element in position 0 from the original array into position 9 of the new array... $ echo ${INV_ARRAY[@]} 10 9 8 7 6 5 4 3 2 1 The command INV_ARRAY[$((j++))]=ARRAY[$((i--))] is doing three things: Assigning the element of ARRAY in position i to INV_ARRAY in position j Incrementing j in one And decreasing i in one It is equivalent to this set of instructions: INV_ARRAY[${j}]=ARRAY[${i}] ((j++)) ((i--)) Multiple conditions In the following example there is an array called SUBJECTS . Some of those subjects are controls and their ID starts with the letter C, other subjects are patients and their ID starts with the letter P. The array is organized so that the controls go before the patients. The loop will copy only the controls into a new array ( CONTROLS ). So, there are two conditions to be met so that the loop continues to run: The index variable i is less than the size of SUBJECTS ( ${#SUBJECTS[@]} ). This condition is written like this: [ ${i} -lt ${#SUBJECTS[@]} ] . The current element ( SUBJECTS[${i}] ) starts with the letter C . To get the first letter of the current element you must use the previously learned syntax to extract a sub-string: ${STRING:START:NUM} . So, this condition is written like this: [ \"${SUBJECTS[${i}]:0:1}\" == \"C\" ] . $ declare -a SUBJECTS=('C01' 'C02' 'C03' 'C04' 'C05' 'C06' 'P07' 'P08' 'P09' 'P10') $ i=0 $ while [ ${i} -lt ${#SUBJECTS[@]} ] && [ \"${SUBJECTS[${i}]:0:1}\" == \"C\" ] > do > CONTROLS[${i}]=${SUBJECTS[$((i++))]} > done $ echo ${CONTROLS[@]} C01 C02 C03 C04 C05 C06","title":"Iteration"},{"location":"iteration/#iteration","text":"Iteration is the repetition of commands on a list of items. For example, you might use iteration to manipulate in the same way a long list of files. It saves time because instead of typing the same command 100 times to do the same thing on 100 files, you type it just one time inside a loop. You will use loops (as well as condition-testing) in almost every script that you write. Command Use Syntax for For iterating over a series of items within a list (array). for item in list; do; commands; done for For iterating through an index. for ((i=1; i<=64; i+=1)); do; commands; done while For iterating while a control expression (condition) is true . while condition; do; commands; done","title":"Iteration"},{"location":"iteration/#the-for-loop","text":"","title":"The for loop"},{"location":"iteration/#array-of-words","text":"In the following example we have an array with a list of subjects: declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') If we want to print the ID of each subject within the list without using a loop, we would have to type 5 different commands: $ echo ${ARRAY[0]} SUBJ0 $ echo ${ARRAY[1]} SUBJ9 $ echo ${ARRAY[2]} SUBJ3 $ echo ${ARRAY[3]} SUBJ4 $ echo ${ARRAY[4]} SUBJ3 If instead we use a loop, we just need to write the command one time. In this example, with only five subjects, so it doesn\u2019t save too many lines of code. But normally you will be working with many more items than five. $ for ID in ${ARRAY[@]} > do > echo ${ID} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 The previous for loop iterates through every item in ${ARRAY[@]} (the items that would be listed if you typed echo ${ARRAY[@]}) ), and assign each item to the variable ID during the corresponding loop. So, the loop will run 5 times. The first time it runs it will assign the value SUBJ0 to variable ID , the second loop will assign value SUBJ9 to variable ID , etc. $ num=0 $ for ID in ${ARRAY[@]} > do > echo \"Subject number ${num} is ${ID}\" > ((num++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3","title":"Array of words"},{"location":"iteration/#using-patterns","text":"As we learned in the arrays section , you can use patterns to create arrays. You can also use patterns to list files that have a similar path except for a few words or letters. For example, if you have a folder located in the following path: /Users/MyUserName/Desktop/MyProjectFolder . Inside this folder you have 100 files named very similarly: DTI_SUBJ1.nii.gz, DTI_SUBJ2.nii.gz, DTI_SUBJ3.nii.gz, DTI_SUBJ4.nii.gz, DTI_SUBJ5.nii.gz, ..., DTI_SUBJ100.nii.gz Then, you could print the list of all those files by simply typing: echo /Users/MyUserName/Desktop/MyProjectFolder/DTI_SUBJ*.nii.gz . This command matches all the file paths that contain any number of characters in the position where the asterisk is located. Let's look at another example. Suppose that you have information for a list of subjects organized the following way: Your main subjects is folder located in this path: /Users/MyUserName/Desktop/MyProjectFolder Inside that folder you have one folder per subject: /Users/MyUserName/Desktop/MyProjectFolder/Subject1 , /Users/MyUserName/Desktop/MyProjectFolder/Subject2 , ..., /Users/MyUserName/Desktop/MyProjectFolder/Subject100 Inside each subject folder, you have the following files: DTI.nii.gz , ANAT.nii.gz , LGN.nii.gz If you wanted to obtain the list of paths for the DTI.nii.gz files of all subjects, you could type: echo /Users/MyUserName/Desktop/MyProjectFolder/Subject*/DTI.nii.gz . Because the path of these files is the same except for the subject number, you can create the pattern by substituting the part that changes by an asterisk. When using the asterisk, it will select all files that contain any amount of characters in that position. But if you want to restrict the search to a specific amount of characters, you could also use the interrogation mark. For example, let's suppose you have a main folder located in the following path: /MyComputer/MyUser/MyDocuments/MyFolder . And inside that folder you have 100 files named: myFile001.txt , myFile002.txt , ..., myFile100.txt You want to iterate through the files myFile001.txt to myFile009.txt . All those files have the exact same path and name except for exactly one character. So, you can replace that character by an interrogation mark: $ for f in /MyComputer/MyUser/MyDocuments/MyFolder/myFile00?.txt > do > echo $f > done /MyComputer/MyUser/MyDocuments/MyFolder/myFile001.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile002.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile003.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile004.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile005.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile006.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile007.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile008.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile009.txt You could choose to print the results into a file instead of the command prompt. This can be achieved using the symbol >> . After running the following loop, you will not see any output in the command line, the path of the nine files will be saved to output.txt : The command cat ${maindir}output.txt prints the content of this output file. $ maindir=/MyComputer/MyUser/MyDocuments/MyFolder/ $ for f in ${maindir}myFile00?.txt > do > echo $f >> ${maindir}output.txt > done $ cat ${maindir}output.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile001.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile002.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile003.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile004.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile005.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile006.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile007.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile008.txt /MyComputer/MyUser/MyDocuments/MyFolder/myFile009.txt","title":"Using patterns"},{"location":"iteration/#iterating-through-files","text":"To know the current directory in which you are located in the command line, type pwd . In the following example we want to we want to perform some action on all the files inside the current directory. To get the list of those files we use the ls . $ pwd /path/to/my/current/directory $ for f in $( ls ) > do > echo \"Do something with this file: ${f}\" > done","title":"Iterating through files"},{"location":"iteration/#from-for-to-while","text":"Every loop that you write using for can also be written with while . The results will be the same, but sometimes one of them will be more efficient and easier to code than the other. You should use the for command when you want to iterate through all the elements of an array. You should use the for command when iterating through the indices of an array (either all or a subset of them). You should use the while command when you want to iterate through a limited number of elements within the array. You should use the while command when you want to iterate through more than one array or while several conditions should be met . The following example shows how a for loop can be converted into a while loop. The objective of this piece of code is to print the elements of an array. Using for : declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') $ for E in ${ARRAY[@]} > do > echo ${E} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 Using while : $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo ${ARRAY[${i}]} > ((i++)) > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 OR: $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo ${ARRAY[$((i++))]} > done SUBJ0 SUBJ9 SUBJ3 SUBJ4 SUBJ3 In the previous example both loops iterate through the elements of an array and print them in the terminal. However, there are some important differences: The for loop automatically stops when iteration reaches the end of the array. The while loop stops when the condition ( [ ${i} -lt ${SIZE} ] ) evaluates false . This means that it will iterate as long as variable i is less than ( -lt ) SIZE . In the while loop, variable i contains the index of each item during the iteration and variable SIZE contains the size of the array. For this reason ((i++)) is included inside the while loop. ((i++)) increments the value of i in 1 on each iteration. If you didn't include this, Bash would iterate forever , because you wouldn't be increasing the value of i , and it would always equal zero. Hence, it would never be less than the size of the array. So, the condition that the while evaluates will never be false . Since while iterates as long as that condition is true , it would iterate forever. In the for loop each element of the array is saved in variable E . However, you don't have to assign each value to the variable, it is done automatically. In the while loop the element in the position i is referenced with ${ARRAY[${i}]} . In this case we want to iterate through all the elements of ARRAY . So, it makes more sense to use the for loop. Below is another example on how to print the elements of an array and their position within the array using for and while : Using for : $ declare -a ARRAY=('SUBJ0' 'SUBJ9' 'SUBJ3' 'SUBJ4' 'SUBJ3') $ i=0 $ for ID in ${ARRAY[@]} > do > echo \"Subject number ${i} is ${ID}\" > ((i++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3 Using while : $ SIZE=${#ARRAY[@]} $ i=0 $ while [ ${i} -lt ${SIZE} ] > do > echo \"Subject number ${i} is ${ARRAY[$i]}\" > ((i++)) > done Subject number 0 is SUBJ0 Subject number 1 is SUBJ9 Subject number 2 is SUBJ3 Subject number 3 is SUBJ4 Subject number 4 is SUBJ3 Previously we learned that the following loop would echo the path of all the files in the current directory: $ for f in $( ls ) > do > echo \"Do something with this file: ${f}\" > done In this case, it makes more sense to use the for loop. However, if instead of echoing all the files inside the current directory you wanted to echo only the first five files, then you should use the while loop: $ i=0 $ ARRAY=($( ls )) $ while [ ${i} -le 4 ] > do > echo ${ARRAY[${i}]} > ((i++)) > done In the following example we rename all the files in the current directory that end in .nii.gz: $ ls 10132423423.nii.gz 25675756756.nii.gz 36787686767.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz $ i=1 $ for f in ./*.nii.gz > do > mv ${f} Subject_${i}.nii.gz > ((i++)) > done $ ls Subject_1.nii.gz Subject_2.nii.gz Subject_3.nii.gz Subject_4.nii.gz Subject_5.nii.gz Subject_6.nii.gz In the following example we rename the first three files in the current directory that end in .nii.gz: $ ls 10132423423.nii.gz 25675756756.nii.gz 36787686767.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz $ i=0 $ ARRAY=($( ls ./*.nii.gz )) $ while [ ${i} -le 2 ] > do > mv ${ARRAY[${i}]} ./Subject_$((++i)).nii.gz > done $ ls Subject_1.nii.gz Subject_2.nii.gz Subject_3.nii.gz 37456456456.nii.gz 39756756756.nii.gz 41786786677.nii.gz","title":"From for to while"},{"location":"iteration/#the-while-loop","text":"","title":"The while loop"},{"location":"iteration/#multiple-arrays","text":"As previously mentioned, when you are iterating through more than one array you should use while instead of for .","title":"Multiple arrays"},{"location":"iteration/#iterating-through-two-arrays","text":"In the following example we have two arrays ( ID and VISIT ), which contain a list of subject IDs and visit numbers respectively. The loop iterates through both arrays (until it reaches the end of one or the other) and saves the information extracted from both arrays into a text file. Then, it prints the content of the text file ( test.txt ) using cat , which will be explained in detail in the following chapter ( File manipulation ). This while loop will run as long as the two conditions ( [ ${i} -lt ${SIZE_ID} ] and [ ${i} -lt ${SIZE_VISIT} ] ) are true . So, as the value of i be greater than SIZE_ID or SIZE_VISIT , it will stop. It is important to not forget the line ((i++)) . Otherwise, it will loop forever (you can always break a loop with Control + C). $ declare -a ID=('SUBJ0' 'SUBJ1' 'SUBJ2' 'SUBJ3' 'SUBJ4' 'SUBJ5' 'SUBJ6') $ declare -a VISIT=('V1' 'V1' 'V2' 'V1' 'V2' 'V2' 'V3') $ SIZE_ID=${#ID[@]} $ SIZE_VISIT=${#VISIT[@]} $ i=0 $ while [ ${i} -lt ${SIZE_ID} ] && [ ${i} -lt ${SIZE_VISIT} ] > do > echo \"${ID[${i}]}_${VISIT[${i}]}\" >> test.txt > ((i++)) > done $ cat test.txt SUBJ0_V1 SUBJ1_V1 SUBJ2_V2 SUBJ3_V1 SUBJ4_V2 SUBJ5_V2 SUBJ6_V3","title":"Iterating through two arrays"},{"location":"iteration/#inverting-an-array","text":"In this example initially there is only one array, but after the code is executed there will be two arrays. The second array will be the inversion of the first one. The code will iterate starting at the end of the array and finishing at the beginning. In each iteration it will copy the current value into the new array. It will start adding items at the beginning of the new array (in the index 0). For this purpose, there will be two variables: Variable i will be initialized with value $(( ${#ARRAY[@]} \u2013 1 )) (the size of the initial array minus one). It will represent the position in which the loop is iterating in the original array. In each loop, i will decrease its value in 1 until it reaches 0. It is initialized with value equal to the size of the array minus one because the first index of an array is 0 and the last one is the size of the array minus one. Variable j will be initialized with value 0. It will represent the position in which the loop is iterating in the inverted array. In each loop, j will increase its value until it reaches the size of the original array. Values of i : 9, 8, 7, 6, 5, 4, 3, 2, 1, 0. Order of values in the original array: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Values of j : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Order of values in the inverted array: 10, 9, 8, 7, 6, 5, 4, 3, 2, 1. $ declare -a ARRAY=('1' '2' '3' '4' '5' '6' '7' '8' '9' '10') $ i=$(( ${#ARRAY[@]} - 1 )) $ j=0 $ while [ ${i} -ge 0 ] > do > echo \"Copying element in position ${i} from the original array into position ${j} of the new array...\" > INV_ARRAY[$((j++))]=${ARRAY[$((i--))]} > done Copying element in position 9 from the original array into position 0 of the new array... Copying element in position 8 from the original array into position 1 of the new array... Copying element in position 7 from the original array into position 2 of the new array... Copying element in position 6 from the original array into position 3 of the new array... Copying element in position 5 from the original array into position 4 of the new array... Copying element in position 4 from the original array into position 5 of the new array... Copying element in position 3 from the original array into position 6 of the new array... Copying element in position 2 from the original array into position 7 of the new array... Copying element in position 1 from the original array into position 8 of the new array... Copying element in position 0 from the original array into position 9 of the new array... $ echo ${INV_ARRAY[@]} 10 9 8 7 6 5 4 3 2 1 The command INV_ARRAY[$((j++))]=ARRAY[$((i--))] is doing three things: Assigning the element of ARRAY in position i to INV_ARRAY in position j Incrementing j in one And decreasing i in one It is equivalent to this set of instructions: INV_ARRAY[${j}]=ARRAY[${i}] ((j++)) ((i--))","title":"Inverting an array"},{"location":"iteration/#multiple-conditions","text":"In the following example there is an array called SUBJECTS . Some of those subjects are controls and their ID starts with the letter C, other subjects are patients and their ID starts with the letter P. The array is organized so that the controls go before the patients. The loop will copy only the controls into a new array ( CONTROLS ). So, there are two conditions to be met so that the loop continues to run: The index variable i is less than the size of SUBJECTS ( ${#SUBJECTS[@]} ). This condition is written like this: [ ${i} -lt ${#SUBJECTS[@]} ] . The current element ( SUBJECTS[${i}] ) starts with the letter C . To get the first letter of the current element you must use the previously learned syntax to extract a sub-string: ${STRING:START:NUM} . So, this condition is written like this: [ \"${SUBJECTS[${i}]:0:1}\" == \"C\" ] . $ declare -a SUBJECTS=('C01' 'C02' 'C03' 'C04' 'C05' 'C06' 'P07' 'P08' 'P09' 'P10') $ i=0 $ while [ ${i} -lt ${#SUBJECTS[@]} ] && [ \"${SUBJECTS[${i}]:0:1}\" == \"C\" ] > do > CONTROLS[${i}]=${SUBJECTS[$((i++))]} > done $ echo ${CONTROLS[@]} C01 C02 C03 C04 C05 C06","title":"Multiple conditions"},{"location":"math/","text":"Arithmetic calculations Integer calculations In order to compute arithmetic calculations with integers you can use one of the following syntaxes: Syntax Usage $(( OPERATION )) Evaluates OPERATION . It can be any arithmetic operation with integer numbers. Including addition ( + ), subtraction ( - ), multiplication ( * ), division ( / ), square root ( sqrt(NUM) ), exponentiation ( NUM**EXP ), etc. ((++NUM)) Increases variable NUM in 1 before evaluating any expression that contains ++NUM . ((NUM++)) Increases variable NUM in 1 after evaluating any expression that contains NUM++ . ((--NUM)) Decreases variable NUM in 1 before evaluating any expression that contains --NUM . ((NUM--)) Decreases variable NUM in 1 after evaluating any expression that contains NUM-- . ((VAR+=NUM)) Increases variable VAR in NUM . Equivalent to VAR=$(( $VAR + $NUM )) . ((VAR-=NUM)) Decreases variable VAR in NUM . Equivalent to VAR=$(( $VAR - $NUM )) . (( $i % 2 )) Returns true if i is an odd number or false if i is even. Usage of $(( OPERATION )) $ echo \"2+1=$(( 2 + 1 ))\" 2+1=3 $ A=2 $ echo \"A+1=$(( ${A} + 1 ))\" A+1=3 $ B=1 $ echo \"A+B=$(( ${A} + ${B} ))\" A+B=3 $ echo \"A-B=$(( ${A} - ${B} ))\" A-B=1 $ echo \"AxB=$(( ${A} * ${B} ))\" AxB=2 $ echo \"A/B=$(( ${A} / ${B} ))\" A/B=2 $ echo \"(A+B)x(A-B)=$(( $(( ${A} + ${B} )) * $(( ${A} - ${B} )) ))\" (A+B)x(A-B)=3 $ echo \"A^3=$(( ${A} ** 3 ))\" A^3=8 $ B=4 $ echo \"A^B=$(( ${A} ** ${B} ))\" A^B=16 $ echo \"B/A=$(( ${B} / ${A} ))\" 0 In the last example, the result is zero because this syntax is used for integer numbers. So, if the result of the operation is not an integer, it will be rounded to the nearest integer. In the next section you will learn how to operate with non-integer numbers . Usage of ((++NUM)) and ((NUM++)) In order to increment the value of a variable by one, there are a couple of options. Some of these options will be very useful when doing iterations (which you will learn later on). ${NUM} + 1 $ NUM=1 $ echo $(( ${NUM} + 1 )) 2 $ echo ${NUM} 1 The command echo $(( ${NUM} + 1 )) prints the result of NUM plus one, but it does not modify the value of NUM . For that reason, when NUM is echoed at the end, it still has value 1 (instead of 2). ((++NUM)) $ NUM=1 $ echo $((++NUM)) 2 $ echo ${NUM} 2 The command echo $((++NUM)) is equivalent to this sequence of instructions: NUM=$(( ${NUM} + 1 )) echo ${NUM} First, increases the value of variable NUM in one, and then it echoes the result. Opposite to the example above, here the variable value is actually modified. And opposite to the example in the below, the variable value is modified before the other instruction ( echo ). ((NUM++)) $ NUM=1 $ echo $((NUM++)) 1 $ echo ${NUM} 2 The command echo $((NUM++)) is equivalent to this sequence of instructions: echo ${NUM} NUM=$(( ${NUM} + 1 )) First echoes the value of NUM . Then, it increases the value of the variable. Usage of ((--NUM)) and ((NUM--)) Expressions ((--NUM)) and ((NUM--)) work in a very similar way than the previous ones, but instead of increasing the value of NUM by one, they decrease the value of NUM by one. These expressions will also be very useful once you learn iteration . ${NUM} - 1 $ NUM=1 $ echo $(( ${NUM} - 1 )) 0 $ echo ${NUM} 1 The command echo $(( ${NUM} - 1 )) prints the result of NUM minus one, but it does not modify the value of NUM . For that reason, when NUM is echoed at the end, it still has value 1 (instead of 0). ((--NUM)) $ NUM=1 $ echo $((--NUM)) 0 $ echo ${NUM} 0 The command echo $((--NUM)) is equivalent to this sequence of instructions: NUM=$(( ${NUM} - 1 )) echo ${NUM} First, decreases the value of variable $NUM in one, and then it echoes the result. Opposite to the example above, here the variable value is actually modified. And opposite to the example below, the variable value is modified before the other instruction ( = ). ((NUM--)) $ NUM=1 $ echo $((NUM--)) 1 $ echo ${NUM} 0 The command echo $((NUM--)) is equivalent to this sequence of instructions: echo ${NUM} NUM=$(( ${NUM} - 1 )) First, echoes the value of NUM . Then, it decreases the value of the variable. Usage of ((VAR+=NUM)) This expression is a compact way of writing VAR=$(( ${VAR} + ${NUM} )) . Compact expression Extended equivalent ((A+=2)) A=$(( ${A} + 2 )) B=$((A+=2)) A=$(( ${A} + 2 )); B=${A} ((A+=B)) A=$(( ${A} + ${B} )) The value of B is not modified, only A is modified. B=$((A+=B)) A=$(( ${A} + ${B} )); B=${A} In this case the value of both A and B is modified because the result of ((A+=B)) is assigned to B . Usage of ((VAR-=NUM)) This expression is a compact way of writing: VAR=$(( ${VAR} - ${NUM} )) Compact expression Extended equivalent ((A-=2)) A=$(( ${A} - 2 )) B=$((A-=2)) A=$(( ${A} - 2 )); B=${A} ((A-=B)) A=$(( ${A} - ${B} )) The value of B is not modified, only A is modified. B=$((A-=B)) A=$(( ${A} - ${B} )); B=${A} In this case the value of both A and B is modified because the result of ((A-=B)) is assigned to B . Usage of (( $i % 2 )) $ for i in $(seq 10) > do > if (( $i % 2 )) > then > echo $i is odd > else > echo $i is even > fi > done 1 is odd 2 is even 3 is odd 4 is even 5 is odd 6 is even 7 is odd 8 is even 9 is odd 10 is even Non-integer calculations When programming in Bash, you will often need to do mathematical operations that involve non-integer calculations. To do this, you will need the bc utility. You can use this utility also for integer calculations, but it is normally left for advanced math. Syntax Usage echo \"OPERATION\" | bc Evaluates OPERATION . This can be any arithmetic operation with integer or non-integer numbers. Including addition ( + ), subtraction ( - ), multiplication ( * ), division ( / ), square root ( sqrt(NUM) ), exponentiation ( NUM**EXP ), etc. It will round the result to the closest integer. echo \"OPERATION\" | bc -l Flag -l will not round the result. Instead, will print it with all the decimals. echo \"scale=NDECIMALS; OPERATION\" | bc -l Will only print NDECIMALS instead of all the decimals. echo \"OPERATION\" | bc $ echo \"2.34 / 1.895\" | bc 1 $ echo \"2 / 3\" | bc 0 echo \"OPERATION\" | bc -l $ echo \"2.34 / 1.895\" | bc -l 1.23482849604221635883 $ echo \"2 / 3\" | bc -l .66666666666666666666 $ A=$(echo \"2.34 / 1.895\" | bc) $ B=$(echo \"2.34 / 1.895\" | bc -l) $ echo ${A} 1 $ echo ${B} 1.23482849604221635883 $ echo \"${A} + ${B}\" | bc -l 2.23482849604221635883 $ echo \"${A} + ${B}\" 1 + 1.23482849604221635883 Look at the difference between the last two expressions. They are almost the same except for the | bc -l at the end of the first expression. Yet, the results are very different. That is because in the second case we are just printing the text \"\\${A} + \\${B}\", while in the first one we are evaluating the expression written in that text, with the use of the bc utility. The following example may clarify this concept: $ echo \"${A} + ${B}=$(echo \"${A} + ${B}\" | bc -l)\" 1 + 1.23482849604221635883=2.23482849604221635883 To find the square root of a number you use the expression sqrt() , like in many other programming languages. So, to find the square root of 10 and save it to variable a you would use the following command: $ A=$(echo \"sqrt (10)\" | bc -l) $ echo ${A} 3.16227766016837933199 Knowing this, you can do any type of operations with non-integer numbers. Just by writing the desired expression between the quotation marks, or combine integer and non-integer calculations. Let\u2019s look at a few more examples: $ echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l 4.39710615621059569082 $ echo $((2**3)) 12.397106156210595690828 $ echo \"(2.34 / 1.895) + sqrt (10) + $((2**3))\" | bc -l 12.39710615621059569082 $ echo \"(2.34 / 1.895) + sqrt (10) + 2^3\" | bc -l 12.39710615621059569082 $ echo \"2 + 2\" | bc -l 4 $ echo \"2 + 2\" 2 + 2 $ echo \"2 + 2 = $(echo \"2 + 2\" | bc -l)\" 2 + 2 = 4 $ A=$(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l) $ echo ${A} 4.39710615621059569082 $ echo $(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l) 4.39710615621059569082 $ echo \"(2.34 / 1.895) + sqrt (10)= $(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l)\" (2.34 / 1.895) + sqrt (10)= 4.39710615621059569082 echo \"scale=NDECIMALS; OPERATION\" | bc -l Clearly, some of the results of the previous examples have too many decimals. You can cut the number of decimals using scale . $ echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l 4.39710615621059569082 $ echo \"scale=3; (2.34 / 1.895) + sqrt (10)\" | bc -l 4.396 $ echo \"scale=0; (2.34 / 1.895) + sqrt (10)\" | bc -l 4 Comparing non-integers In order to compare non-integers you can use awk . This function will be studied more in detail in later chapters as it is mainly used for processing files and strings. But as this example shows, it can also be used to deal with numbers. $ awk 'BEGIN{ print (2.41==2.4) ? \"equal\" : \"not equal\" }' not equal $ awk 'BEGIN{ print (2.41==2.41) ? \"equal\" : \"not equal\" }' equal","title":"Arithmetic calculations"},{"location":"math/#arithmetic-calculations","text":"","title":"Arithmetic calculations"},{"location":"math/#integer-calculations","text":"In order to compute arithmetic calculations with integers you can use one of the following syntaxes: Syntax Usage $(( OPERATION )) Evaluates OPERATION . It can be any arithmetic operation with integer numbers. Including addition ( + ), subtraction ( - ), multiplication ( * ), division ( / ), square root ( sqrt(NUM) ), exponentiation ( NUM**EXP ), etc. ((++NUM)) Increases variable NUM in 1 before evaluating any expression that contains ++NUM . ((NUM++)) Increases variable NUM in 1 after evaluating any expression that contains NUM++ . ((--NUM)) Decreases variable NUM in 1 before evaluating any expression that contains --NUM . ((NUM--)) Decreases variable NUM in 1 after evaluating any expression that contains NUM-- . ((VAR+=NUM)) Increases variable VAR in NUM . Equivalent to VAR=$(( $VAR + $NUM )) . ((VAR-=NUM)) Decreases variable VAR in NUM . Equivalent to VAR=$(( $VAR - $NUM )) . (( $i % 2 )) Returns true if i is an odd number or false if i is even.","title":"Integer calculations"},{"location":"math/#usage-of-operation","text":"$ echo \"2+1=$(( 2 + 1 ))\" 2+1=3 $ A=2 $ echo \"A+1=$(( ${A} + 1 ))\" A+1=3 $ B=1 $ echo \"A+B=$(( ${A} + ${B} ))\" A+B=3 $ echo \"A-B=$(( ${A} - ${B} ))\" A-B=1 $ echo \"AxB=$(( ${A} * ${B} ))\" AxB=2 $ echo \"A/B=$(( ${A} / ${B} ))\" A/B=2 $ echo \"(A+B)x(A-B)=$(( $(( ${A} + ${B} )) * $(( ${A} - ${B} )) ))\" (A+B)x(A-B)=3 $ echo \"A^3=$(( ${A} ** 3 ))\" A^3=8 $ B=4 $ echo \"A^B=$(( ${A} ** ${B} ))\" A^B=16 $ echo \"B/A=$(( ${B} / ${A} ))\" 0 In the last example, the result is zero because this syntax is used for integer numbers. So, if the result of the operation is not an integer, it will be rounded to the nearest integer. In the next section you will learn how to operate with non-integer numbers .","title":"Usage of $(( OPERATION ))"},{"location":"math/#usage-of-num-and-num","text":"In order to increment the value of a variable by one, there are a couple of options. Some of these options will be very useful when doing iterations (which you will learn later on).","title":"Usage of ((++NUM)) and ((NUM++))"},{"location":"math/#num-1","text":"$ NUM=1 $ echo $(( ${NUM} + 1 )) 2 $ echo ${NUM} 1 The command echo $(( ${NUM} + 1 )) prints the result of NUM plus one, but it does not modify the value of NUM . For that reason, when NUM is echoed at the end, it still has value 1 (instead of 2).","title":"${NUM} + 1"},{"location":"math/#num","text":"$ NUM=1 $ echo $((++NUM)) 2 $ echo ${NUM} 2 The command echo $((++NUM)) is equivalent to this sequence of instructions: NUM=$(( ${NUM} + 1 )) echo ${NUM} First, increases the value of variable NUM in one, and then it echoes the result. Opposite to the example above, here the variable value is actually modified. And opposite to the example in the below, the variable value is modified before the other instruction ( echo ).","title":"((++NUM))"},{"location":"math/#num_1","text":"$ NUM=1 $ echo $((NUM++)) 1 $ echo ${NUM} 2 The command echo $((NUM++)) is equivalent to this sequence of instructions: echo ${NUM} NUM=$(( ${NUM} + 1 )) First echoes the value of NUM . Then, it increases the value of the variable.","title":"((NUM++))"},{"location":"math/#usage-of-num-and-num-","text":"Expressions ((--NUM)) and ((NUM--)) work in a very similar way than the previous ones, but instead of increasing the value of NUM by one, they decrease the value of NUM by one. These expressions will also be very useful once you learn iteration .","title":"Usage of ((--NUM)) and ((NUM--))"},{"location":"math/#num-1_1","text":"$ NUM=1 $ echo $(( ${NUM} - 1 )) 0 $ echo ${NUM} 1 The command echo $(( ${NUM} - 1 )) prints the result of NUM minus one, but it does not modify the value of NUM . For that reason, when NUM is echoed at the end, it still has value 1 (instead of 0).","title":"${NUM} - 1"},{"location":"math/#-num","text":"$ NUM=1 $ echo $((--NUM)) 0 $ echo ${NUM} 0 The command echo $((--NUM)) is equivalent to this sequence of instructions: NUM=$(( ${NUM} - 1 )) echo ${NUM} First, decreases the value of variable $NUM in one, and then it echoes the result. Opposite to the example above, here the variable value is actually modified. And opposite to the example below, the variable value is modified before the other instruction ( = ).","title":"((--NUM))"},{"location":"math/#num-","text":"$ NUM=1 $ echo $((NUM--)) 1 $ echo ${NUM} 0 The command echo $((NUM--)) is equivalent to this sequence of instructions: echo ${NUM} NUM=$(( ${NUM} - 1 )) First, echoes the value of NUM . Then, it decreases the value of the variable.","title":"((NUM--))"},{"location":"math/#usage-of-varnum","text":"This expression is a compact way of writing VAR=$(( ${VAR} + ${NUM} )) . Compact expression Extended equivalent ((A+=2)) A=$(( ${A} + 2 )) B=$((A+=2)) A=$(( ${A} + 2 )); B=${A} ((A+=B)) A=$(( ${A} + ${B} )) The value of B is not modified, only A is modified. B=$((A+=B)) A=$(( ${A} + ${B} )); B=${A} In this case the value of both A and B is modified because the result of ((A+=B)) is assigned to B .","title":"Usage of ((VAR+=NUM))"},{"location":"math/#usage-of-var-num","text":"This expression is a compact way of writing: VAR=$(( ${VAR} - ${NUM} )) Compact expression Extended equivalent ((A-=2)) A=$(( ${A} - 2 )) B=$((A-=2)) A=$(( ${A} - 2 )); B=${A} ((A-=B)) A=$(( ${A} - ${B} )) The value of B is not modified, only A is modified. B=$((A-=B)) A=$(( ${A} - ${B} )); B=${A} In this case the value of both A and B is modified because the result of ((A-=B)) is assigned to B .","title":"Usage of ((VAR-=NUM))"},{"location":"math/#usage-of-i-2","text":"$ for i in $(seq 10) > do > if (( $i % 2 )) > then > echo $i is odd > else > echo $i is even > fi > done 1 is odd 2 is even 3 is odd 4 is even 5 is odd 6 is even 7 is odd 8 is even 9 is odd 10 is even","title":"Usage of (( $i % 2 ))"},{"location":"math/#non-integer-calculations","text":"When programming in Bash, you will often need to do mathematical operations that involve non-integer calculations. To do this, you will need the bc utility. You can use this utility also for integer calculations, but it is normally left for advanced math. Syntax Usage echo \"OPERATION\" | bc Evaluates OPERATION . This can be any arithmetic operation with integer or non-integer numbers. Including addition ( + ), subtraction ( - ), multiplication ( * ), division ( / ), square root ( sqrt(NUM) ), exponentiation ( NUM**EXP ), etc. It will round the result to the closest integer. echo \"OPERATION\" | bc -l Flag -l will not round the result. Instead, will print it with all the decimals. echo \"scale=NDECIMALS; OPERATION\" | bc -l Will only print NDECIMALS instead of all the decimals.","title":"Non-integer calculations"},{"location":"math/#echo-operation-bc","text":"$ echo \"2.34 / 1.895\" | bc 1 $ echo \"2 / 3\" | bc 0","title":"echo \"OPERATION\" | bc"},{"location":"math/#echo-operation-bc-l","text":"$ echo \"2.34 / 1.895\" | bc -l 1.23482849604221635883 $ echo \"2 / 3\" | bc -l .66666666666666666666 $ A=$(echo \"2.34 / 1.895\" | bc) $ B=$(echo \"2.34 / 1.895\" | bc -l) $ echo ${A} 1 $ echo ${B} 1.23482849604221635883 $ echo \"${A} + ${B}\" | bc -l 2.23482849604221635883 $ echo \"${A} + ${B}\" 1 + 1.23482849604221635883 Look at the difference between the last two expressions. They are almost the same except for the | bc -l at the end of the first expression. Yet, the results are very different. That is because in the second case we are just printing the text \"\\${A} + \\${B}\", while in the first one we are evaluating the expression written in that text, with the use of the bc utility. The following example may clarify this concept: $ echo \"${A} + ${B}=$(echo \"${A} + ${B}\" | bc -l)\" 1 + 1.23482849604221635883=2.23482849604221635883 To find the square root of a number you use the expression sqrt() , like in many other programming languages. So, to find the square root of 10 and save it to variable a you would use the following command: $ A=$(echo \"sqrt (10)\" | bc -l) $ echo ${A} 3.16227766016837933199 Knowing this, you can do any type of operations with non-integer numbers. Just by writing the desired expression between the quotation marks, or combine integer and non-integer calculations. Let\u2019s look at a few more examples: $ echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l 4.39710615621059569082 $ echo $((2**3)) 12.397106156210595690828 $ echo \"(2.34 / 1.895) + sqrt (10) + $((2**3))\" | bc -l 12.39710615621059569082 $ echo \"(2.34 / 1.895) + sqrt (10) + 2^3\" | bc -l 12.39710615621059569082 $ echo \"2 + 2\" | bc -l 4 $ echo \"2 + 2\" 2 + 2 $ echo \"2 + 2 = $(echo \"2 + 2\" | bc -l)\" 2 + 2 = 4 $ A=$(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l) $ echo ${A} 4.39710615621059569082 $ echo $(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l) 4.39710615621059569082 $ echo \"(2.34 / 1.895) + sqrt (10)= $(echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l)\" (2.34 / 1.895) + sqrt (10)= 4.39710615621059569082","title":"echo \"OPERATION\" | bc -l"},{"location":"math/#echo-scalendecimals-operation-bc-l","text":"Clearly, some of the results of the previous examples have too many decimals. You can cut the number of decimals using scale . $ echo \"(2.34 / 1.895) + sqrt (10)\" | bc -l 4.39710615621059569082 $ echo \"scale=3; (2.34 / 1.895) + sqrt (10)\" | bc -l 4.396 $ echo \"scale=0; (2.34 / 1.895) + sqrt (10)\" | bc -l 4","title":"echo \"scale=NDECIMALS; OPERATION\" | bc -l"},{"location":"math/#comparing-non-integers","text":"In order to compare non-integers you can use awk . This function will be studied more in detail in later chapters as it is mainly used for processing files and strings. But as this example shows, it can also be used to deal with numbers. $ awk 'BEGIN{ print (2.41==2.4) ? \"equal\" : \"not equal\" }' not equal $ awk 'BEGIN{ print (2.41==2.41) ? \"equal\" : \"not equal\" }' equal","title":"Comparing non-integers"},{"location":"pdf/","text":"Manipulating PDF files","title":"PDF files"},{"location":"pdf/#manipulating-pdf-files","text":"","title":"Manipulating PDF files"},{"location":"permissions/","text":"File permissions","title":"File permissions"},{"location":"permissions/#file-permissions","text":"","title":"File permissions"},{"location":"remote_shell/","text":"Remote shell","title":"Remote shell"},{"location":"remote_shell/#remote-shell","text":"","title":"Remote shell"},{"location":"simple_scripts/","text":"Creating simple Bash scripts The vi editor This editor is installed by default in both Linux and MacOS and can be accessed and used through the terminal window. These are some of the advantages of vi: It is available in all Unix systems and any type of terminal. It doesn't require a lot of memory to run. So, if you are running heavy programs in your computer or your computer is old, vi is a good option because it won't slow down the machine anymore and will still load very fast. Even though there are a lot of commands that you must learn to become skilled in using this program, once you learn them you can use very short and fast commands to accomplish a lot of things. You can use it to code in any programming language. Some editors add special characters to the text and when you run scripts written in those editors, they could fail. vi doesn't add any special characters, and if a script has any, they are visible in the editor. If you don't like using your mouse too much, you don't have a mouse, or your mouse doesn't work properly, this editor is a good choice because you rarely need to use the mouse. Most things are accomplished using the keyboard. However, there are some disadvantages too: The learning curve can be steep, especially for people who are new to programming and not very comfortable with computers. If you're new to Bash, you not only need to learn the language, but also a whole set of commands specific to this program. Not being able to use your mouse can end up wasting your time while you learn all the commands that are used to scroll around the file or jump from one line to another. It doesn't give you any error messages or explanation of why it's not doing what you want. If you type the wrong command, it will just do nothing (or do the wrong thing). To create a new file, type (on the command line) vi file_path/file_name . The vi editor will open in the current terminal. This program runs in two modes, the command mode and the typing mode. By default, it opens in command mode. What this means is that anything you type is not actually being registered in the file but are commands. For example, if you type :q! as soon as you open the file, it will quit without saving (because :q! is the command for ignoring any modifications and exiting). If you type :w it will save changes to the file (or if you haven't write anything, it will just create an empty file). To change to typing mode, type a ( a is the command for entering typing mode). After you type a , you can start editing your file. To go back to command mode (for example to save changes), press the key esc (top left corner of the keyboard). Example: Open the vi editor, create a script that prints \"Hello Word\" , and save it with the file name helloword.sh Step 1: Open the vi editor vi helloword.sh Step 2: Type a to start editing the file. You will see that an --Insert-- message in the bottom of the terminal appears. This means that now you are in typing mode. - - - - - - - - - - -- INSERT -- Step 3: Start typing the commands that will go in your script. The simplest command, to print a message such as \"Hello World\" (or any other) is echo . echo \"Hello World!\" - - - - - - - - - - -- INSERT -- Step 4: Once you finish your script, press the esc key to enter command mode. You will see that the --Insert-- message at the bottom of the terminal disappears (this means that now you are in command mode). echo \"Hello World!\" - - - - - - - - - - Step 5: Save changes and exit the vi editor. In order to do this, type :wq (to write and quit at the same time). echo \"Hello World!\" - - - - - - - - - - :wq List of vi commands The table below shows the most commonly used commands for vi. In general, a number preceding any vi command will tell vi to repeat the command that number of times. For example, p is the command for pasting. If you write (in command mode) 2p , vi will paste whatever you copied two times where the cursor is currently located. Key/command Action [ESC] Switch to command mode [ctrl] b Scroll backward one screen. [ctrl] d Scroll down half screen. [ctrl] f Scroll forward one screen. [ctrl] f Scroll forward one screen. [ctrl] u Scroll up half screen. . Repeat last command. $ Go to end of line. ? string Search backward for string . / string Search forward for string . :0 Go to beginning of line. :N Go to line N . :N,Md Delete lines N to M . :N,MmP Move lines N to M and paste them after line P . :N,MmP Copy lines N to M and paste them after line P . :N,Mw file Save lines N to M to file . :q Quit (does not save any changes). :q! Ignore any modifications made and quit. :%s/old/new/option Searches and replaces the string old by the string new in the entire file. The following letters can be added in the field option: c to prompt for confirmation, g to replace all the occurrences of the string. :s/old/new/option Searches and replaces the string old by the string new in the line in which the cursor is located. The following letters can be added in the field option: c to prompt for confirmation, g to replace all the occurrences of the string. :set ignorecase Ignore case sensitivity during search. :set noignorecase Restore case sensitivity during search. :set number Turn on line numbering. :set nonumber Turn off line numbering. :syntax on Turn on syntax colors in the text. :syntax off Turn off syntax colors in the text. :w Save changes. :w file Save changes to file . :wq Save changes and quit. :x Save changes and quit. a Switch to editing mode and continue writing where the cursor is located. A Switch to editing mode and continue writing at the end of the line where the cursor is located. I Switch to editing mode and continue writing at the beginning of the line where the cursor is located. cw Delete the rest of the word in which the cursor is located (keeps the characters located before the cursor). D Delete the rest of the line in which the cursor is located (keeps the characters and words located before the cursor). dd Delete the entire line where the cursor is located. dw Delete the whole word in which the cursor is located. J Put the next line at the end of the line where the cursor is located. o Open line below cursor. O Open line above cursor. p Paste below current line. P Paste above current line. :u Undo previous command. :U Undo all changes to line. x Delete text at cursor. X Delete (backspace) text at cursor. yy Copy line in which the cursor is located. Other editors There is an unlimited number of editors and the choice of which to use is totally personal. The following editors are available for both Linux and MacOS (among many others): vim emacs gedit (which is also installed by default in Linux and uses a GUI, great for beginners) Eclipse : this is a lot more than an editor; it is a development environment used for programming in many other languages and for software development and modeling. VS Code : this editor has intelligent code completion and allows version control with Git. It also has support for many other programming languages. The following are editors available only for MacOS (among many others): Xcode TextMate Tips Albeit not mandatory, the first line of any Bash script should be the shebang ( #!/bin/bash ). It indicates that the script is written in Bash (instead of tcsh, for example) and that the Bash interpreter should execute it. Be organized when writing scripts. As you start writing longer and more complicated programs, this will become more important. Comment as often as possible, so that other programmers can understand what your script is doing, which parameters are needed and what they mean, or what the output means. To insert a comment, start the line with a hash ( # ). Use indentation to know where pieces of code start and end (for example when doing loops). Use appropriate variable names. Use names that are associated to the structure you're using (for example, if you're creating an array, naming it array will help you remember that this variable is an array and not a string or a number). Use short variable names. For example, instead of naming a variable myListOfSubjects , you can call it subjList . Use the following commands at the beginning of any script: set -e : this will make the program exit as soon as it encounters an error, preventing it from running commands on wrong data. set -u : this will make the program exit when using undeclared variables, preventing it from executing the wrong commands if you misspell a variable name. Use double quotes ( \" ) when declaring a string, single quotes ( ' ) when declaring a character, and no quotes when declaring numbers. This will prevent word splitting (when declaring a string that has spaces) and other errors in your code. Use functions . This will make your code more readable, reusable, and will allow you to run only parts of the code without having to comment all the lines when debugging. If you are declaring a variable whose value should never change, use the word readonly before the variable name. For example, if you want to declare a variable called age with value 30 and this value should never be replaced, then you should declare readonly age=30 . If at some point in the script you try to replace the value of that variable, you will get an error message: -bash: age: readonly variable . Running a script To run a script, first make it runnable using the chmod command shown below and then type the path and name of the file in the command line and press enter. For example, to execute a script located in the Desktop called helloWord.sh : chmod 775 /home/myuser/Desktop/helloWord.sh /home/myuser//Desktop/helloWord.sh","title":"Getting started"},{"location":"simple_scripts/#creating-simple-bash-scripts","text":"","title":"Creating simple Bash scripts"},{"location":"simple_scripts/#the-vi-editor","text":"This editor is installed by default in both Linux and MacOS and can be accessed and used through the terminal window. These are some of the advantages of vi: It is available in all Unix systems and any type of terminal. It doesn't require a lot of memory to run. So, if you are running heavy programs in your computer or your computer is old, vi is a good option because it won't slow down the machine anymore and will still load very fast. Even though there are a lot of commands that you must learn to become skilled in using this program, once you learn them you can use very short and fast commands to accomplish a lot of things. You can use it to code in any programming language. Some editors add special characters to the text and when you run scripts written in those editors, they could fail. vi doesn't add any special characters, and if a script has any, they are visible in the editor. If you don't like using your mouse too much, you don't have a mouse, or your mouse doesn't work properly, this editor is a good choice because you rarely need to use the mouse. Most things are accomplished using the keyboard. However, there are some disadvantages too: The learning curve can be steep, especially for people who are new to programming and not very comfortable with computers. If you're new to Bash, you not only need to learn the language, but also a whole set of commands specific to this program. Not being able to use your mouse can end up wasting your time while you learn all the commands that are used to scroll around the file or jump from one line to another. It doesn't give you any error messages or explanation of why it's not doing what you want. If you type the wrong command, it will just do nothing (or do the wrong thing). To create a new file, type (on the command line) vi file_path/file_name . The vi editor will open in the current terminal. This program runs in two modes, the command mode and the typing mode. By default, it opens in command mode. What this means is that anything you type is not actually being registered in the file but are commands. For example, if you type :q! as soon as you open the file, it will quit without saving (because :q! is the command for ignoring any modifications and exiting). If you type :w it will save changes to the file (or if you haven't write anything, it will just create an empty file). To change to typing mode, type a ( a is the command for entering typing mode). After you type a , you can start editing your file. To go back to command mode (for example to save changes), press the key esc (top left corner of the keyboard). Example: Open the vi editor, create a script that prints \"Hello Word\" , and save it with the file name helloword.sh Step 1: Open the vi editor vi helloword.sh Step 2: Type a to start editing the file. You will see that an --Insert-- message in the bottom of the terminal appears. This means that now you are in typing mode. - - - - - - - - - - -- INSERT -- Step 3: Start typing the commands that will go in your script. The simplest command, to print a message such as \"Hello World\" (or any other) is echo . echo \"Hello World!\" - - - - - - - - - - -- INSERT -- Step 4: Once you finish your script, press the esc key to enter command mode. You will see that the --Insert-- message at the bottom of the terminal disappears (this means that now you are in command mode). echo \"Hello World!\" - - - - - - - - - - Step 5: Save changes and exit the vi editor. In order to do this, type :wq (to write and quit at the same time). echo \"Hello World!\" - - - - - - - - - - :wq","title":"The vi editor"},{"location":"simple_scripts/#list-of-vi-commands","text":"The table below shows the most commonly used commands for vi. In general, a number preceding any vi command will tell vi to repeat the command that number of times. For example, p is the command for pasting. If you write (in command mode) 2p , vi will paste whatever you copied two times where the cursor is currently located. Key/command Action [ESC] Switch to command mode [ctrl] b Scroll backward one screen. [ctrl] d Scroll down half screen. [ctrl] f Scroll forward one screen. [ctrl] f Scroll forward one screen. [ctrl] u Scroll up half screen. . Repeat last command. $ Go to end of line. ? string Search backward for string . / string Search forward for string . :0 Go to beginning of line. :N Go to line N . :N,Md Delete lines N to M . :N,MmP Move lines N to M and paste them after line P . :N,MmP Copy lines N to M and paste them after line P . :N,Mw file Save lines N to M to file . :q Quit (does not save any changes). :q! Ignore any modifications made and quit. :%s/old/new/option Searches and replaces the string old by the string new in the entire file. The following letters can be added in the field option: c to prompt for confirmation, g to replace all the occurrences of the string. :s/old/new/option Searches and replaces the string old by the string new in the line in which the cursor is located. The following letters can be added in the field option: c to prompt for confirmation, g to replace all the occurrences of the string. :set ignorecase Ignore case sensitivity during search. :set noignorecase Restore case sensitivity during search. :set number Turn on line numbering. :set nonumber Turn off line numbering. :syntax on Turn on syntax colors in the text. :syntax off Turn off syntax colors in the text. :w Save changes. :w file Save changes to file . :wq Save changes and quit. :x Save changes and quit. a Switch to editing mode and continue writing where the cursor is located. A Switch to editing mode and continue writing at the end of the line where the cursor is located. I Switch to editing mode and continue writing at the beginning of the line where the cursor is located. cw Delete the rest of the word in which the cursor is located (keeps the characters located before the cursor). D Delete the rest of the line in which the cursor is located (keeps the characters and words located before the cursor). dd Delete the entire line where the cursor is located. dw Delete the whole word in which the cursor is located. J Put the next line at the end of the line where the cursor is located. o Open line below cursor. O Open line above cursor. p Paste below current line. P Paste above current line. :u Undo previous command. :U Undo all changes to line. x Delete text at cursor. X Delete (backspace) text at cursor. yy Copy line in which the cursor is located.","title":"List of vi commands"},{"location":"simple_scripts/#other-editors","text":"There is an unlimited number of editors and the choice of which to use is totally personal. The following editors are available for both Linux and MacOS (among many others): vim emacs gedit (which is also installed by default in Linux and uses a GUI, great for beginners) Eclipse : this is a lot more than an editor; it is a development environment used for programming in many other languages and for software development and modeling. VS Code : this editor has intelligent code completion and allows version control with Git. It also has support for many other programming languages. The following are editors available only for MacOS (among many others): Xcode TextMate","title":"Other editors"},{"location":"simple_scripts/#tips","text":"Albeit not mandatory, the first line of any Bash script should be the shebang ( #!/bin/bash ). It indicates that the script is written in Bash (instead of tcsh, for example) and that the Bash interpreter should execute it. Be organized when writing scripts. As you start writing longer and more complicated programs, this will become more important. Comment as often as possible, so that other programmers can understand what your script is doing, which parameters are needed and what they mean, or what the output means. To insert a comment, start the line with a hash ( # ). Use indentation to know where pieces of code start and end (for example when doing loops). Use appropriate variable names. Use names that are associated to the structure you're using (for example, if you're creating an array, naming it array will help you remember that this variable is an array and not a string or a number). Use short variable names. For example, instead of naming a variable myListOfSubjects , you can call it subjList . Use the following commands at the beginning of any script: set -e : this will make the program exit as soon as it encounters an error, preventing it from running commands on wrong data. set -u : this will make the program exit when using undeclared variables, preventing it from executing the wrong commands if you misspell a variable name. Use double quotes ( \" ) when declaring a string, single quotes ( ' ) when declaring a character, and no quotes when declaring numbers. This will prevent word splitting (when declaring a string that has spaces) and other errors in your code. Use functions . This will make your code more readable, reusable, and will allow you to run only parts of the code without having to comment all the lines when debugging. If you are declaring a variable whose value should never change, use the word readonly before the variable name. For example, if you want to declare a variable called age with value 30 and this value should never be replaced, then you should declare readonly age=30 . If at some point in the script you try to replace the value of that variable, you will get an error message: -bash: age: readonly variable .","title":"Tips"},{"location":"simple_scripts/#running-a-script","text":"To run a script, first make it runnable using the chmod command shown below and then type the path and name of the file in the command line and press enter. For example, to execute a script located in the Desktop called helloWord.sh : chmod 775 /home/myuser/Desktop/helloWord.sh /home/myuser//Desktop/helloWord.sh","title":"Running a script"},{"location":"txt_csv/","text":"Manipulating text and csv files Writing files echo So far we have used echo to print text into the terminal. You can also use this utility to print text into a file (and create a new file if it doesn't exist): echo \"some text\" >> someFile.txt appends some text in a new line of someFile.txt and adds the new line character at the end. If someFile.txt didn't exist, the file is created. If you add the flag -n , Bash won't print the trailing newline character: echo -n \"some text\" >> someFile.txt . If you add the flag -e , Bash will interpret the character scape sequences in the text (see table below in the printf section for a list of scape sequences). If you use > instead of >> , the previous contents of the file (if it existed) will be erased and replaced with the new text that you are echoing. printf printf is a powerful tool that allows you to format the information before printing it in a file, the command line or another variable. For example, you can specify the format of any number that you print and the number of decimal points you want to use. You could even use this tool to change the format of a variable (i.e. from scientific notation to float) and save the result in a new variable instead of a file. You can also add tab or any character scape sequence to your text. Syntax: printf <format> <arguments> printf uses the format specified in <format> to print the objects (strings, numbers or variables) specified in <arguments> . In contrast with the echo command, printf does not print the text in a new line by default, in order to add a new line the following character scape sequence should be added at the end of <format> : \\n . Format <format> is a string that contains alphanumerical characters, character scape sequences and format specifications, each of which causes printing of the next successive argument. The table below shows the strings that can be used for formatting. One should specify one format per argument. For example, in the command printf \"%d %s\" 10 \"my_string\" , \"%d %s\" is the format, which indicates that the first argument after the format ( 10 ) should be printed as a decimal ( %d ). Then, there should be a space, and then the second argument ( my_string ) should be printed as a string ( %s ). In printf \"%d %s\\n\" 10 \"my_string\" , %d %s\\n is the format, which indicates that the first argument after the format ( 10 ) should be printed as a decimal ( %d ), followed by a space. The second argument ( string ) should be printed as a string ( %s ). It also indicates that after the second argument there should be a new-line character ( \\n ). \\n is a scape sequence. The list of scape sequences can be found bellow. If any of the arguments is a string with special characters, spaces or scape sequences , make sure to always surround it with quotation marks. Format option Meaning %% Prints the symbol % and no argument is used. For example, printf \"%%\" just prints a % . %b Prints the corresponding argument as a string. The scape sequences are interpreted instead of reading them as literal strings. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision). %c Prints the first character of the corresponding argument if it is a string or the first digit if it's a number. printf \"%c %c\" \"some string\" 199 will print s 1 . %d The corresponding argument is a positive or negative integer number. If no precision is specified, it just prints the number. Otherwise, adds zeros before the integer to achieve the number of digits specified in the precision. For example, printf \"%d %.5d\\n\" -2 2 prints -2 00002 . %e Prints the corresponding argument, which should be a number, in scientific notation. There will be one digit before the decimal point and six digits after the decimal point if no precision is specified (or the number of digits specified in the precision). Infinity is printed as inf and NaN as nan . For example, 234.567 equals 2.34567 \u00d7 102 in scientific notation. So, if we use printf \"%e\" 234.567 , the result will be 2.345670e+02 . %f Prints the corresponding argument, which should be a number, in floating-point. The number of digits after the decimal point equals the precision or six digits if no precision was specified. Infinity is printed as inf and NaN as nan . For example, printf \"%f\\n\" 2.34567890123 will print 2.345679 and printf \"%.3f\\n\" -2.34567890123 will print -2.346 . %s Prints the corresponding argument as a string. The scape sequences are interpreted as literal strings. So, printf \"%s,%s\" \"text1\" \"text2\\ttext3\" will print text1,text2ttext3 , no tab introduced. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision). For example, printf \"%s\" \"example\" will print example , and printf \"%.3s\" \"example\" will print exa . Scape sequences Character scape sequence Meaning \\b Do not print the previous character (acts as backspace). For example, printf \"%b\" \"abcdef\" will print abcdef , while printf \"%b\" \"abc\\bdef\" will print abdef . \\c Suppresses any output after the sequence. For example, printf \"%b\" \"Hello\\c World\" will print only Hello . World will not be printed. \\n Write a new-line character. For example, printf \"%b\" \"abc\\ndef\" will print abc in one line, and def in another line. \\r Moves the cursor to the beginning of the current line. So, the following characters will replace the ones at the beginning of the line. For example, printf \"%b\" \"Happy World\\rLala\" prints Lalay World because Lala is written at the beginning of the line and replaces Happ . \\t Write a tab character. \\v Write a vertical tab. \\' Write a single quote character. \\\\ Write a backslash character. Save result to a variable You can save the output of printf into a variable instead of printing it. For example, if you have a number in scientific notation and you want to convert it to floating, you can type the following: $ FLOAT=$(printf \"%f\" 2.345670e+02) $ echo $FLOAT 234.567000 Reading files Reading line by line The cat command, followed by the path of a file, can be used to visualize the content of the file in the command line: $ cat subjectList.txt AA0083277 AA0084999 AC0208933 AC0148099 AD0190300 BB0299033 BC0345100 BD0365666 CA0372599 CA0381677 CB0384399 CC0384433 DD0385444 If you want to read a file line by line and run a set of instructions on each line, you can combine the cat and for commands. The following example reads the content of a file line by line (which contains a list of subject IDs) and copies that information into a new file with their group membership, which can be obtained from the first two letters of the subject ID. The first two letters of each line are extracted with ${line:0:2} . $ for line in $(cat subjectList.txt) > do > echo \"${line:0:2},${line}\" >> subjectInfo.txt > don The content of subjectInfo.txt after running those lines will be: AA,AA0083277 AA,AA0084999 AC,AC0208933 AC,AC0148099 AD,AD0190300 BB,BB0299033 BC,BC0345100 BD,BD0365666 CA,CA0372599 CA,CA0381677 CB,CB0384399 CC,CC0384433 DD,DD0385444 Doing statistics This is the content of infoFile.txt : SubjectID Group Gender Ethnicity Handedness Age Movement AA0083277 Control M Hispanic R 20 0.23525 AA0084999 Patient M Hispanic R 18 0.14564 AC0208933 Control F Hispanic R 17 0.18698 AC0148099 Control M NonHispanic R 21 0.19789 AD0190300 Patient M NonHispanic R 16 0.23454 BB0299033 Control F NonHispanic R 22 0.19752 BC0345100 Control M NonHispanic R 19 0.18789 BD0365666 Patient F NonHispanic R 17 0.14386 CA0372599 Patient F NonHispanic R 20 0.12384 CA0381677 Control F NonHispanic L 17 0.13453 CB0384399 Control F Hispanic R 18 0.45655 CC0384433 Control M NonHispanic R 15 0.13465 DD0385444 Patient M Hispanic R 16 0.32433 In this example we will calculate the minimum, maximum and average movement in the MRI scanner for the subjects in each group and gender. These values should be shown with only three decimals. There are many ways to do that, some of them a lot more efficient than the one presented here, using functions that we have not learn yet but that will be introduced further down in this document. We will use in this case the cat command to read from the file, the for loop, and some non-integer and array operations that have been learned from previous chapters. The for will read in each loop one line of the text file and extract the gender, group and movement values. Depending the group and gender, it will add the movement to one of the following arrays: CM: to save the movement of all male controls. CF: to save the movement of all female controls. PM: to save the movement of all male patients. PF: to save the movement of all female patients. In Bash it is not necessary to initialize an array. Instead, you can start adding values. The first time that you add a value to a non-existent array, it will be automatically initialized. When you ask Bash the size of an array that hasn\u2019t been initialized, it will return value zero. These are the steps to follow in order to calculate the minimum, maximum and average movement from the file: Create a loop that reads each line of the file (except the first one which is just a heather with column names). In each loop do the following: Split the line using the comma as a separator and save that in a variable called ARRAY . Obtain the subject group, which is located in the 2nd column (position 1 of the array). Remember, Bash arrays start in the position 0 (not the position 1). Obtain the subject gender, which is located in the 3rd column (position 2 of the array). Obtain the subject movement, which is located in the 7th column (position 6 of the array). Depending on the value of the group and gender, add movement to the corresponding array: If group equals Control and gender equals M (Male): Add the movement at the end of the array CM . If CM has zero values, the new item should be added to the position 0 If CM has one value, the new item should be added to the position 1 (because the existent item in the array will be in the position 0). Every new item is added to the position that is equal to the current size of the array. The size of an array can be obtained with ${#array[@]} . If group equals Control and gender equals F (Female): Add the movement at the end of the array CF . If group equals Patient and gender equals M : Add the movement at the end of the array PM . If group equals Patient and gender equals F : Add the movement at the end of the array PF . Sort the four arrays with the previously learned command: IFS=$'\\n' sorted=($(sort <<<\"${array[*]}\")) Show the minimum, maximum and average value of each array: Use printf instead of echo in order to show only three decimals per number. Minimum value: will be the first value in the sorted array. Maximum value: will be the last value in the sorted array (in the position SIZE_ARRAY\u20131 ). Average value: will equal to the sum of all values divided by the size of the array using IFS='+' avg=$(echo \"scale=1;(${array[*]})/${#array[@]}\"|bc) . Now, lets see this in actual code: First, loop through each line of the file, skipping the first row with the heathers using if [ $((n++)) -gt 0 ] : n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" GRP=${ARRAY[1]} GEN=${ARRAY[2]} MOV=${ARRAY[6]} if [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"M\" ] then CM[${#CM[@]}]=${MOV} fi if [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"F\" ] then CF[${#CF[@]}]=${MOV} fi if [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"M\" ] > then PM[${#PM[@]}]=${MOV} fi if [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"F\" ] then PF[${#PF[@]}]=${MOV} fi fi done Then, get the minimum, maximum and average values of the CM array (Controls, Males): IFS=$'\\n' sortedCM=($(sort <<<\"${CM[*]}\")) IFS='+' avg=$(echo \"scale=4;(${CM[*]})/${#CM[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedCM[0]} ${sortedCM[${#sortedCM[@]} -1]} $avg Now get the minimum, maximum and average values of the CF array (Controls, Females): IFS=$'\\n' sortedCF=($(sort <<<\"${CF[*]}\")) IFS='+' avg=$(echo \"scale=4;(${CF[*]})/${#CF[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedCF[0]} ${sortedCF[${#sortedCF[@]} -1]} $avg Get the minimum, maximum and average values of the PM array (Patients, Males): IFS=$'\\n' sortedPM=($(sort <<<\"${PM[*]}\")) IFS='+' avg=$(echo \"scale=4;(${PM[*]})/${#PM[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedPM[0]} ${sortedPM[${#sortedPM[@]} -1]} $avg Get the minimum, maximum and average values of the PF array (Patients, Females): IFS=$'\\n' sortedPF=($(sort <<<\"${PF[*]}\")) IFS='+' avg=$(echo \"scale=4;(${PF[*]})/${#PF[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedPF[0]} The number of lines in the loop could be reduced by simplifying the if expressions. The code below is equivalent to loop above, but uses less lines. In the chapter of Condition testing I explain in detail how to simplify if expressions: n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" GRP=${ARRAY[1]} GEN=${ARRAY[2]} MOV=${ARRAY[6]} [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"M\" ] && CM[${#CM[@]}]=${MOV} [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"F\" ] && CF[${#CF[@]}]=${MOV} [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"M\" ] && PM[${#PM[@]}]=${MOV} [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"F\" ] && PF[${#PF[@]}]=${MOV} fi done You could reduce even more the number of lines in the code of the loop: n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" [ \"${ARRAY[1]}\" == \"Control\" ] && [ \"${ARRAY[2]}\" == \"M\" ] && CM[${#CM[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Control\" ] && [ \"${ARRAY[2]}\" == \"F\" ] && CF[${#CF[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Patient\" ] && [ \"${ARRAY[2]}\" == \"M\" ] && PM[${#PM[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Patient\" ] && [ \"${ARRAY[2]}\" == \"F\" ] && PF[${#PF[@]}]=${ARRAY[6]} fi done Dealing with spaces In the previous example we read line by line a file using a for loop and the cat utility. This works most of the times. However, if you try to read this way a file in which one or more of the lines contain a space, Bash will read each word separated by a space as a separate line. For example, if file test.txt has the following content: a b c d e f g h i j When you try to read each line using a file, this is the result you will get: $ for line in $(cat test.txt) > do > echo $((i++)) $line > done 0 a 1 b 2 c 3 d 4 e 5 f 6 g 7 h 8 i 9 j To fix this problem you have to tell Bash that newline ( \\n ) is the only separator. You do this by declaring the system variable IFS=$'\\n' . $ IFS=$'\\n' $ for line in $(cat test.txt) > do > echo $((i++)) $line > done 0 a b 1 c d 2 e f 3 g h 4 i j Loading into an array $ ARRAY=($(cat test.txt)) $ echo ${ARRAY[0]} a b $ echo ${ARRAY[1]} c d $ echo ${ARRAY[2]} e f $ echo ${ARRAY[3]} g h $ echo ${ARRAY[4]} i j The read command So far, we have learned that using the for loop and the cat utility you can read each line of a file and separate it into different fields using a separator. However, csv files can become very difficult to separate into fields if some of them contain a comma (the same character that is being used as a separator), a space, or both. Example: Obtain the last field of line using the concepts learned before. $ line=\"SUBJ20\",\" Age 22-30\",\"VISIT1\",\"1\",\"DIAGN: Major Depressive Disorder, Single Episode, In Full Remission\" $ IFS=',' read -a ARRAY >>> \"$line\" $ echo \"The last fifth of line is: \"${ARRAY[4]} The fifth field of line is: DIAGN: Major Depressive Disorder However, this is not the correct result. The fifth field of line is \"DIAGN: Major Depressive Disorder, Single Episode, In Full Remission\" . But because we are using a comma as a separator, Bash is separating this field into separate columns. To solve this problem, you can read from the file descriptor and save each field in a separate variable using read . With read if one of the columns contains a comma, but is surrounded by quotation marks, it will read the text inside the quotation marks as a single field. Suppose that you have a file called example.csv with the following content: \"SUBJ1\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Major Depressive Disorder, Single Episode\" \"SUBJ2\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Bipolar, Schizophrenia\" \"SUBJ3\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Major Depressive Disorder\" \"SUBJ4\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Autism, Dyslexia, ADHD\" You want to read each line of the file and save the first and last fields into a new file called result.csv . You would accomplish that with the following code: Assign the file descriptor 3 (or any integer number) to example.csv: exec 3< example.csv Obtain the number of lines in the input file: $ N=$(cat example.csv | wc -l) $ echo $N 4 Iterate through all the lines of the file: $ i=0 $ while [ $((i++)) -lt $N ] > do > IFS=',' read -u 3 f1 f2 f3 f4 # Save each field in a different variable. Variable f1 will contain the 1st field, variable f2 the second field, etc. > echo \"$f1,$f4\" >> result.csv # Write the value of the first and last fields into the output file. > done You must close the file descriptor using the following command (replace number 3 by the corresponding file descriptor): exec 3<&- Finally, read the content of the output file $ cat result.csv \"SUBJ1\",\"DIAGN: Major Depressive Disorder, Single Episode\" \"SUBJ2\",\"DIAGN: Bipolar, Schizophrenia\" \"SUBJ3\",\"DIAGN: Major Depressive Disorder\" \"SUBJ4\",\"DIAGN: Autism, Dyslexia, ADHD\" In the following example we are going to read the same csv file from above called example.csv . The file has four columns. We are going to use the while loop to iterate through each line of the file and save the fields in variables f1 , f2 , f3 , f4 . Before starting to iterate, we have to tell Bash that comma will be the separator in each line with IFS=',' . $ IFS=',' $ i=1 $ while read f1 f2 f3 f4 > do > echo \"Line $((i++)):\" > echo \"Field 1: $f1\" > echo \"Field 2: $f2\" > echo \"Field 3: $f3\" > echo \"Field 4: $f4\" > done < example.csv Line 1: Field 1: \"SUBJ1\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Major Depressive Disorder, Single Episode\" Line 2: Field 1: \"SUBJ2\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Bipolar, Schizophrenia\" Line 3: Field 1: \"SUBJ3\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Major Depressive Disorder\" Line 4: Field 1: \"SUBJ4\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Autism, Dyslexia, ADHD\" awk awk is a Bash command that scans files and process their content using patterns. It reads each line of a file or a group of files searching for the specified pattern and each time that it finds the pattern, performs an associated action. This tool can extract specific lines or columns from files, merge files, search the content of one file in the other, etc. When reading each line of the specified files, awk will separate it into fields (columns) using the blank space as a separator. If your file uses a different separator (i.e. a comma), you must specify your separator using the -F flag (see syntax below). The different fields will be denoted $1 , $2 , $3 ... etc. $0 will refer to the entire line. If the field separator ( FS ) is null, each line will be split into one field per character. See the examples section for a better understanding of this command. Syntax: awk [ -F fs ] [ -v var=value ] [ 'pattern {action}' ] [ files ] | [ other functions ] Command Section Meaning -F fs (optional) Defines the input field separator to be the regular expression fs . Use this flag when the columns of your file use a separator other than a space. -v var=variableName (optional) When the value that is being search is stored in a variable, you should use this flag. See below for examples on how to use this flag. files List of files to be searched. other functions (optional) You can apply to the output of awk other functions such as head , tail , paste , grep , etc. grep grep searches a given pattern or text in a file or list of files. grep is able to find simple patterns and basic regular expressions, egrep can perform search of extended regular expressions. fgrep is quicker than both tools, but can only handle fixed patterns. zgrep , zegrep , and zfgrep act like grep , egrep , and fgrep , respectively, but accept compressed files as input. See the examples section for a better understanding of this command. Syntax: grep [flag] [pattern] [file(s)] grep Format Meaning grep my_string files Search the list of files for lines that contain my_string . grep '^my_expression' files Search for any lines that start with my_expression in the list of files. If my_expression contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. grep '^string' file.txt will search for any lines in file.txt that start with string. grep 'my_expression$' files Search for any lines that end with my_expression in the list of files. If my_expression contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. grep 'string$' file.txt matches any lines in file.txt that end with string . grep '^string$' file.txt matches any lines in file.txt that start and end with string . grep '[characters]' files Search for any lines that contain any of the characters enclosed between the brackets. Use a hyphen for a range of values. grep '[abcde]' file.txt matches any lines in file.txt that contain a , b , c , d or e . grep '[Ss]tring' file.txt matches any lines in file.txt that contain the words string or String. grep 'B[ai][dt]' file.txt matches any lines in file.txt that contain the words Bad , Bat , Bid or Bit (the second character can be a or i and the third character d or t ). grep '[0-9][0-9]' file.txt matches any lines in file.txt that contain a pair of numeric digits. grep '[a-zA-Z]' file.txt matches any lines in file.txt with at least one letter. grep '^$' file.txt matches any empty lines. grep '[^characters]' files Search for any lines that don't contain any of the characters enclosed between he brackets. Use a hyphen for a range of values. grep '[^a-zA-Z0-9]' file.txt matches any lines in file.txt that don't contain any letter or number (any lines that contain only special characters). grep 'character*' files The character preceding the asterisk is optional when matching lines. grep '\"*smug\"*' file.txt matches any lines in file.txt that contain smug or \"smug\" (with or without the quotes that precede the asterisks). grep 'my_expression\\{n\\}' files Match exactly n occurrences of my_expression . grep '[0-9]\\{3\\}-[0-9]\\{4\\}' file.txt matches any lines in file.txt that contain three digits, followed by a line and four digits. grep 'expression \\{n,\\}' files Match n or more occurrences of expression. grep '[0-9]\\{3,\\}' file.txt matches any lines in file.txt that contain three or more digits. Flag Meaning -A num Print num lines of trailing context after each match. -B num Print num lines of leading context before each match. -C num Print num lines of leading and trailing context surrounding each match. If num is not specified, num=2 . -c Print the number of matched lines per file instead of the actual lines. --color=when Mark up the matching text with the expression stored in the GREP_COLOR environment variable. The possible values of when can be: never , always or auto . -d action Specify the demanded action for directories. The possible values of action are: read (default), which means that the directories are read in the same manner as normal files; skip to silently ignore the directories, and recourse to read them recursively, which has the same effect as the -R and -r option. -e pattern To search for more than one pattern/expression, add the flag -e in front of each pattern/expression. --exclude If specified, it excludes files matching the given filename pattern from the search. Note that --exclude patterns take priority over --include patterns. Patterns are matched to the full path specified, not only to the filename component. --exclude-dir filename_pattern If -R is specified, it excludes directories matching the given filename_pattern from the search. -f file Read one or more newline separated patterns from file . Empty pattern lines match every input line. Newlines are not considered part of a pattern. If file is empty, nothing is matched. -h Omit the filename headers with output lines. --help Print a brief help message. --include If specified, only files matching the given filename pattern are searched. Note that --exclude patterns take priority over --include patterns. Patterns are matched to the full path specified, not only to the filename component. --include-dir filename_pattern If -R is specified, only directories matching the given filename_pattern are searched. Note that --exclude-dir patterns take priority over --include-dir patterns. -L Only the names of files not containing selected lines are listed. -l Only the names of files containing selected lines are listed. -m num Stop reading the file after num matches. -n Each output line is preceded by its relative line number in the file, starting at line 1. The line number counter is reset for each file processed. This option is ignored if -c , -L , -l , or -q is specified. --null Prints a zero-byte after the file name. -O If -R is specified, follow symbolic links only if they were explicitly listed on the command line. The default is not to follow symbolic links. -o Prints only the matching part of the lines. -q Suppress normal output. -R or -r Recursively search subdirectories listed. -S If -R is specified, all symbolic links are followed. The default is not to follow symbolic links. -s Suppress error messages from nonexistent or unreadable files. -V Display version information and exit. -v Selected lines are those not matching any of the specified patterns. -w The expression is searched for as a whole word. -x Show only the cases where the whole line equals the expression. -Z or -z Accepts compressed input files. --line-buffered Force output to be line buffered. By default, output is line buffered when standard output is a terminal and block buffered otherwise. Examples: awk and grep The following examples will show how to read and manipulate files using different command line tools. Each example will read one or more of the following files. file1.csv and file3.csv use comma as the separator between columns. On the other hand, file2.txt and file file4.txt use a space as the separator between columns. Content of file1.csv : \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\" Content of file2.txt : \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" \"B11130912\" \"Group2b\" \"900\" \"MissingData\" \"B11137244\" \"Group1\" \"450\" \"555\" \"B11154534\" \"Group1\" \"456\" \"456\" \"B11144100\" \"Group1\" \"450\" \"886\" \"B11137244\" \"Group1\" \"450\" \"456\" \"B12226566\" \"Group2b\" \"450\" \"MissingData\" \"B11134987\" \"Group1\" \"900\" \"MissingData\" \"B11144345\" \"Group1\" \"900\" \"776\" \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" \"B11156453\" \"Group4\" \"456\" \"2\" \"B11110676\" \"Group1\" \"900\" \"10\" \"C11138929\" \"Group2b\" \"2\" \"MissingData\" \"B11154532\" \"Group1\" \"456\" \"886\" \"B11155267\" \"Group3\" \"900\" \"10\" \"B11137120\" \"Group2b\" \"450\" \"456\" \"B33191224\" \"Group2b\" \"450\" \"776\" \"B11155267\" \"Group3\" \"900\" \"10\" \"C11138999\" \"Group2b\" \"900\" \"MissingData\" \"B11131605\" \"Group1\" \"456\" \"MissingData\" \"B11137784\" \"Group1\" \"900\" \"436\" \"B11156098\" \"Group1\" \"500\" \"886\" \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" \"C11138912\" \"Group2b\" \"900\" \"MissingData\" \"B11150911\" \"Group2b\" \"900\" \"117\" \"B11152577\" \"Group1\" \"900\" \"756\" \"B11156098\" \"Group1\" \"456\" \"886\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" Content of file3.csv : Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content of file4.txt : AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Reading specific columns Example 1: Print the first column of each file. In order to print the first column of these files, we will use awk . As it was shown before, this command has some optional flags followed by an action statement, and then the list of files. In this case, the action statement is '{print $1}' , because we want to print only the first column ( $1 ). file2.txt and file4.txt use a space as a column separator (which is the separator for default). So, to access the first column of these files we don't need the -F flag. However, file1.csv and file3.csv use a comma as a separator. So, in order for awk to distinguish the different columns, we have to use the -F flag with a comma ( -F',' ). Space-separated files: $ awk '{print $1}' file2.txt \"AnonymizedID\" \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"C11137159\" \"B11156453\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"B11135292\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" $ awk '{print $1}' file4.txt AnonymizedID B11108326 B11110893 B11119909 D11144030 D11144030 B11119903 C11131039 C11133100 C11135566 C11137159 C11137159 C11137167 C11137167 C11137439 C11137439 C11137443 C11137544 C11137123 C11138150 C11138152 C11138797 C11138184 C11138122 C11138122 C11138192 B12226507 B12226546 Comma-separated files: $ awk -F',' '{print $1}' file1.csv \"Anonymized ID\" \"B33199522\" \"B33199603\" \"B11137879\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11153927\" \"B11177579\" \"B11177806\" \"B11157958\" \"B11110690\" \"B11152799\" \"B11154358\" \"B11110925\" \"B11135291\" \"B11135072\" \"B33199603\" \"B11137879\" \"B11131605\" \"B11110927\" \"B11147712\" \"B33191224\" \"B11131290\" \"B11157974\" \"B33191224\" \"B11141503\" \"C11137159\" \"B33199522\" $ awk -F',' '{print $1}' file3.csv AnonymizedID C11138122 C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11137167 C11137159 C11137167 C11137159 C11131039 C11135566 B11119903 C11137544 C11137443 C11137123 C11137439 C11137439 C11133100 D11144030 B11108399 B11108326 B11119909 B11110893 To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): Space-separated files: $ awk '{print NR,$1}' file2.txt 1 \"AnonymizedID\" 2 \"B11130912\" 3 \"B11137244\" 4 \"B11154534\" 5 \"B11144100\" 6 \"B11137244\" 7 \"B12226566\" 8 \"B11134987\" 9 \"B11144345\" 10 \"C11137159\" 11 \"B11156453\" 12 \"B11110676\" 13 \"C11138929\" 14 \"B11154532\" 15 \"B11155267\" 16 \"B11137120\" 17 \"B33191224\" 18 \"B11155267\" 19 \"C11138999\" 20 \"B11131605\" 21 \"B11137784\" 22 \"B11156098\" 23 \"B11133232\" 24 \"B11135292\" 25 \"C11138912\" 26 \"B11150911\" 27 \"B11152577\" 28 \"B11156098\" 29 \"B11133232\" $ awk '{print NR, $1}' file4.txt 1 AnonymizedID 2 B11108326 3 B11110893 4 B11119909 5 D11144030 6 D11144030 7 B11119903 8 C11131039 9 C11133100 10 C11135566 11 C11137159 12 C11137159 13 C11137167 14 C11137167 15 C11137439 16 C11137439 17 C11137443 18 C11137544 19 C11137123 20 C11138150 21 C11138152 22 C11138797 23 C11138184 24 C11138122 25 C11138122 26 C11138192 27 B12226507 28 B12226546 Comma-separated files: $ awk -F',' '{print NR, $1}' file1.csv 1 \"Anonymized ID\" 2 \"B33199522\" 3 \"B33199603\" 4 \"B11137879\" 5 \"B11144410\" 6 \"B11110455\" 7 \"B11135291\" 8 \"B11153927\" 9 \"B11177579\" 10 \"B11177806\" 11 \"B11157958\" 12 \"B11110690\" 13 \"B11152799\" 14 \"B11154358\" 15 \"B11110925\" 16 \"B11135291\" 17 \"B11135072\" 18 \"B33199603\" 19 \"B11137879\" 20 \"B11131605\" 21 \"B11110927\" 22 \"B11147712\" 23 \"B33191224\" 24 \"B11131290\" 25 \"B11157974\" 26 \"B33191224\" 27 \"B11141503\" 28 \"C11137159\" 29 \"B33199522\" $ awk -F',' '{print NR, $1}' file3.csv 1 Anonymized ID 2 C11138122 3 C11138192 4 B12226507 5 B12226546 6 C11138122 7 C11138184 8 C11138797 9 C11138152 10 C11138150 11 C11137167 12 C11137159 13 C11137167 14 C11137159 15 C11131039 16 C11135566 17 B11119903 18 C11137544 19 C11137443 20 C11137123 21 C11137439 22 C11137439 23 C11133100 24 D11144030 25 B11108399 26 B11108326 27 B11119909 28 B11110893 Example 2: Print the first column of file1.csv and file2.txt in reverse order . In order to print starting with the last line and ending with the first line, you can use the command tail with the flag -r (for reverse) after awk . Bash will first execute the awk command, which is written before the pipe ( | ), and then it will run tail , which inverts the order of the previous output. Remember that for file1.csv you need to use -F',' to indicate that the columns are separated by commas and not spaces. Space-separated file: $ awk '{print $1}' file2.txt | tail -r \"B11133232\" \"B11156098\" \"B11152577\" \"B11150911\" \"C11138912\" \"B11135292\" \"B11133232\" \"B11156098\" \"B11137784\" \"B11131605\" \"C11138999\" \"B11155267\" \"B33191224\" \"B11137120\" \"B11155267\" \"B11154532\" \"C11138929\" \"B11110676\" \"B11156453\" \"C11137159\" \"B11144345\" \"B11134987\" \"B12226566\" \"B11137244\" \"B11144100\" \"B11154534\" \"B11137244\" \"B11130912\" \"AnonymizedID\" Comma-separated file: $ awk -F',' '{print $1}' file1.csv | tail -r \"B33199522\" \"C11137159\" \"B11141503\" \"B33191224\" \"B11157974\" \"B11131290\" \"B33191224\" \"B11147712\" \"B11110927\" \"B11110603\" \"B11137879\" \"B33199603\" \"B11135072\" \"B11135291\" \"B11110925\" \"B11154358\" \"B11152799\" \"B11110690\" \"B11157958\" \"B11177806\" \"B11177579\" \"B11153927\" \"B11135291\" \"B11110455\" \"B11144410\" \"B11137879\" \"B33199603\" \"B33199522\" \"Anonymized ID\" The same as in example 1, to precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): Space-separated file: $ awk '{print NR, $1}' file2.txt | tail -r 29 \"B11133232\" 28 \"B11156098\" 27 \"B11152577\" 26 \"B11150911\" 25 \"C11138912\" 24 \"B11135292\" 23 \"B11133232\" 22 \"B11156098\" 21 \"B11137784\" 20 \"B11131605\" 19 \"C11138999\" 18 \"B11155267\" 17 \"B33191224\" 16 \"B11137120\" 15 \"B11155267\" 14 \"B11154532\" 13 \"C11138929\" 12 \"B11110676\" 11 \"B11156453\" 10 \"C11137159\" 9 \"B11144345\" 8 \"B11134987\" 7 \"B12226566\" 6 \"B11137244\" 5 \"B11144100\" 4 \"B11154534\" 3 \"B11137244\" 2 \"B11130912\" 1 \"AnonymizedID\" Comma-separated file: $ awk -F',' '{print NR, $1}' file1.csv | tail -r 29 \"B33199522\" 28 \"C11137159\" 27 \"B11141503\" 26 \"B33191224\" 25 \"B11157974\" 24 \"B11131290\" 23 \"B33191224\" 22 \"B11147712\" 21 \"B11110927\" 20 \"B11110603\" 19 \"B11137879\" 18 \"B33199603\" 17 \"B11135072\" 16 \"B11135291\" 15 \"B11110925\" 14 \"B11154358\" 13 \"B11152799\" 12 \"B11110690\" 11 \"B11157958\" 10 \"B11177806\" 9 \"B11177579\" 8 \"B11153927\" 7 \"B11135291\" 6 \"B11110455\" 5 \"B11144410\" 4 \"B11137879\" 3 \"B33199603\" 2 \"B33199522\" 1 \"Anonymized ID\" Example 3: Print the second and third columns of file2.txt . In the previous examples we used the action statement '{print $1}' to print the first column. Since we now want to print the second and third columns instead of the first one, we replace $1 by $2,$3 . If you wanted to print columns 4 and 5 instead, you would simply use $4,$5 , etc. $ awk '{print $2,$3}' file2.txt \"SubjectGroup\" \"TEST1\" \"Group2b\" \"900\" \"Group1\" \"450\" \"Group1\" \"456\" \"Group1\" \"450\" \"Group1\" \"450\" \"Group2b\" \"450\" \"Group1\" \"900\" \"Group1\" \"900\" \"Group3\" \"MissingData\" \"Group4\" \"456\" \"Group1\" \"900\" \"Group2b\" \"2\" \"Group1\" \"456\" \"Group3\" \"900\" \"Group2b\" \"450\" \"Group2b\" \"450\" \"Group3\" \"900\" \"Group2b\" \"900\" \"Group1\" \"456\" \"Group1\" \"900\" \"Group1\" \"500\" \"Group1\" \"500\" \"Group3\" \"MissingData\" \"Group2b\" \"900\" \"Group2b\" \"900\" \"Group1\" \"900\" \"Group1\" \"456\" \"Group1\" \"456\" To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): $ awk '{print NR,$2,$3}' file2.txt 1 \"SubjectGroup\" \"TEST1\" 2 \"Group2b\" \"900\" 3 \"Group1\" \"450\" 4 \"Group1\" \"456\" 5 \"Group1\" \"450\" 6 \"Group1\" \"450\" 7 \"Group2b\" \"450\" 8 \"Group1\" \"900\" 9 \"Group1\" \"900\" 10 \"Group3\" \"MissingData\" 11 \"Group4\" \"456\" 12 \"Group1\" \"900\" 13 \"Group2b\" \"2\" 14 \"Group1\" \"456\" 15 \"Group3\" \"900\" 16 \"Group2b\" \"450\" 17 \"Group2b\" \"450\" 18 \"Group3\" \"900\" 19 \"Group2b\" \"900\" 20 \"Group1\" \"456\" 21 \"Group1\" \"900\" 22 \"Group1\" \"500\" 23 \"Group1\" \"500\" 24 \"Group3\" \"MissingData\" 25 \"Group2b\" \"900\" 26 \"Group2b\" \"900\" 27 \"Group1\" \"900\" 28 \"Group1\" \"456\" 29 \"Group1\" \"456\" Example 4: Print the second and third columns of file1.csv in reverse order . In order to print the output in reverse order for file1.csv , use the tail -r command after the awk . $ awk -F',' '{print $2,$3}' file1.csv | tail -r \"Group1\" \"0\" \"Group3\" \"9\" \"Group3\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group2 b\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"MISSING\" \"0\" \"Group3\" \"9\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group3\" \"0\" \"Group1\" \"MD\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group2 b\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group1\" \"0\" \"Subject Group\" \"HASCONDITION\" To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): $ awk -F',' '{print NR,$2,$3}' file1.csv | tail -r 29 \"Group1\" \"0\" 28 \"Group3\" \"9\" 27 \"Group3\" \"0\" 26 \"Group2 b\" \"0\" 25 \"Group1\" \"0\" 24 \"Group2 b\" \"0\" 23 \"Group2 b\" \"0\" 22 \"Group1\" \"0\" 21 \"Group1\" \"0\" 20 \"Group1\" \"0\" 19 \"Group1\" \"0\" 18 \"Group3\" \"0\" 17 \"MISSING\" \"0\" 16 \"Group3\" \"9\" 15 \"Group1\" \"0\" 14 \"Group1\" \"0\" 13 \"Group1\" \"0\" 12 \"Group3\" \"0\" 11 \"Group3\" \"0\" 10 \"Group1\" \"MD\" 9 \"Group2 b\" \"0\" 8 \"Group1\" \"0\" 7 \"Group3\" \"0\" 6 \"Group2 b\" \"0\" 5 \"Group2 b\" \"0\" 4 \"Group1\" \"0\" 3 \"Group3\" \"0\" 2 \"Group1\" \"0\" 1 \"Subject Group\" \"HASCONDITION\" Example 5: Print all the columns of file1.csv showing the lines in reverse order . To print all the columns of a file using awk , use $0 (instead of a column number). Or use the command cat . Using awk : awk -F',' '{print $0}' file1.csv | tail -r Using cat : cat file1.csv | tail -r Example 6: Print all the columns of file1.csv in reversed order , and save the re-ordered columns in a new file called file1_reordered.csv . If you were going to print the columns one to three in normal order, you would use '{print $1,$2,$3}' . To print them in reverse order, you just reverse the order of the columns in print , like so: '{print $3,$2,$1}' . To save the output to a file instead of showing it in the terminal, use >> file_name , as explained in previous sections. Remember to use the -F',' flag to indicate that the columns are separated by commas, and not the default space. awk -F',' '{print $3,$2,$1}' file1.csv >> file1_reordered.csv Example 7: Print the columns and lines of file1.csv in reverse order Use the same command as before, adding | tail -r at the end to invert also the lines. awk -F',' '{print $3,$2,$1}' file1.csv | tail -r Example 8: Read the second column of file1.csv and save it into an array. When saving a column of a file into an array, you must specify that the elements of the array are separated by new lines ( '\\n' ). You do this using the command IFS=$'\\n' . The elements of the array will be saved in the variable ARRAY . Remember that to access the individual elements of ARRAY you use ${ARRAY[index]} . With index starting at 0. So, to access the first element the command is echo ${ARRAY[0]} . To access the second element it is echo ${ARRAY[1]} , etc. Type echo ${ARRAY[@]} to view all the elements of the array. Remember, the system variable IFS contains the separator that is being used to separate each field within the lines of a file. You can change the value of this variable at any time by using IFS='character' , where character is the one separating the fields. $ IFS=$'\\n' $ ARRAY=($(awk -F',' '{print $2}' file1.csv)) $ echo ${ARRAY[0]} \"Subject Group\" $ echo ${ARRAY[1]} \"Group1\" $ echo ${ARRAY[@]} \"Subject Group\" \"Group1\" \"Group3\" \"Group1\" \"Group2 b\" \"Group2 b\" \"Group3\" \"Group1\" \"Group2 b\" \"Group1\" \"Group3\" \"Group3\" \"Group1\" \"Group1\" \"Group1\" \"Group3\" \"MISSING\" \"Group3\" \"Group1\" \"Group1\" \"Group1\" \"Group1\" \"Group2 b\" \"Group2 b\" \"Group1\" \"Group2 b\" \"Group3\" \"Group3\" \"Group1\" $ echo ${#ARRAY[@]} 29 Example 9: Print the first column of file2.txt followed by the first column of file4.txt . To print a specific column for more than one file, you use the same command, adding the list of files you want to print after the first one. However, all the files in the list must use the same column separator. Since the column separator for this list of files is a space (the default), you don't need to use the -F flag. awk '{print $1}' file2.txt file4.txt Example 10: Print the first column of file3.csv followed by the first column of file1.csv . Since the column separator for this list of files is a comma, you need to use the -F',' flag. awk -F',' '{print $1}' file3.csv file1.csv Sorting columns Example 1: Print the first column of file1.csv and file2.txt in alphabetical order . First, use awk to print the desired column. Then, use sort to sort it in alphabetical order. Space-separated file: $ awk '{print $1}' file2.txt | sort \"AnonymizedID\" \"B11110676\" \"B11130912\" \"B11131605\" \"B11133232\" \"B11133232\" \"B11134987\" \"B11135292\" \"B11137120\" \"B11137244\" \"B11137244\" \"B11137784\" \"B11144100\" \"B11144345\" \"B11150911\" \"B11152577\" \"B11154532\" \"B11154534\" \"B11155267\" \"B11155267\" \"B11156098\" \"B11156098\" \"B11156453\" \"B12226566\" \"B33191224\" \"C11137159\" \"C11138912\" \"C11138929\" \"C11138999\" Comma-separated file: $ awk -F ',' '{print $1}' file1.csv | sort \"Anonymized ID\" \"B11110455\" \"B11110603\" \"B11110690\" \"B11110925\" \"B11110927\" \"B11131290\" \"B11135072\" \"B11135291\" \"B11135291\" \"B11137879\" \"B11137879\" \"B11141503\" \"B11144410\" \"B11147712\" \"B11152799\" \"B11153927\" \"B11154358\" \"B11157958\" \"B11157974\" \"B11177579\" \"B11177806\" \"B33191224\" \"B33191224\" \"B33199522\" \"B33199522\" \"B33199603\" \"B33199603\" \"C11137159\" Example2: Print the first column of file1.csv and file2.txt in alphabetical removing any duplicate values . Use awk to print the desired column, followed by sort | uniq to sort and remove the duplicates on the result. Space-separated file: $ awk '{print $1}' file2.txt | sort | uniq \"AnonymizedID\" \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"C11137159\" \"B11156453\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"B11135292\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" Comma-separated file $ awk -F ',' '{print $1}' file1.csv | sort | uniq \"Anonymized ID\" \"B33199522\" \"B33199603\" \"B11137879\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11153927\" \"B11177579\" \"B11177806\" \"B11157958\" \"B11110690\" \"B11152799\" \"B11154358\" \"B11110925\" \"B11135291\" \"B11135072\" \"B33199603\" \"B11137879\" \"B11110603\" \"B11110927\" \"B11147712\" \"B33191224\" \"B11131290\" \"B11157974\" \"B33191224\" \"B11141503\" \"C11137159\" \"B33199522\" Example 4: Print the first column of file1.csv and file3.csv combined, in alphabetical order and with no duplicates. Use awk with the list of files to be read ( file1.csv file3.csv ) as arguments. Then, use | sort to organize the output in alphabetical order, and finally use | uniq to remove the duplicates. In this case, because the strings in file1.csv all start by colons, while the values in file3.csv don't, then all the values of file1.csv will be printed before those of file3.csv , because alphabetically, special characters such as \" go before any letter (including A). So, for Bash \"B11110455\" goes before Anonymized ID . $ awk -F ',' '{print $1}' file1.csv file3.csv | sort | uniq \"Anonymized ID\" \"B11110455\" \"B11110603\" \"B11110690\" \"B11110925\" \"B11110927\" \"B11131290\" \"B11135072\" \"B11135291\" \"B11137879\" \"B11141503\" \"B11144410\" \"B11147712\" \"B11152799\" \"B11153927\" \"B11154358\" \"B11157958\" \"B11157974\" \"B11177579\" \"B11177806\" \"B33191224\" \"B33199522\" \"B33199603\" \"C11137159\" Anonymized ID B11108326 B11108399 B11110893 B11119903 B11119909 B12226507 B12226546 C11131039 C11133100 C11135566 C11137123 C11137159 C11137167 C11137439 C11137443 C11137544 C11138122 C11138150 C11138152 C11138184 C11138192 C11138797 D11144030 paste Horizontal concatenation Example1: Concatenate all the columns of file2.txt and file4.txt horizontally, using a space as separator between the columns of one file and the other. $ paste -d ' ' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" AnonymizedID SubjectGroup AGE B11108399 Group1 23b\" \"900\" \"MissingData\" B11108326 Group1 59 \"B11137244\" \"Group1\" \"450\" \"555\" B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\" B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\" D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\" D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\" B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\" C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\" C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\" C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\" C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\" C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\" C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\" C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\" C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\" C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\" C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\" C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\" C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\" C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\" C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\" C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\" C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\" C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\" B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\" B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\" Example 2: Concatenate all the columns of file2.txt and file4.txt horizontally using a semicolon as separator between the columns of one file and the other. $ paste -d ';' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\";AnonymizedID SubjectGroup AGE B11108399 Group1 23b\" \"900\" \"MissingData\";B11108326 Group1 59 \"B11137244\" \"Group1\" \"450\" \"555\";B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\";B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\";D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\";D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\";B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\";C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\";C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\";C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\";C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\";C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\";C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\";C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\";C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\";C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\";C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\";C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\";C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\";C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\";C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\";C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\";C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\";C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\";C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\";C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\";B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\";B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\"; Example 3: Concatenate all the columns of file2.txt and file4.txt . Use a newline character as separator between the columns of one file and the other. As a result, the two files will be interlined. In the output you will have the first line of file2.txt followed by the first line of file4.txt , followed by the second line of file2.txt , then the second line of file4.txt , etc. $ paste -d '\\n' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" AnonymizedID SubjectGroup AGE \"B11130912\" \"Group2b\" \"900\" \"MissingData\" B11108399 Group1 23 \"B11137244\" \"Group1\" \"450\" \"555\" B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\" B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\" D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\" D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\" B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\" C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\" C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\" C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\" C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\" C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\" C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\" C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\" C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\" C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\" C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\" C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\" C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\" C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\" C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\" C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\" C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\" C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\" B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\" B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\" Example 4: Print the first column of file2.txt followed (horizontally) by the second column of file4.txt . awk '{print $1}' file2.txt will read and print the first column of file2.txt . Conversely, awk '{print $2}' file4.txt will read and print the second column of file4.txt . You must use the following syntax to concatenate these two results horizontally: $ paste <(awk '{print $1}' file2.txt) <(awk '{print $2}' file4.txt) \"AnonymizedID\"\u2003SubjectGroup \"B11130912\"\u2003Group1 \"B11137244\"\u2003Group1 \"B11154534\"\u2003Group2 \"B11144100\"\u2003Group3 \"B11137244\"\u2003Group3 \"B12226566\"\u2003Group2 \"B11134987\"\u2003Group2 \"B11144345\"\u2003Group1 \"C11137159\"\u2003Group2 \"B11156453\"\u2003Group3 \"B11110676\"\u2003Group3 \"C11138929\"\u2003Group3 \"B11154532\"\u2003Group3 \"B11155267\"\u2003Group3 \"B11137120\"\u2003Group3 \"B33191224\"\u2003Group3 \"B11155267\"\u2003Group1 \"C11138999\"\u2003Group2 \"B11131605\"\u2003Group1 \"B11137784\"\u2003Group1 \"B11156098\"\u2003Group1 \"B11133232\"\u2003Group1 \"B11135292\"\u2003Group1 \"C11138912\"\u2003MISSING \"B11150911\"\u2003Group1 \"B11152577\"\u2003Group1 \"B11156098\"\u2003Group1 \"B11133232\" Example 5: Print the first column of file1.csv followed (horizontally) by the second column of file3.csv . Separate the columns with a comma. In this example, we use the same syntax as the example before, but because file1.csv and file3.csv use comma as the column separator, you have to use the -F',' flag in the awk commands. Additionally, remember to use the flag -d ',' for the paste command in order to separate the pasted columns with a comma. $ paste -d ',' <(awk -F',' '{print $1}' file1.csv) <(awk -F',' '{print $2}' file3.csv) \"Anonymized ID\",Subject Group \"B33199522\",MISSING \"B33199603\",Group1 \"B11137879\",Group1 \"B11144410\",Group1 \"B11110455\",Group1 \"B11135291\",Group1 \"B11153927\",Group1 \"B11177579\",Group1 \"B11177806\",Group1 \"B11157958\",Group3 \"B11110690\",Group3 \"B11152799\",Group3 \"B11154358\",Group3 \"B11110925\",Group2 b \"B11135291\",Group2 b \"B11135072\",Group2 b \"B33199603\",Group1 \"B11137879\",Group3 \"B11110603\",Group2 b \"B11110927\",Group3 \"B11147712\",Group3 \"B33191224\",Group1 \"B11131290\",Group3 \"B11157974\",Group1 \"B33191224\",Group1 \"B11141503\",Group2 b \"C11137159\",Group1 \"B33199522\", Reading specific lines Example 1: Print the first line of file1.csv . In order to print only the first line of the file, we first read it using the cat command, and then we select the first line from the previous output using head -n 1 . $ cat file1.csv | head -n 1 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" Example 2: Print the first two lines of file1.csv . In order to print only the first two lines of the file we first read it using the cat command, and then we select those lines from the previous output using head -n 2 . $ cat file1.csv | head -n 2 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" Example 3: Print the first three lines of file1.csv . $ cat file1.csv | head -n 3 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" Example 4: Print the last line of file1.csv . In order to print only the last line of the file we first read it using the cat command, and then we select the last line from the previous output using tail -n 1 . $ cat file1.csv | tail -n 1 \"B33199522\",\"Group1\",\"0\",\"\" Example 5: Print the last two lines of file1.csv . $ cat file1.csv | tail -n 2 \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\" Example 6: Print the last three lines of file1.csv in reverse . As we learned previously, the flag -r of tail command can be used to print things in reversed order. $ cat file1.csv | tail -r -n 3 \"B33199522\",\"Group1\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B11141503\",\"Group3\",\"0\",\"\" Example 7: Print from the second line until the end of the file for file1.csv (omit the first line). $ cat file1.csv | head -n+2 \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\" Searching a value In the following examples we will read specific columns or lines in a file or a list of files, that contain a searched value. Example 1: Print the line(s) of file3.csv that contain the string C11137439 . Using awk : $ awk '/C11137439/' file3.csv C11137439,Group3,79 C11137439,Group3,15 Using grep : $ grep C11137439 file3.csv C11137439,Group3,79 C11137439,Group3,15 Example 2: Print the line(s) of file3.csv that contain the string AAA (which is stored in a variable). Using awk : $ VAR=C11137439 $ awk -v var=$VAR '$0~var' file3.csv C11137439,Group3,79 C11137439,Group3,15 Using grep : $ grep $VAR file3.csv C11137439,Group3,79 C11137439,Group3,15 Example 3: Print the line(s) of file3.csv that contain the strings C11137439 or B11119909 . To search for more than one expression, add the flag -e in front of each expression. $ grep -e \"C11137439\" -e \"B11119909\" file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 Example 4: Print the line(s) of file3.csv that contain the strings C11137439 , B11119909 or B11110893 . $ grep -e \"C11137439\" -e \"B11119909\" -e \"B11110893\" file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 B11110893,Group1,28 Example 5: Print the line(s) of file3.csv that contain the strings C11137439 or B11119909 (which are stored in a file called patterns.txt ). $ cat patterns.txt C11137439 B11119909 $ grep -f patterns.txt file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 Example 6: Print the line(s) of file3.csv that do not contain the string C11137439 . $ grep -v \"C11137439\" file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 7: Print the line(s) of any file in the current directory that contain the string C11137439 . $ awk '/C11137439/' * C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 C11137439 Group3 79 C11137439 $ grep C11137439 * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 patterns.txt:C11137439 To omit the file names using grep , use the flag -h : $ grep -h C11137439 * C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 C11137439 Group3 79 C11137439 If you wanted to include the line number for each match, you can add the flag -n : $ grep -n \"C11137439\" * file3.csv:21:C11137439,Group3,79 file3.csv:22:C11137439,Group3,15 file4.txt:15:C11137439 Group3 15 file4.txt:16:C11137439 Group3 79 patterns.txt:1:C11137439 $ grep -h -n \"C11137439\" * 21:C11137439,Group3,79 22:C11137439,Group3,15 15:C11137439 Group3 15 16:C11137439 Group3 79 1:C11137439 If you want to show only the first three matches, you can add the flag -m 3 (to print only three lines): $ grep -m 3 \"C11137439\" * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file4.txt:C11137439 Group3 15 $ grep -m 3 \"C11137439\" * -h C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 Example 8: Print the number of lines in each file of the current directory that contain C11137439 . $ grep -c \"C11137439\" * file1.csv:0 file1_reordered.csv:0 file2.txt:0 file3.csv:2 file4.txt:2 patterns.txt:1 patterns2.txt:0 Example 9: Print only the name of the files in the current directory that contain C11137439 . $ grep -l \"C11137439\" * file3.csv file4.txt patterns.txt Example 10: Print the line(s) of any file in the current directory that contain C11137439 , each line followed by the next three lines in the corresponding file (if there are three or more lines after the matched one). $ grep -A 3 \"C11137439\" * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- patterns.txt:C11137439 patterns.txt-B11119909 Example 11: Print the line(s) of any file in the current directory that contain C11137439 , each line preceded by the previous three lines in the corresponding file (if there are three or more lines before the matched one). $ grep -B 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 -- patterns.txt:C11137439 Example 12: Print the line(s) of any file in the current directory that contain C11137439 , each line preceded by the previous three lines and followed by the next three lines in the corresponding file (if there is three or more lines before/after the matched one). $ grep -C 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- -- patterns.txt:C11137439 patterns.txt-B11119909 $ grep -A 3 -B 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- -- patterns.txt:C11137439 patterns.txt-B11119909 Example 13: Print the line(s) of any file in the current directory that contain \"B11133232\" (including the quotation marks). $ awk '/\"B11133232\"/' * \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" $ grep \\\"B11133232\\\" * file2.txt:\"B11133232\" \"Group1\" \"500\" \"MissingData\" file2.txt:\"B11133232\" \"Group1\" \"456\" \"MissingData\" IF you want to make sure the quotation marks are included in the grep search, you must include the backslash before the quotation marks ( \\\" ). Otherwise, Bash will interpret the search value as B11133232 and not \"B11133232\" . Example 14: Print the line(s) of file3.csv that contain B11108399 or B11108326 . This search has the following rules: We're looking for words that start with the following seven characters: B111083 . The 8th character can be a 9 or a 2 . The last character can be a 9 or a 6 . So, in the grep command, we replace the 8th character by [92] to indicate that it can have any of those two values, and the last character by [96] to indicate that it can have value 9 or 6 . $ grep B111083[92][96] file3.csv B11108399,Group1,23 B11108326,Group1,59 Example 15: Print the line(s) of file3.csv that contain the values Group1 or Group2 . $ grep Group[12] file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137123,Group2 b,69 C11133100,Group1,23 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 16: Print the first column of file2.txt and file3.csv for those lines that contain the values Group1 or Group2 . Remember that you have to use the flag -F',' with awk when the columns of the file are separated by commas and not spaces. Space-separated file: $ grep Group[12] file2.txt | awk '{print $1}' \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11137120\" \"B33191224\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" Comma-separated file: $ grep Group[12] file3.csv | awk -F',' '{print $1}' C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11131039 C11135566 B11119903 C11137544 C11137123 C11133100 B11108399 B11108326 B11119909 B11110893 Example 17: Print the first and second columns of file2.txt and file3.csv for those lines that contain the values Group1 or Group2 . Space-separated file: $ grep Group[12] file2.txt | awk '{print $1,$2}' \"B11130912\" \"Group2b\" \"B11137244\" \"Group1\" \"B11154534\" \"Group1\" \"B11144100\" \"Group1\" \"B11137244\" \"Group1\" \"B12226566\" \"Group2b\" \"B11134987\" \"Group1\" \"B11144345\" \"Group1\" \"B11110676\" \"Group1\" \"C11138929\" \"Group2b\" \"B11154532\" \"Group1\" \"B11137120\" \"Group2b\" \"B33191224\" \"Group2b\" \"C11138999\" \"Group2b\" \"B11131605\" \"Group1\" \"B11137784\" \"Group1\" \"B11156098\" \"Group1\" \"B11133232\" \"Group1\" \"C11138912\" \"Group2b\" \"B11150911\" \"Group2b\" \"B11152577\" \"Group1\" \"B11156098\" \"Group1\" \"B11133232\" \"Group1\" Comma-separated file: $ grep Group[12] file3.csv | awk -F',' '{print $1,$2}' C11138192 Group1 B12226507 Group1 B12226546 Group1 C11138122 Group1 C11138184 Group1 C11138797 Group1 C11138152 Group1 C11138150 Group1 C11131039 Group2 b C11135566 Group2 b B11119903 Group2 b C11137544 Group1 C11137123 Group2 b C11133100 Group1 B11108399 Group1 B11108326 Group1 B11119909 Group2 b B11110893 Group1 Example 18: Print the line(s) of file3.csv and file4.txt that have value 11 in the third column. Space-separated file: $ awk '$3 == \"11\" {print $1,$2}' file4.txt D11144030 Group3 C11137159 Group3 Comma-separated file: $ awk -F',' '$3 == \"11\" {print $1,$2}' file3.csv C11137443 Group3 Example 19: Print the first and second columns of those lines in file3.csv and file4.txt that have value 11 in the third column. Space-separated file: $ awk '$3 == \"11\" {print $1,$2}' file4.txt D11144030 Group3 C11137159 Group3 Comma-separated file: $ awk -F',' '$3 == \"11\" {print $1,$2}' file3.csv C11137443 Group3 Example 20: Print the line(s) of file1.csv and file2.txt that have value \"Group1\" (including the colons) in the second column. Space-separated file: $ awk '$2 == \"\\\"Group1\\\"\"' file2.txt \"B11137244\" \"Group1\" \"450\" \"555\" \"B11154534\" \"Group1\" \"456\" \"456\" \"B11144100\" \"Group1\" \"450\" \"886\" \"B11137244\" \"Group1\" \"450\" \"456\" \"B11134987\" \"Group1\" \"900\" \"MissingData\" \"B11144345\" \"Group1\" \"900\" \"776\" \"B11110676\" \"Group1\" \"900\" \"10\" \"B11154532\" \"Group1\" \"456\" \"886\" \"B11131605\" \"Group1\" \"456\" \"MissingData\" \"B11137784\" \"Group1\" \"900\" \"436\" \"B11156098\" \"Group1\" \"500\" \"886\" \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11152577\" \"Group1\" \"900\" \"756\" \"B11156098\" \"Group1\" \"456\" \"886\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" Comma-separated file: $ awk -F',' '$2 == \"\\\"Group1\\\"\"' file1.csv \"B33199522\",\"Group1\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33199522\",\"Group1\",\"0\",\"\" Example 21: Print the line(s) of file1.csv and file2.txt that do not have value \"Group1\" (including the quotation marks) in the second column. Space-separated file: $ awk '$2 != \"\\\"Group1\\\"\"' file2.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" \"B11130912\" \"Group2b\" \"900\" \"MissingData\" \"B12226566\" \"Group2b\" \"450\" \"MissingData\" \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" \"B11156453\" \"Group4\" \"456\" \"2\" \"C11138929\" \"Group2b\" \"2\" \"MissingData\" \"B11155267\" \"Group3\" \"900\" \"10\" \"B11137120\" \"Group2b\" \"450\" \"456\" \"B33191224\" \"Group2b\" \"450\" \"776\" \"B11155267\" \"Group3\" \"900\" \"10\" \"C11138999\" \"Group2b\" \"900\" \"MissingData\" \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" \"C11138912\" \"Group2b\" \"900\" \"MissingData\" \"B11150911\" \"Group2b\" \"900\" \"117\" Comma-separated file: $ awk -F',' '$2 != \"\\\"Group1\\\"\"' file1.csv \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" Example 22: Print the first column of those lines in file1.csv and file2.txt that do not have value \"Group1\" (including the quotation marks) in the second column. Space-separated file: $ awk '$2 != \"\\\"Group1\\\"\" {print $1}' file2.txt \"AnonymizedID\" \"B11130912\" \"B12226566\" \"C11137159\" \"B11156453\" \"C11138929\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11135292\" \"C11138912\" \"B11150911\" Comma-separated file: $ awk -F',' '$2 != \"\\\"Group1\\\"\" {print $1}' file1.csv \"Anonymized ID\" \"B33199603\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11177579\" \"B11157958\" \"B11110690\" \"B11135291\" \"B11135072\" \"B33199603\" \"B33191224\" \"B11131290\" \"B33191224\" \"B11141503\" \"C11137159\" Example 23: Print the first column of those lines in file3.csv and file4.txt that have age (third column) greater than 20. Space-separated file: $ awk '$3 > \"20\" {print $1}' file4.txt AnonymizedID B11108326 B11110893 B11119909 B11119903 C11131039 C11133100 C11135566 C11137439 C11137544 C11137123 C11138150 C11138797 C11138184 C11138122 C11138122 C11138192 B12226507 B12226546 Comma-separated file: $ awk -F',' '$3 > \"20\" {print $1}' file3.csv Anonymized ID C11138122 C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11131039 C11135566 B11119903 C11137544 C11137123 C11137439 C11133100 B11108399 B11108326 B11119909 B11110893 Example 24: Print the first column of those lines in file3.csv and file4.txt that have age (third column) less than 20. Space-separated file: $ awk '$3 < \"20\" {print $1}' file4.txt D11144030 D11144030 C11137159 C11137159 C11137167 C11137167 C11137439 C11137443 C11138152 Comma-separated file: $ awk -F',' '$3 < \"20\" {print $1}' file3.csv C11137167 C11137159 C11137167 C11137159 C11137443 C11137439 D11144030 Example 25: Print the line(s) of file3.csv that have value \"Group1\" or \"Group3\" in the second column. When there is more than one rule, the easiest and more organized way to run the command is to put all the rules in a text file and call that text file using the flag -f . In the following example, patterns3.txt contains the rules to filter the lines that are to be printed ( $2 == \"Group1\" and $2 == \"Group3\" ). $ cat patterns3.txt $2 == \"Group1\" $2 == \"Group3\" $ awk -F',' -f patterns3.txt file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137544,Group1,21 C11137443,Group3,11 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11110893,Group1,28 $ cat patterns4.txt $2 == \"Group1\" || $2 == \"Group3\" $ awk -F',' -f test.txt file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137544,Group1,21 C11137443,Group3,11 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11110893,Group1,28 In this example, we obtained the same result using either patterns3.txt or patterns4.txt . When you want to select any line that contains any pattern in a list of patterns, you can either put each pattern in a different line of the text file or use the or ( || ) symbol to concatenate all the patterns or rules. Example 26: Print the first column of those lines in file3.csv that have value \"Group1\" in the second column, and value greater than 60 in the third column. Or that have value \"Group3\" in the second column value less than 20 in the third column. In this example, we want to print any line that contains one of the following rules: Second column equals Group1 and third greater than 60: $2 == \"Group1\" && $3 > 60 Second column equals and Group3 third less than 20: $2 == \"Group3\" && $3 < 20 So, the content of our pattern file must be: $ cat patterns5.txt $2 == \"Group1\" && $3 > 60 $2 == \"Group3\" && $3 < 20 To print all the columns from the selected lines: $ awk -F',' -f patterns5.txt file3.csv B12226507,Group1,68 B12226546,Group1,67 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137443,Group3,11 C11137439,Group3,15 D11144030,Group3,13 To print the first column: $ awk -F',' -f patterns5.txt file3.csv | awk -F',' '{print $1}' B12226507 B12226546 C11137167 C11137159 C11137167 C11137159 C11137443 C11137439 D11144030 The following page contains a summary of other patterns that can be included in a pattern file: https://ss64.com/bash/awk.html . Searching a pattern Example 1: Print the line(s) of file3.csv that start with B . $ grep '^B' file3.csv B12226507,Group1,68 B12226546,Group1,67 B11119903,Group2 b,83 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 2: Print the line(s) of test7.csv that end with 13 . $ grep '13$' file3.csv C11137159,Group3,13 C11137159,Group3,13 D11144030,Group3,13 Example 3: Print the line(s) of test7.csv that end with 13 (when this pattern is stored in a file called patterns2.txt ). $ cat patterns2.txt 13$ $ grep -f patterns2.txt file3.csv C11137159,Group3,13 C11137159,Group3,13 D11144030,Group3,13 Example 4: Print all the non-empty lines (lines with more than 0 fields NF > 0 ) in file3.csv and file4.txt . Space-separated file: $ awk 'NF > 0' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Comma-separated file: $ awk -F',' 'NF > 0' file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 5: Print all the lines that have more than two fields ( NF > 2 ) in file3.csv and file4.txt . Space-separated file: $ awk 'NF > 2' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Comma-separated file: $ awk -F',' 'NF > 2' file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Find and replace text Replace all occurrences of C11137159 in file3.csv with XXXXXXXXX and save the modified content in file3_mod.csv . Command to execute the substitution: sed 's/C11137159/XXXXXXXXX/' file3.csv > file3_mod.csv Content of file3.csv before the substitution: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content of file3.csv after the substitution: $ cat file3_mod.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 XXXXXXXXX,Group3,13 C11137167,Group3,16 XXXXXXXXX,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Find and replace patterns In the following examples, instead of replacing a fix string as we did before, we will replace a group of characters (i.e. all upper-case characters in the file) by a single character or another group of characters (i.e. replace with lower-case characters). The groups of characters that can be used are listed in the following table: Expression Group of characters [:alnum:] Letters and digits [:alpha:] Letters [:blank:] Horizontal white space [:cntrl:] Control characters [:digit:] Digits [:graph:] Printable characters, excluding space [:lower:] Lower-case letters [:print:] Printable characters, including space [:punct:] Punctuation characters [:space:] Horizontal or vertical white space [:upper:] Upper-case letters [:xdigit:] Hexadecimal digits Example 1: Replace all upper-case letters in file3.csv by lower-case. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:upper:]' '[:lower:]' anonymized id,subject group,age c11138122,missing,21 c11138192,group1,54 b12226507,group1,68 b12226546,group1,67 c11138122,group1,24 c11138184,group1,59 c11138797,group1,22 c11138152,group1,53 c11138150,group1,41 c11137167,group3,14 c11137159,group3,13 c11137167,group3,16 c11137159,group3,13 c11131039,group2 b,67 c11135566,group2 b,73 b11119903,group2 b,83 c11137544,group1,21 c11137443,group3,11 c11137123,group2 b,69 c11137439,group3,79 c11137439,group3,15 c11133100,group1,23 d11144030,group3,13 b11108399,group1,23 b11108326,group1,59 b11119909,group2 b,61 b11110893,group1,28 Example 2: Replace all lower-case letters in file3.csv by upper-case. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:lower:]' '[:upper:]' ANONYMIZED ID,SUBJECT GROUP,AGE C11138122,MISSING,21 C11138192,GROUP1,54 B12226507,GROUP1,68 B12226546,GROUP1,67 C11138122,GROUP1,24 C11138184,GROUP1,59 C11138797,GROUP1,22 C11138152,GROUP1,53 C11138150,GROUP1,41 C11137167,GROUP3,14 C11137159,GROUP3,13 C11137167,GROUP3,16 C11137159,GROUP3,13 C11131039,GROUP2 B,67 C11135566,GROUP2 B,73 B11119903,GROUP2 B,83 C11137544,GROUP1,21 C11137443,GROUP3,11 C11137123,GROUP2 B,69 C11137439,GROUP3,79 C11137439,GROUP3,15 C11133100,GROUP1,23 D11144030,GROUP3,13 B11108399,GROUP1,23 B11108326,GROUP1,59 B11119909,GROUP2 B,61 B11110893,GROUP1,28 Example 3: Replace all alphabetical characters in file3.csv by the number 0. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:alpha:]' 0 0000000000 00,0000000 00000,000 011138122,0000000,21 011138192,000001,54 012226507,000001,68 012226546,000001,67 011138122,000001,24 011138184,000001,59 011138797,000001,22 011138152,000001,53 011138150,000001,41 011137167,000003,14 011137159,000003,13 011137167,000003,16 011137159,000003,13 011131039,000002 0,67 011135566,000002 0,73 011119903,000002 0,83 011137544,000001,21 011137443,000003,11 011137123,000002 0,69 011137439,000003,79 011137439,000003,15 011133100,000001,23 011144030,000003,13 011108399,000001,23 011108326,000001,59 011119909,000002 0,61 011110893,000001,28 Example 4: Replace all digits in file3.csv by the letter X . Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:digit:]' X Anonymized ID,Subject Group,AGE CXXXXXXXX,MISSING,XX CXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX b,XX BXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX DXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX b,XX BXXXXXXXX,GroupX,XX Example 5: Replace all punctuation characters in file3.csv by a space. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:punct:]' ' ' Anonymized ID Subject Group AGE C11138122 MISSING 21 C11138192 Group1 54 B12226507 Group1 68 B12226546 Group1 67 C11138122 Group1 24 C11138184 Group1 59 C11138797 Group1 22 C11138152 Group1 53 C11138150 Group1 41 C11137167 Group3 14 C11137159 Group3 13 C11137167 Group3 16 C11137159 Group3 13 C11131039 Group2 b 67 C11135566 Group2 b 73 B11119903 Group2 b 83 C11137544 Group1 21 C11137443 Group3 11 C11137123 Group2 b 69 C11137439 Group3 79 C11137439 Group3 15 C11133100 Group1 23 D11144030 Group3 13 B11108399 Group1 23 B11108326 Group1 59 B11119909 Group2 b 61 B11110893 Group1 28 Example 5: Replace all white spaces in file3.csv by an underscore. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:blank:]' '_' Anonymized_ID,Subject_Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2_b,67 C11135566,Group2_b,73 B11119903,Group2_b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2_b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2_b,61 B11110893,Group1,28 Replace range of letters or numbers Example 6: Replace any A , B or C (letters in the range A-C) in file3.csv by the letter D . Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr 'A-C' 'D' Dnonymized ID,Subject Group,DGE D11138122,MISSING,21 D11138192,Group1,54 D12226507,Group1,68 D12226546,Group1,67 D11138122,Group1,24 D11138184,Group1,59 D11138797,Group1,22 D11138152,Group1,53 D11138150,Group1,41 D11137167,Group3,14 D11137159,Group3,13 D11137167,Group3,16 D11137159,Group3,13 D11131039,Group2 b,67 D11135566,Group2 b,73 D11119903,Group2 b,83 D11137544,Group1,21 D11137443,Group3,11 D11137123,Group2 b,69 D11137439,Group3,79 D11137439,Group3,15 D11133100,Group1,23 D11144030,Group3,13 D11108399,Group1,23 D11108326,Group1,59 D11119909,Group2 b,61 D11110893,Group1,28 Example 7: Replace A by W, B by X , C by Y , and D by Z in file3.csv (replace letters in the range A-D with letters in the range W-Z). Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr 'A-D' 'W-Z' Wnonymized IZ,Subject Group,WGE Y11138122,MISSING,21 Y11138192,Group1,54 X12226507,Group1,68 X12226546,Group1,67 Y11138122,Group1,24 Y11138184,Group1,59 Y11138797,Group1,22 Y11138152,Group1,53 Y11138150,Group1,41 Y11137167,Group3,14 Y11137159,Group3,13 Y11137167,Group3,16 Y11137159,Group3,13 Y11131039,Group2 b,67 Y11135566,Group2 b,73 X11119903,Group2 b,83 Y11137544,Group1,21 Y11137443,Group3,11 Y11137123,Group2 b,69 Y11137439,Group3,79 Y11137439,Group3,15 Y11133100,Group1,23 Z11144030,Group3,13 X11108399,Group1,23 X11108326,Group1,59 X11119909,Group2 b,61 X11110893,Group1,28 Example 8: Remove all spaces in file3.csv : you can use the -d flag for deletion. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr -d '[:blank:]' AnonymizedID,SubjectGroup,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2b,67 C11135566,Group2b,73 B11119903,Group2b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2b,61 B11110893,Group1,28 Example 9: Remove any repeated characters ( [:alnum:] ) in file3.csv : In order to delete any repeated (continuous) character or sequence use the -s flag. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr -s '[:alnum:]' Anonymized ID,Subject Group,AGE C13812,MISING,21 C138192,Group1,54 B126507,Group1,68 B126546,Group1,67 C13812,Group1,24 C138184,Group1,59 C138797,Group1,2 C138152,Group1,53 C138150,Group1,41 C137167,Group3,14 C137159,Group3,13 C137167,Group3,16 C137159,Group3,13 C131039,Group2 b,67 C1356,Group2 b,73 B1903,Group2 b,83 C13754,Group1,21 C13743,Group3,1 C137123,Group2 b,69 C137439,Group3,79 C137439,Group3,15 C1310,Group1,23 D14030,Group3,13 B10839,Group1,23 B108326,Group1,59 B1909,Group2 b,61 B10893,Group1,28 Print files information Example 1: Print the number of lines in file3.csv and file4.txt . Comma-separated file: $ awk '{print NF}' file3.csv | wc -l 28 $ nlines=$(awk '{print NF}' file3.csv | wc -l) $ echo $nlines 28 Space-separated file: $ awk '{print NF}' file4.txt | wc -l 29 $ nlines=$(awk '{print NF}' file4.txt | wc -l) $ echo $nlines 29 Example 2: Print the number of columns in file3.csv and file4.txt . Comma-separated file: $ awk -F',' '{print NF}' file3.csv | sort \u2013nu 3 $ ncols=$(awk -F',' '{print NF}' file3.csv | sort -nu) $ echo $ncols 3 Space-separated file: $ awk '{print NF}' file4.txt | sort -nu 3 $ ncols=$(awk '{print NF}' file4.txt | sort -nu) $ echo $ncols 3 Example 3: Print the length of each line of file4.txt . To get the length of a string you can use the function length() , and pass as parameter $0 which obtains all the fields (the whole line). Print each line: $ awk '{print $0}' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Print the length of each line: $ awk '{print length($0)}' file4.txt 29 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 20 19 19 19 Example 4: Print the length of the second field ( length($2) ) in file3.csv and file4.txt . Comma-separated file: $ awk '{print length($2)}' file4.txt 12 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 6 Space-separated file: $ awk -F',' '{print length($2)}' file3.csv 13 7 6 6 6 6 6 6 6 6 6 6 6 6 8 8 8 6 6 8 6 6 6 6 6 6 8 6 Example 5: Print all the lines of file4.txt in upper-case. To convert a string to upper-case use the function toupper() and pass as parameter $0 which contains the whole line. $ awk '{print toupper($0)}' file4.txt ANONYMIZEDID SUBJECTGROUP AGE B11108326 GROUP1 59 B11108399 GROUP1 23 B11110893 GROUP1 28 B11119909 GROUP2 61 D11144030 GROUP3 11 D11144030 GROUP3 13 B11119903 GROUP2 84 C11131039 GROUP2 67 C11133100 GROUP1 23 C11135566 GROUP2 72 C11137159 GROUP3 11 C11137159 GROUP3 12 C11137167 GROUP3 14 C11137167 GROUP3 16 C11137439 GROUP3 15 C11137439 GROUP3 79 C11137443 GROUP3 15 C11137544 GROUP1 22 C11137123 GROUP2 68 C11138150 GROUP1 44 C11138152 GROUP1 10 C11138797 GROUP1 24 C11138184 GROUP1 57 C11138122 GROUP1 23 C11138122 MISSING 25 C11138192 GROUP1 45 B12226507 GROUP1 26 B12226546 GROUP1 55 Example 6: Print all the lines of file4.txt in lower-case. To convert a string to lower-case use the function tolower() and pass as parameter $0 which contains the whole line. $ awk '{print tolower($0)}' file4.txt anonymizedid subjectgroup age b11108326 group1 59 b11108399 group1 23 b11110893 group1 28 b11119909 group2 61 d11144030 group3 11 d11144030 group3 13 b11119903 group2 84 c11131039 group2 67 c11133100 group1 23 c11135566 group2 72 c11137159 group3 11 c11137159 group3 12 c11137167 group3 14 c11137167 group3 16 c11137439 group3 15 c11137439 group3 79 c11137443 group3 15 c11137544 group1 22 c11137123 group2 68 c11138150 group1 44 c11138152 group1 10 c11138797 group1 24 c11138184 group1 57 c11138122 group1 23 c11138122 missing 25 c11138192 group1 45 b12226507 group1 26 b12226546 group1 55 Some other functions that can be used in addition to toupper() and tolower() can be found here .","title":"Text and CSV files"},{"location":"txt_csv/#manipulating-text-and-csv-files","text":"","title":"Manipulating text and csv files"},{"location":"txt_csv/#writing-files","text":"","title":"Writing files"},{"location":"txt_csv/#echo","text":"So far we have used echo to print text into the terminal. You can also use this utility to print text into a file (and create a new file if it doesn't exist): echo \"some text\" >> someFile.txt appends some text in a new line of someFile.txt and adds the new line character at the end. If someFile.txt didn't exist, the file is created. If you add the flag -n , Bash won't print the trailing newline character: echo -n \"some text\" >> someFile.txt . If you add the flag -e , Bash will interpret the character scape sequences in the text (see table below in the printf section for a list of scape sequences). If you use > instead of >> , the previous contents of the file (if it existed) will be erased and replaced with the new text that you are echoing.","title":"echo"},{"location":"txt_csv/#printf","text":"printf is a powerful tool that allows you to format the information before printing it in a file, the command line or another variable. For example, you can specify the format of any number that you print and the number of decimal points you want to use. You could even use this tool to change the format of a variable (i.e. from scientific notation to float) and save the result in a new variable instead of a file. You can also add tab or any character scape sequence to your text. Syntax: printf <format> <arguments> printf uses the format specified in <format> to print the objects (strings, numbers or variables) specified in <arguments> . In contrast with the echo command, printf does not print the text in a new line by default, in order to add a new line the following character scape sequence should be added at the end of <format> : \\n .","title":"printf"},{"location":"txt_csv/#format","text":"<format> is a string that contains alphanumerical characters, character scape sequences and format specifications, each of which causes printing of the next successive argument. The table below shows the strings that can be used for formatting. One should specify one format per argument. For example, in the command printf \"%d %s\" 10 \"my_string\" , \"%d %s\" is the format, which indicates that the first argument after the format ( 10 ) should be printed as a decimal ( %d ). Then, there should be a space, and then the second argument ( my_string ) should be printed as a string ( %s ). In printf \"%d %s\\n\" 10 \"my_string\" , %d %s\\n is the format, which indicates that the first argument after the format ( 10 ) should be printed as a decimal ( %d ), followed by a space. The second argument ( string ) should be printed as a string ( %s ). It also indicates that after the second argument there should be a new-line character ( \\n ). \\n is a scape sequence. The list of scape sequences can be found bellow. If any of the arguments is a string with special characters, spaces or scape sequences , make sure to always surround it with quotation marks. Format option Meaning %% Prints the symbol % and no argument is used. For example, printf \"%%\" just prints a % . %b Prints the corresponding argument as a string. The scape sequences are interpreted instead of reading them as literal strings. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision). %c Prints the first character of the corresponding argument if it is a string or the first digit if it's a number. printf \"%c %c\" \"some string\" 199 will print s 1 . %d The corresponding argument is a positive or negative integer number. If no precision is specified, it just prints the number. Otherwise, adds zeros before the integer to achieve the number of digits specified in the precision. For example, printf \"%d %.5d\\n\" -2 2 prints -2 00002 . %e Prints the corresponding argument, which should be a number, in scientific notation. There will be one digit before the decimal point and six digits after the decimal point if no precision is specified (or the number of digits specified in the precision). Infinity is printed as inf and NaN as nan . For example, 234.567 equals 2.34567 \u00d7 102 in scientific notation. So, if we use printf \"%e\" 234.567 , the result will be 2.345670e+02 . %f Prints the corresponding argument, which should be a number, in floating-point. The number of digits after the decimal point equals the precision or six digits if no precision was specified. Infinity is printed as inf and NaN as nan . For example, printf \"%f\\n\" 2.34567890123 will print 2.345679 and printf \"%.3f\\n\" -2.34567890123 will print -2.346 . %s Prints the corresponding argument as a string. The scape sequences are interpreted as literal strings. So, printf \"%s,%s\" \"text1\" \"text2\\ttext3\" will print text1,text2ttext3 , no tab introduced. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision). For example, printf \"%s\" \"example\" will print example , and printf \"%.3s\" \"example\" will print exa .","title":"Format"},{"location":"txt_csv/#scape-sequences","text":"Character scape sequence Meaning \\b Do not print the previous character (acts as backspace). For example, printf \"%b\" \"abcdef\" will print abcdef , while printf \"%b\" \"abc\\bdef\" will print abdef . \\c Suppresses any output after the sequence. For example, printf \"%b\" \"Hello\\c World\" will print only Hello . World will not be printed. \\n Write a new-line character. For example, printf \"%b\" \"abc\\ndef\" will print abc in one line, and def in another line. \\r Moves the cursor to the beginning of the current line. So, the following characters will replace the ones at the beginning of the line. For example, printf \"%b\" \"Happy World\\rLala\" prints Lalay World because Lala is written at the beginning of the line and replaces Happ . \\t Write a tab character. \\v Write a vertical tab. \\' Write a single quote character. \\\\ Write a backslash character.","title":"Scape sequences"},{"location":"txt_csv/#save-result-to-a-variable","text":"You can save the output of printf into a variable instead of printing it. For example, if you have a number in scientific notation and you want to convert it to floating, you can type the following: $ FLOAT=$(printf \"%f\" 2.345670e+02) $ echo $FLOAT 234.567000","title":"Save result to a variable"},{"location":"txt_csv/#reading-files","text":"","title":"Reading files"},{"location":"txt_csv/#reading-line-by-line","text":"The cat command, followed by the path of a file, can be used to visualize the content of the file in the command line: $ cat subjectList.txt AA0083277 AA0084999 AC0208933 AC0148099 AD0190300 BB0299033 BC0345100 BD0365666 CA0372599 CA0381677 CB0384399 CC0384433 DD0385444 If you want to read a file line by line and run a set of instructions on each line, you can combine the cat and for commands. The following example reads the content of a file line by line (which contains a list of subject IDs) and copies that information into a new file with their group membership, which can be obtained from the first two letters of the subject ID. The first two letters of each line are extracted with ${line:0:2} . $ for line in $(cat subjectList.txt) > do > echo \"${line:0:2},${line}\" >> subjectInfo.txt > don The content of subjectInfo.txt after running those lines will be: AA,AA0083277 AA,AA0084999 AC,AC0208933 AC,AC0148099 AD,AD0190300 BB,BB0299033 BC,BC0345100 BD,BD0365666 CA,CA0372599 CA,CA0381677 CB,CB0384399 CC,CC0384433 DD,DD0385444","title":"Reading line by line"},{"location":"txt_csv/#doing-statistics","text":"This is the content of infoFile.txt : SubjectID Group Gender Ethnicity Handedness Age Movement AA0083277 Control M Hispanic R 20 0.23525 AA0084999 Patient M Hispanic R 18 0.14564 AC0208933 Control F Hispanic R 17 0.18698 AC0148099 Control M NonHispanic R 21 0.19789 AD0190300 Patient M NonHispanic R 16 0.23454 BB0299033 Control F NonHispanic R 22 0.19752 BC0345100 Control M NonHispanic R 19 0.18789 BD0365666 Patient F NonHispanic R 17 0.14386 CA0372599 Patient F NonHispanic R 20 0.12384 CA0381677 Control F NonHispanic L 17 0.13453 CB0384399 Control F Hispanic R 18 0.45655 CC0384433 Control M NonHispanic R 15 0.13465 DD0385444 Patient M Hispanic R 16 0.32433 In this example we will calculate the minimum, maximum and average movement in the MRI scanner for the subjects in each group and gender. These values should be shown with only three decimals. There are many ways to do that, some of them a lot more efficient than the one presented here, using functions that we have not learn yet but that will be introduced further down in this document. We will use in this case the cat command to read from the file, the for loop, and some non-integer and array operations that have been learned from previous chapters. The for will read in each loop one line of the text file and extract the gender, group and movement values. Depending the group and gender, it will add the movement to one of the following arrays: CM: to save the movement of all male controls. CF: to save the movement of all female controls. PM: to save the movement of all male patients. PF: to save the movement of all female patients. In Bash it is not necessary to initialize an array. Instead, you can start adding values. The first time that you add a value to a non-existent array, it will be automatically initialized. When you ask Bash the size of an array that hasn\u2019t been initialized, it will return value zero. These are the steps to follow in order to calculate the minimum, maximum and average movement from the file: Create a loop that reads each line of the file (except the first one which is just a heather with column names). In each loop do the following: Split the line using the comma as a separator and save that in a variable called ARRAY . Obtain the subject group, which is located in the 2nd column (position 1 of the array). Remember, Bash arrays start in the position 0 (not the position 1). Obtain the subject gender, which is located in the 3rd column (position 2 of the array). Obtain the subject movement, which is located in the 7th column (position 6 of the array). Depending on the value of the group and gender, add movement to the corresponding array: If group equals Control and gender equals M (Male): Add the movement at the end of the array CM . If CM has zero values, the new item should be added to the position 0 If CM has one value, the new item should be added to the position 1 (because the existent item in the array will be in the position 0). Every new item is added to the position that is equal to the current size of the array. The size of an array can be obtained with ${#array[@]} . If group equals Control and gender equals F (Female): Add the movement at the end of the array CF . If group equals Patient and gender equals M : Add the movement at the end of the array PM . If group equals Patient and gender equals F : Add the movement at the end of the array PF . Sort the four arrays with the previously learned command: IFS=$'\\n' sorted=($(sort <<<\"${array[*]}\")) Show the minimum, maximum and average value of each array: Use printf instead of echo in order to show only three decimals per number. Minimum value: will be the first value in the sorted array. Maximum value: will be the last value in the sorted array (in the position SIZE_ARRAY\u20131 ). Average value: will equal to the sum of all values divided by the size of the array using IFS='+' avg=$(echo \"scale=1;(${array[*]})/${#array[@]}\"|bc) . Now, lets see this in actual code: First, loop through each line of the file, skipping the first row with the heathers using if [ $((n++)) -gt 0 ] : n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" GRP=${ARRAY[1]} GEN=${ARRAY[2]} MOV=${ARRAY[6]} if [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"M\" ] then CM[${#CM[@]}]=${MOV} fi if [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"F\" ] then CF[${#CF[@]}]=${MOV} fi if [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"M\" ] > then PM[${#PM[@]}]=${MOV} fi if [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"F\" ] then PF[${#PF[@]}]=${MOV} fi fi done Then, get the minimum, maximum and average values of the CM array (Controls, Males): IFS=$'\\n' sortedCM=($(sort <<<\"${CM[*]}\")) IFS='+' avg=$(echo \"scale=4;(${CM[*]})/${#CM[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedCM[0]} ${sortedCM[${#sortedCM[@]} -1]} $avg Now get the minimum, maximum and average values of the CF array (Controls, Females): IFS=$'\\n' sortedCF=($(sort <<<\"${CF[*]}\")) IFS='+' avg=$(echo \"scale=4;(${CF[*]})/${#CF[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedCF[0]} ${sortedCF[${#sortedCF[@]} -1]} $avg Get the minimum, maximum and average values of the PM array (Patients, Males): IFS=$'\\n' sortedPM=($(sort <<<\"${PM[*]}\")) IFS='+' avg=$(echo \"scale=4;(${PM[*]})/${#PM[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedPM[0]} ${sortedPM[${#sortedPM[@]} -1]} $avg Get the minimum, maximum and average values of the PF array (Patients, Females): IFS=$'\\n' sortedPF=($(sort <<<\"${PF[*]}\")) IFS='+' avg=$(echo \"scale=4;(${PF[*]})/${#PF[@]}\"|bc) printf \"Male Controls:\\nMin: %.3f\\nMax: %.3f\\nAve: %.3f\\n\" ${sortedPF[0]} The number of lines in the loop could be reduced by simplifying the if expressions. The code below is equivalent to loop above, but uses less lines. In the chapter of Condition testing I explain in detail how to simplify if expressions: n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" GRP=${ARRAY[1]} GEN=${ARRAY[2]} MOV=${ARRAY[6]} [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"M\" ] && CM[${#CM[@]}]=${MOV} [ \"$GRP\" == \"Control\" ] && [ \"$GEN\" == \"F\" ] && CF[${#CF[@]}]=${MOV} [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"M\" ] && PM[${#PM[@]}]=${MOV} [ \"$GRP\" == \"Patient\" ] && [ \"$GEN\" == \"F\" ] && PF[${#PF[@]}]=${MOV} fi done You could reduce even more the number of lines in the code of the loop: n=0 for line in $(cat infoFile.csv) do if [ $((n++)) -gt 0 ] then IFS=',' read -a ARRAY <<< \"${line}\" [ \"${ARRAY[1]}\" == \"Control\" ] && [ \"${ARRAY[2]}\" == \"M\" ] && CM[${#CM[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Control\" ] && [ \"${ARRAY[2]}\" == \"F\" ] && CF[${#CF[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Patient\" ] && [ \"${ARRAY[2]}\" == \"M\" ] && PM[${#PM[@]}]=${ARRAY[6]} [ \"${ARRAY[1]}\" == \"Patient\" ] && [ \"${ARRAY[2]}\" == \"F\" ] && PF[${#PF[@]}]=${ARRAY[6]} fi done","title":"Doing statistics"},{"location":"txt_csv/#dealing-with-spaces","text":"In the previous example we read line by line a file using a for loop and the cat utility. This works most of the times. However, if you try to read this way a file in which one or more of the lines contain a space, Bash will read each word separated by a space as a separate line. For example, if file test.txt has the following content: a b c d e f g h i j When you try to read each line using a file, this is the result you will get: $ for line in $(cat test.txt) > do > echo $((i++)) $line > done 0 a 1 b 2 c 3 d 4 e 5 f 6 g 7 h 8 i 9 j To fix this problem you have to tell Bash that newline ( \\n ) is the only separator. You do this by declaring the system variable IFS=$'\\n' . $ IFS=$'\\n' $ for line in $(cat test.txt) > do > echo $((i++)) $line > done 0 a b 1 c d 2 e f 3 g h 4 i j","title":"Dealing with spaces"},{"location":"txt_csv/#loading-into-an-array","text":"$ ARRAY=($(cat test.txt)) $ echo ${ARRAY[0]} a b $ echo ${ARRAY[1]} c d $ echo ${ARRAY[2]} e f $ echo ${ARRAY[3]} g h $ echo ${ARRAY[4]} i j","title":"Loading into an array"},{"location":"txt_csv/#the-read-command","text":"So far, we have learned that using the for loop and the cat utility you can read each line of a file and separate it into different fields using a separator. However, csv files can become very difficult to separate into fields if some of them contain a comma (the same character that is being used as a separator), a space, or both. Example: Obtain the last field of line using the concepts learned before. $ line=\"SUBJ20\",\" Age 22-30\",\"VISIT1\",\"1\",\"DIAGN: Major Depressive Disorder, Single Episode, In Full Remission\" $ IFS=',' read -a ARRAY >>> \"$line\" $ echo \"The last fifth of line is: \"${ARRAY[4]} The fifth field of line is: DIAGN: Major Depressive Disorder However, this is not the correct result. The fifth field of line is \"DIAGN: Major Depressive Disorder, Single Episode, In Full Remission\" . But because we are using a comma as a separator, Bash is separating this field into separate columns. To solve this problem, you can read from the file descriptor and save each field in a separate variable using read . With read if one of the columns contains a comma, but is surrounded by quotation marks, it will read the text inside the quotation marks as a single field. Suppose that you have a file called example.csv with the following content: \"SUBJ1\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Major Depressive Disorder, Single Episode\" \"SUBJ2\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Bipolar, Schizophrenia\" \"SUBJ3\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Major Depressive Disorder\" \"SUBJ4\",\"Age 22-30\",\"VISIT1\",\"DIAGN: Autism, Dyslexia, ADHD\" You want to read each line of the file and save the first and last fields into a new file called result.csv . You would accomplish that with the following code: Assign the file descriptor 3 (or any integer number) to example.csv: exec 3< example.csv Obtain the number of lines in the input file: $ N=$(cat example.csv | wc -l) $ echo $N 4 Iterate through all the lines of the file: $ i=0 $ while [ $((i++)) -lt $N ] > do > IFS=',' read -u 3 f1 f2 f3 f4 # Save each field in a different variable. Variable f1 will contain the 1st field, variable f2 the second field, etc. > echo \"$f1,$f4\" >> result.csv # Write the value of the first and last fields into the output file. > done You must close the file descriptor using the following command (replace number 3 by the corresponding file descriptor): exec 3<&- Finally, read the content of the output file $ cat result.csv \"SUBJ1\",\"DIAGN: Major Depressive Disorder, Single Episode\" \"SUBJ2\",\"DIAGN: Bipolar, Schizophrenia\" \"SUBJ3\",\"DIAGN: Major Depressive Disorder\" \"SUBJ4\",\"DIAGN: Autism, Dyslexia, ADHD\" In the following example we are going to read the same csv file from above called example.csv . The file has four columns. We are going to use the while loop to iterate through each line of the file and save the fields in variables f1 , f2 , f3 , f4 . Before starting to iterate, we have to tell Bash that comma will be the separator in each line with IFS=',' . $ IFS=',' $ i=1 $ while read f1 f2 f3 f4 > do > echo \"Line $((i++)):\" > echo \"Field 1: $f1\" > echo \"Field 2: $f2\" > echo \"Field 3: $f3\" > echo \"Field 4: $f4\" > done < example.csv Line 1: Field 1: \"SUBJ1\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Major Depressive Disorder, Single Episode\" Line 2: Field 1: \"SUBJ2\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Bipolar, Schizophrenia\" Line 3: Field 1: \"SUBJ3\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Major Depressive Disorder\" Line 4: Field 1: \"SUBJ4\" Field 2: \"Age 22-30\" Field 3: \"VISIT1\" Field 4: \"DIAGN: Autism, Dyslexia, ADHD\"","title":"The read command"},{"location":"txt_csv/#awk","text":"awk is a Bash command that scans files and process their content using patterns. It reads each line of a file or a group of files searching for the specified pattern and each time that it finds the pattern, performs an associated action. This tool can extract specific lines or columns from files, merge files, search the content of one file in the other, etc. When reading each line of the specified files, awk will separate it into fields (columns) using the blank space as a separator. If your file uses a different separator (i.e. a comma), you must specify your separator using the -F flag (see syntax below). The different fields will be denoted $1 , $2 , $3 ... etc. $0 will refer to the entire line. If the field separator ( FS ) is null, each line will be split into one field per character. See the examples section for a better understanding of this command. Syntax: awk [ -F fs ] [ -v var=value ] [ 'pattern {action}' ] [ files ] | [ other functions ] Command Section Meaning -F fs (optional) Defines the input field separator to be the regular expression fs . Use this flag when the columns of your file use a separator other than a space. -v var=variableName (optional) When the value that is being search is stored in a variable, you should use this flag. See below for examples on how to use this flag. files List of files to be searched. other functions (optional) You can apply to the output of awk other functions such as head , tail , paste , grep , etc.","title":"awk"},{"location":"txt_csv/#grep","text":"grep searches a given pattern or text in a file or list of files. grep is able to find simple patterns and basic regular expressions, egrep can perform search of extended regular expressions. fgrep is quicker than both tools, but can only handle fixed patterns. zgrep , zegrep , and zfgrep act like grep , egrep , and fgrep , respectively, but accept compressed files as input. See the examples section for a better understanding of this command. Syntax: grep [flag] [pattern] [file(s)] grep Format Meaning grep my_string files Search the list of files for lines that contain my_string . grep '^my_expression' files Search for any lines that start with my_expression in the list of files. If my_expression contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. grep '^string' file.txt will search for any lines in file.txt that start with string. grep 'my_expression$' files Search for any lines that end with my_expression in the list of files. If my_expression contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. grep 'string$' file.txt matches any lines in file.txt that end with string . grep '^string$' file.txt matches any lines in file.txt that start and end with string . grep '[characters]' files Search for any lines that contain any of the characters enclosed between the brackets. Use a hyphen for a range of values. grep '[abcde]' file.txt matches any lines in file.txt that contain a , b , c , d or e . grep '[Ss]tring' file.txt matches any lines in file.txt that contain the words string or String. grep 'B[ai][dt]' file.txt matches any lines in file.txt that contain the words Bad , Bat , Bid or Bit (the second character can be a or i and the third character d or t ). grep '[0-9][0-9]' file.txt matches any lines in file.txt that contain a pair of numeric digits. grep '[a-zA-Z]' file.txt matches any lines in file.txt with at least one letter. grep '^$' file.txt matches any empty lines. grep '[^characters]' files Search for any lines that don't contain any of the characters enclosed between he brackets. Use a hyphen for a range of values. grep '[^a-zA-Z0-9]' file.txt matches any lines in file.txt that don't contain any letter or number (any lines that contain only special characters). grep 'character*' files The character preceding the asterisk is optional when matching lines. grep '\"*smug\"*' file.txt matches any lines in file.txt that contain smug or \"smug\" (with or without the quotes that precede the asterisks). grep 'my_expression\\{n\\}' files Match exactly n occurrences of my_expression . grep '[0-9]\\{3\\}-[0-9]\\{4\\}' file.txt matches any lines in file.txt that contain three digits, followed by a line and four digits. grep 'expression \\{n,\\}' files Match n or more occurrences of expression. grep '[0-9]\\{3,\\}' file.txt matches any lines in file.txt that contain three or more digits. Flag Meaning -A num Print num lines of trailing context after each match. -B num Print num lines of leading context before each match. -C num Print num lines of leading and trailing context surrounding each match. If num is not specified, num=2 . -c Print the number of matched lines per file instead of the actual lines. --color=when Mark up the matching text with the expression stored in the GREP_COLOR environment variable. The possible values of when can be: never , always or auto . -d action Specify the demanded action for directories. The possible values of action are: read (default), which means that the directories are read in the same manner as normal files; skip to silently ignore the directories, and recourse to read them recursively, which has the same effect as the -R and -r option. -e pattern To search for more than one pattern/expression, add the flag -e in front of each pattern/expression. --exclude If specified, it excludes files matching the given filename pattern from the search. Note that --exclude patterns take priority over --include patterns. Patterns are matched to the full path specified, not only to the filename component. --exclude-dir filename_pattern If -R is specified, it excludes directories matching the given filename_pattern from the search. -f file Read one or more newline separated patterns from file . Empty pattern lines match every input line. Newlines are not considered part of a pattern. If file is empty, nothing is matched. -h Omit the filename headers with output lines. --help Print a brief help message. --include If specified, only files matching the given filename pattern are searched. Note that --exclude patterns take priority over --include patterns. Patterns are matched to the full path specified, not only to the filename component. --include-dir filename_pattern If -R is specified, only directories matching the given filename_pattern are searched. Note that --exclude-dir patterns take priority over --include-dir patterns. -L Only the names of files not containing selected lines are listed. -l Only the names of files containing selected lines are listed. -m num Stop reading the file after num matches. -n Each output line is preceded by its relative line number in the file, starting at line 1. The line number counter is reset for each file processed. This option is ignored if -c , -L , -l , or -q is specified. --null Prints a zero-byte after the file name. -O If -R is specified, follow symbolic links only if they were explicitly listed on the command line. The default is not to follow symbolic links. -o Prints only the matching part of the lines. -q Suppress normal output. -R or -r Recursively search subdirectories listed. -S If -R is specified, all symbolic links are followed. The default is not to follow symbolic links. -s Suppress error messages from nonexistent or unreadable files. -V Display version information and exit. -v Selected lines are those not matching any of the specified patterns. -w The expression is searched for as a whole word. -x Show only the cases where the whole line equals the expression. -Z or -z Accepts compressed input files. --line-buffered Force output to be line buffered. By default, output is line buffered when standard output is a terminal and block buffered otherwise.","title":"grep"},{"location":"txt_csv/#examples-awk-and-grep","text":"The following examples will show how to read and manipulate files using different command line tools. Each example will read one or more of the following files. file1.csv and file3.csv use comma as the separator between columns. On the other hand, file2.txt and file file4.txt use a space as the separator between columns. Content of file1.csv : \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\" Content of file2.txt : \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" \"B11130912\" \"Group2b\" \"900\" \"MissingData\" \"B11137244\" \"Group1\" \"450\" \"555\" \"B11154534\" \"Group1\" \"456\" \"456\" \"B11144100\" \"Group1\" \"450\" \"886\" \"B11137244\" \"Group1\" \"450\" \"456\" \"B12226566\" \"Group2b\" \"450\" \"MissingData\" \"B11134987\" \"Group1\" \"900\" \"MissingData\" \"B11144345\" \"Group1\" \"900\" \"776\" \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" \"B11156453\" \"Group4\" \"456\" \"2\" \"B11110676\" \"Group1\" \"900\" \"10\" \"C11138929\" \"Group2b\" \"2\" \"MissingData\" \"B11154532\" \"Group1\" \"456\" \"886\" \"B11155267\" \"Group3\" \"900\" \"10\" \"B11137120\" \"Group2b\" \"450\" \"456\" \"B33191224\" \"Group2b\" \"450\" \"776\" \"B11155267\" \"Group3\" \"900\" \"10\" \"C11138999\" \"Group2b\" \"900\" \"MissingData\" \"B11131605\" \"Group1\" \"456\" \"MissingData\" \"B11137784\" \"Group1\" \"900\" \"436\" \"B11156098\" \"Group1\" \"500\" \"886\" \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" \"C11138912\" \"Group2b\" \"900\" \"MissingData\" \"B11150911\" \"Group2b\" \"900\" \"117\" \"B11152577\" \"Group1\" \"900\" \"756\" \"B11156098\" \"Group1\" \"456\" \"886\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" Content of file3.csv : Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content of file4.txt : AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55","title":"Examples: awk and grep"},{"location":"txt_csv/#reading-specific-columns","text":"Example 1: Print the first column of each file. In order to print the first column of these files, we will use awk . As it was shown before, this command has some optional flags followed by an action statement, and then the list of files. In this case, the action statement is '{print $1}' , because we want to print only the first column ( $1 ). file2.txt and file4.txt use a space as a column separator (which is the separator for default). So, to access the first column of these files we don't need the -F flag. However, file1.csv and file3.csv use a comma as a separator. So, in order for awk to distinguish the different columns, we have to use the -F flag with a comma ( -F',' ). Space-separated files: $ awk '{print $1}' file2.txt \"AnonymizedID\" \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"C11137159\" \"B11156453\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"B11135292\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" $ awk '{print $1}' file4.txt AnonymizedID B11108326 B11110893 B11119909 D11144030 D11144030 B11119903 C11131039 C11133100 C11135566 C11137159 C11137159 C11137167 C11137167 C11137439 C11137439 C11137443 C11137544 C11137123 C11138150 C11138152 C11138797 C11138184 C11138122 C11138122 C11138192 B12226507 B12226546 Comma-separated files: $ awk -F',' '{print $1}' file1.csv \"Anonymized ID\" \"B33199522\" \"B33199603\" \"B11137879\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11153927\" \"B11177579\" \"B11177806\" \"B11157958\" \"B11110690\" \"B11152799\" \"B11154358\" \"B11110925\" \"B11135291\" \"B11135072\" \"B33199603\" \"B11137879\" \"B11131605\" \"B11110927\" \"B11147712\" \"B33191224\" \"B11131290\" \"B11157974\" \"B33191224\" \"B11141503\" \"C11137159\" \"B33199522\" $ awk -F',' '{print $1}' file3.csv AnonymizedID C11138122 C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11137167 C11137159 C11137167 C11137159 C11131039 C11135566 B11119903 C11137544 C11137443 C11137123 C11137439 C11137439 C11133100 D11144030 B11108399 B11108326 B11119909 B11110893 To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): Space-separated files: $ awk '{print NR,$1}' file2.txt 1 \"AnonymizedID\" 2 \"B11130912\" 3 \"B11137244\" 4 \"B11154534\" 5 \"B11144100\" 6 \"B11137244\" 7 \"B12226566\" 8 \"B11134987\" 9 \"B11144345\" 10 \"C11137159\" 11 \"B11156453\" 12 \"B11110676\" 13 \"C11138929\" 14 \"B11154532\" 15 \"B11155267\" 16 \"B11137120\" 17 \"B33191224\" 18 \"B11155267\" 19 \"C11138999\" 20 \"B11131605\" 21 \"B11137784\" 22 \"B11156098\" 23 \"B11133232\" 24 \"B11135292\" 25 \"C11138912\" 26 \"B11150911\" 27 \"B11152577\" 28 \"B11156098\" 29 \"B11133232\" $ awk '{print NR, $1}' file4.txt 1 AnonymizedID 2 B11108326 3 B11110893 4 B11119909 5 D11144030 6 D11144030 7 B11119903 8 C11131039 9 C11133100 10 C11135566 11 C11137159 12 C11137159 13 C11137167 14 C11137167 15 C11137439 16 C11137439 17 C11137443 18 C11137544 19 C11137123 20 C11138150 21 C11138152 22 C11138797 23 C11138184 24 C11138122 25 C11138122 26 C11138192 27 B12226507 28 B12226546 Comma-separated files: $ awk -F',' '{print NR, $1}' file1.csv 1 \"Anonymized ID\" 2 \"B33199522\" 3 \"B33199603\" 4 \"B11137879\" 5 \"B11144410\" 6 \"B11110455\" 7 \"B11135291\" 8 \"B11153927\" 9 \"B11177579\" 10 \"B11177806\" 11 \"B11157958\" 12 \"B11110690\" 13 \"B11152799\" 14 \"B11154358\" 15 \"B11110925\" 16 \"B11135291\" 17 \"B11135072\" 18 \"B33199603\" 19 \"B11137879\" 20 \"B11131605\" 21 \"B11110927\" 22 \"B11147712\" 23 \"B33191224\" 24 \"B11131290\" 25 \"B11157974\" 26 \"B33191224\" 27 \"B11141503\" 28 \"C11137159\" 29 \"B33199522\" $ awk -F',' '{print NR, $1}' file3.csv 1 Anonymized ID 2 C11138122 3 C11138192 4 B12226507 5 B12226546 6 C11138122 7 C11138184 8 C11138797 9 C11138152 10 C11138150 11 C11137167 12 C11137159 13 C11137167 14 C11137159 15 C11131039 16 C11135566 17 B11119903 18 C11137544 19 C11137443 20 C11137123 21 C11137439 22 C11137439 23 C11133100 24 D11144030 25 B11108399 26 B11108326 27 B11119909 28 B11110893 Example 2: Print the first column of file1.csv and file2.txt in reverse order . In order to print starting with the last line and ending with the first line, you can use the command tail with the flag -r (for reverse) after awk . Bash will first execute the awk command, which is written before the pipe ( | ), and then it will run tail , which inverts the order of the previous output. Remember that for file1.csv you need to use -F',' to indicate that the columns are separated by commas and not spaces. Space-separated file: $ awk '{print $1}' file2.txt | tail -r \"B11133232\" \"B11156098\" \"B11152577\" \"B11150911\" \"C11138912\" \"B11135292\" \"B11133232\" \"B11156098\" \"B11137784\" \"B11131605\" \"C11138999\" \"B11155267\" \"B33191224\" \"B11137120\" \"B11155267\" \"B11154532\" \"C11138929\" \"B11110676\" \"B11156453\" \"C11137159\" \"B11144345\" \"B11134987\" \"B12226566\" \"B11137244\" \"B11144100\" \"B11154534\" \"B11137244\" \"B11130912\" \"AnonymizedID\" Comma-separated file: $ awk -F',' '{print $1}' file1.csv | tail -r \"B33199522\" \"C11137159\" \"B11141503\" \"B33191224\" \"B11157974\" \"B11131290\" \"B33191224\" \"B11147712\" \"B11110927\" \"B11110603\" \"B11137879\" \"B33199603\" \"B11135072\" \"B11135291\" \"B11110925\" \"B11154358\" \"B11152799\" \"B11110690\" \"B11157958\" \"B11177806\" \"B11177579\" \"B11153927\" \"B11135291\" \"B11110455\" \"B11144410\" \"B11137879\" \"B33199603\" \"B33199522\" \"Anonymized ID\" The same as in example 1, to precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): Space-separated file: $ awk '{print NR, $1}' file2.txt | tail -r 29 \"B11133232\" 28 \"B11156098\" 27 \"B11152577\" 26 \"B11150911\" 25 \"C11138912\" 24 \"B11135292\" 23 \"B11133232\" 22 \"B11156098\" 21 \"B11137784\" 20 \"B11131605\" 19 \"C11138999\" 18 \"B11155267\" 17 \"B33191224\" 16 \"B11137120\" 15 \"B11155267\" 14 \"B11154532\" 13 \"C11138929\" 12 \"B11110676\" 11 \"B11156453\" 10 \"C11137159\" 9 \"B11144345\" 8 \"B11134987\" 7 \"B12226566\" 6 \"B11137244\" 5 \"B11144100\" 4 \"B11154534\" 3 \"B11137244\" 2 \"B11130912\" 1 \"AnonymizedID\" Comma-separated file: $ awk -F',' '{print NR, $1}' file1.csv | tail -r 29 \"B33199522\" 28 \"C11137159\" 27 \"B11141503\" 26 \"B33191224\" 25 \"B11157974\" 24 \"B11131290\" 23 \"B33191224\" 22 \"B11147712\" 21 \"B11110927\" 20 \"B11110603\" 19 \"B11137879\" 18 \"B33199603\" 17 \"B11135072\" 16 \"B11135291\" 15 \"B11110925\" 14 \"B11154358\" 13 \"B11152799\" 12 \"B11110690\" 11 \"B11157958\" 10 \"B11177806\" 9 \"B11177579\" 8 \"B11153927\" 7 \"B11135291\" 6 \"B11110455\" 5 \"B11144410\" 4 \"B11137879\" 3 \"B33199603\" 2 \"B33199522\" 1 \"Anonymized ID\" Example 3: Print the second and third columns of file2.txt . In the previous examples we used the action statement '{print $1}' to print the first column. Since we now want to print the second and third columns instead of the first one, we replace $1 by $2,$3 . If you wanted to print columns 4 and 5 instead, you would simply use $4,$5 , etc. $ awk '{print $2,$3}' file2.txt \"SubjectGroup\" \"TEST1\" \"Group2b\" \"900\" \"Group1\" \"450\" \"Group1\" \"456\" \"Group1\" \"450\" \"Group1\" \"450\" \"Group2b\" \"450\" \"Group1\" \"900\" \"Group1\" \"900\" \"Group3\" \"MissingData\" \"Group4\" \"456\" \"Group1\" \"900\" \"Group2b\" \"2\" \"Group1\" \"456\" \"Group3\" \"900\" \"Group2b\" \"450\" \"Group2b\" \"450\" \"Group3\" \"900\" \"Group2b\" \"900\" \"Group1\" \"456\" \"Group1\" \"900\" \"Group1\" \"500\" \"Group1\" \"500\" \"Group3\" \"MissingData\" \"Group2b\" \"900\" \"Group2b\" \"900\" \"Group1\" \"900\" \"Group1\" \"456\" \"Group1\" \"456\" To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): $ awk '{print NR,$2,$3}' file2.txt 1 \"SubjectGroup\" \"TEST1\" 2 \"Group2b\" \"900\" 3 \"Group1\" \"450\" 4 \"Group1\" \"456\" 5 \"Group1\" \"450\" 6 \"Group1\" \"450\" 7 \"Group2b\" \"450\" 8 \"Group1\" \"900\" 9 \"Group1\" \"900\" 10 \"Group3\" \"MissingData\" 11 \"Group4\" \"456\" 12 \"Group1\" \"900\" 13 \"Group2b\" \"2\" 14 \"Group1\" \"456\" 15 \"Group3\" \"900\" 16 \"Group2b\" \"450\" 17 \"Group2b\" \"450\" 18 \"Group3\" \"900\" 19 \"Group2b\" \"900\" 20 \"Group1\" \"456\" 21 \"Group1\" \"900\" 22 \"Group1\" \"500\" 23 \"Group1\" \"500\" 24 \"Group3\" \"MissingData\" 25 \"Group2b\" \"900\" 26 \"Group2b\" \"900\" 27 \"Group1\" \"900\" 28 \"Group1\" \"456\" 29 \"Group1\" \"456\" Example 4: Print the second and third columns of file1.csv in reverse order . In order to print the output in reverse order for file1.csv , use the tail -r command after the awk . $ awk -F',' '{print $2,$3}' file1.csv | tail -r \"Group1\" \"0\" \"Group3\" \"9\" \"Group3\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group2 b\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"MISSING\" \"0\" \"Group3\" \"9\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group3\" \"0\" \"Group1\" \"MD\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group2 b\" \"0\" \"Group2 b\" \"0\" \"Group1\" \"0\" \"Group3\" \"0\" \"Group1\" \"0\" \"Subject Group\" \"HASCONDITION\" To precede each line by the line number, add NR after print in the awk command to indicate that you want to print the Number Row before the column 1 ( $1 ): $ awk -F',' '{print NR,$2,$3}' file1.csv | tail -r 29 \"Group1\" \"0\" 28 \"Group3\" \"9\" 27 \"Group3\" \"0\" 26 \"Group2 b\" \"0\" 25 \"Group1\" \"0\" 24 \"Group2 b\" \"0\" 23 \"Group2 b\" \"0\" 22 \"Group1\" \"0\" 21 \"Group1\" \"0\" 20 \"Group1\" \"0\" 19 \"Group1\" \"0\" 18 \"Group3\" \"0\" 17 \"MISSING\" \"0\" 16 \"Group3\" \"9\" 15 \"Group1\" \"0\" 14 \"Group1\" \"0\" 13 \"Group1\" \"0\" 12 \"Group3\" \"0\" 11 \"Group3\" \"0\" 10 \"Group1\" \"MD\" 9 \"Group2 b\" \"0\" 8 \"Group1\" \"0\" 7 \"Group3\" \"0\" 6 \"Group2 b\" \"0\" 5 \"Group2 b\" \"0\" 4 \"Group1\" \"0\" 3 \"Group3\" \"0\" 2 \"Group1\" \"0\" 1 \"Subject Group\" \"HASCONDITION\" Example 5: Print all the columns of file1.csv showing the lines in reverse order . To print all the columns of a file using awk , use $0 (instead of a column number). Or use the command cat . Using awk : awk -F',' '{print $0}' file1.csv | tail -r Using cat : cat file1.csv | tail -r Example 6: Print all the columns of file1.csv in reversed order , and save the re-ordered columns in a new file called file1_reordered.csv . If you were going to print the columns one to three in normal order, you would use '{print $1,$2,$3}' . To print them in reverse order, you just reverse the order of the columns in print , like so: '{print $3,$2,$1}' . To save the output to a file instead of showing it in the terminal, use >> file_name , as explained in previous sections. Remember to use the -F',' flag to indicate that the columns are separated by commas, and not the default space. awk -F',' '{print $3,$2,$1}' file1.csv >> file1_reordered.csv Example 7: Print the columns and lines of file1.csv in reverse order Use the same command as before, adding | tail -r at the end to invert also the lines. awk -F',' '{print $3,$2,$1}' file1.csv | tail -r Example 8: Read the second column of file1.csv and save it into an array. When saving a column of a file into an array, you must specify that the elements of the array are separated by new lines ( '\\n' ). You do this using the command IFS=$'\\n' . The elements of the array will be saved in the variable ARRAY . Remember that to access the individual elements of ARRAY you use ${ARRAY[index]} . With index starting at 0. So, to access the first element the command is echo ${ARRAY[0]} . To access the second element it is echo ${ARRAY[1]} , etc. Type echo ${ARRAY[@]} to view all the elements of the array. Remember, the system variable IFS contains the separator that is being used to separate each field within the lines of a file. You can change the value of this variable at any time by using IFS='character' , where character is the one separating the fields. $ IFS=$'\\n' $ ARRAY=($(awk -F',' '{print $2}' file1.csv)) $ echo ${ARRAY[0]} \"Subject Group\" $ echo ${ARRAY[1]} \"Group1\" $ echo ${ARRAY[@]} \"Subject Group\" \"Group1\" \"Group3\" \"Group1\" \"Group2 b\" \"Group2 b\" \"Group3\" \"Group1\" \"Group2 b\" \"Group1\" \"Group3\" \"Group3\" \"Group1\" \"Group1\" \"Group1\" \"Group3\" \"MISSING\" \"Group3\" \"Group1\" \"Group1\" \"Group1\" \"Group1\" \"Group2 b\" \"Group2 b\" \"Group1\" \"Group2 b\" \"Group3\" \"Group3\" \"Group1\" $ echo ${#ARRAY[@]} 29 Example 9: Print the first column of file2.txt followed by the first column of file4.txt . To print a specific column for more than one file, you use the same command, adding the list of files you want to print after the first one. However, all the files in the list must use the same column separator. Since the column separator for this list of files is a space (the default), you don't need to use the -F flag. awk '{print $1}' file2.txt file4.txt Example 10: Print the first column of file3.csv followed by the first column of file1.csv . Since the column separator for this list of files is a comma, you need to use the -F',' flag. awk -F',' '{print $1}' file3.csv file1.csv","title":"Reading specific columns"},{"location":"txt_csv/#sorting-columns","text":"Example 1: Print the first column of file1.csv and file2.txt in alphabetical order . First, use awk to print the desired column. Then, use sort to sort it in alphabetical order. Space-separated file: $ awk '{print $1}' file2.txt | sort \"AnonymizedID\" \"B11110676\" \"B11130912\" \"B11131605\" \"B11133232\" \"B11133232\" \"B11134987\" \"B11135292\" \"B11137120\" \"B11137244\" \"B11137244\" \"B11137784\" \"B11144100\" \"B11144345\" \"B11150911\" \"B11152577\" \"B11154532\" \"B11154534\" \"B11155267\" \"B11155267\" \"B11156098\" \"B11156098\" \"B11156453\" \"B12226566\" \"B33191224\" \"C11137159\" \"C11138912\" \"C11138929\" \"C11138999\" Comma-separated file: $ awk -F ',' '{print $1}' file1.csv | sort \"Anonymized ID\" \"B11110455\" \"B11110603\" \"B11110690\" \"B11110925\" \"B11110927\" \"B11131290\" \"B11135072\" \"B11135291\" \"B11135291\" \"B11137879\" \"B11137879\" \"B11141503\" \"B11144410\" \"B11147712\" \"B11152799\" \"B11153927\" \"B11154358\" \"B11157958\" \"B11157974\" \"B11177579\" \"B11177806\" \"B33191224\" \"B33191224\" \"B33199522\" \"B33199522\" \"B33199603\" \"B33199603\" \"C11137159\" Example2: Print the first column of file1.csv and file2.txt in alphabetical removing any duplicate values . Use awk to print the desired column, followed by sort | uniq to sort and remove the duplicates on the result. Space-separated file: $ awk '{print $1}' file2.txt | sort | uniq \"AnonymizedID\" \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"C11137159\" \"B11156453\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"B11135292\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" Comma-separated file $ awk -F ',' '{print $1}' file1.csv | sort | uniq \"Anonymized ID\" \"B33199522\" \"B33199603\" \"B11137879\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11153927\" \"B11177579\" \"B11177806\" \"B11157958\" \"B11110690\" \"B11152799\" \"B11154358\" \"B11110925\" \"B11135291\" \"B11135072\" \"B33199603\" \"B11137879\" \"B11110603\" \"B11110927\" \"B11147712\" \"B33191224\" \"B11131290\" \"B11157974\" \"B33191224\" \"B11141503\" \"C11137159\" \"B33199522\" Example 4: Print the first column of file1.csv and file3.csv combined, in alphabetical order and with no duplicates. Use awk with the list of files to be read ( file1.csv file3.csv ) as arguments. Then, use | sort to organize the output in alphabetical order, and finally use | uniq to remove the duplicates. In this case, because the strings in file1.csv all start by colons, while the values in file3.csv don't, then all the values of file1.csv will be printed before those of file3.csv , because alphabetically, special characters such as \" go before any letter (including A). So, for Bash \"B11110455\" goes before Anonymized ID . $ awk -F ',' '{print $1}' file1.csv file3.csv | sort | uniq \"Anonymized ID\" \"B11110455\" \"B11110603\" \"B11110690\" \"B11110925\" \"B11110927\" \"B11131290\" \"B11135072\" \"B11135291\" \"B11137879\" \"B11141503\" \"B11144410\" \"B11147712\" \"B11152799\" \"B11153927\" \"B11154358\" \"B11157958\" \"B11157974\" \"B11177579\" \"B11177806\" \"B33191224\" \"B33199522\" \"B33199603\" \"C11137159\" Anonymized ID B11108326 B11108399 B11110893 B11119903 B11119909 B12226507 B12226546 C11131039 C11133100 C11135566 C11137123 C11137159 C11137167 C11137439 C11137443 C11137544 C11138122 C11138150 C11138152 C11138184 C11138192 C11138797 D11144030","title":"Sorting columns"},{"location":"txt_csv/#paste","text":"","title":"paste"},{"location":"txt_csv/#horizontal-concatenation","text":"Example1: Concatenate all the columns of file2.txt and file4.txt horizontally, using a space as separator between the columns of one file and the other. $ paste -d ' ' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" AnonymizedID SubjectGroup AGE B11108399 Group1 23b\" \"900\" \"MissingData\" B11108326 Group1 59 \"B11137244\" \"Group1\" \"450\" \"555\" B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\" B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\" D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\" D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\" B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\" C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\" C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\" C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\" C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\" C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\" C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\" C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\" C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\" C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\" C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\" C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\" C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\" C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\" C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\" C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\" C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\" C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\" B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\" B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\" Example 2: Concatenate all the columns of file2.txt and file4.txt horizontally using a semicolon as separator between the columns of one file and the other. $ paste -d ';' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\";AnonymizedID SubjectGroup AGE B11108399 Group1 23b\" \"900\" \"MissingData\";B11108326 Group1 59 \"B11137244\" \"Group1\" \"450\" \"555\";B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\";B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\";D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\";D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\";B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\";C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\";C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\";C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\";C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\";C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\";C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\";C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\";C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\";C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\";C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\";C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\";C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\";C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\";C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\";C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\";C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\";C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\";C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\";C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\";B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\";B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\"; Example 3: Concatenate all the columns of file2.txt and file4.txt . Use a newline character as separator between the columns of one file and the other. As a result, the two files will be interlined. In the output you will have the first line of file2.txt followed by the first line of file4.txt , followed by the second line of file2.txt , then the second line of file4.txt , etc. $ paste -d '\\n' file2.txt file4.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" AnonymizedID SubjectGroup AGE \"B11130912\" \"Group2b\" \"900\" \"MissingData\" B11108399 Group1 23 \"B11137244\" \"Group1\" \"450\" \"555\" B11110893 Group1 28 \"B11154534\" \"Group1\" \"456\" \"456\" B11119909 Group2 61 \"B11144100\" \"Group1\" \"450\" \"886\" D11144030 Group3 11 \"B11137244\" \"Group1\" \"450\" \"456\" D11144030 Group3 13 \"B12226566\" \"Group2b\" \"450\" \"MissingData\" B11119903 Group2 84 \"B11134987\" \"Group1\" \"900\" \"MissingData\" C11131039 Group2 67 \"B11144345\" \"Group1\" \"900\" \"776\" C11133100 Group1 23 \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" C11135566 Group2 72 \"B11156453\" \"Group4\" \"456\" \"2\" C11137159 Group3 11 \"B11110676\" \"Group1\" \"900\" \"10\" C11137159 Group3 12 \"C11138929\" \"Group2b\" \"2\" \"MissingData\" C11137167 Group3 14 \"B11154532\" \"Group1\" \"456\" \"886\" C11137167 Group3 16 \"B11155267\" \"Group3\" \"900\" \"10\" C11137439 Group3 15 \"B11137120\" \"Group2b\" \"450\" \"456\" C11137439 Group3 79 \"B33191224\" \"Group2b\" \"450\" \"776\" C11137443 Group3 15 \"B11155267\" \"Group3\" \"900\" \"10\" C11137544 Group1 22 \"C11138999\" \"Group2b\" \"900\" \"MissingData\" C11137123 Group2 68 \"B11131605\" \"Group1\" \"456\" \"MissingData\" C11138150 Group1 44 \"B11137784\" \"Group1\" \"900\" \"436\" C11138152 Group1 10 \"B11156098\" \"Group1\" \"500\" \"886\" C11138797 Group1 24 \"B11133232\" \"Group1\" \"500\" \"MissingData\" C11138184 Group1 57 \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" C11138122 Group1 23 \"C11138912\" \"Group2b\" \"900\" \"MissingData\" C11138122 MISSING 25 \"B11150911\" \"Group2b\" \"900\" \"117\" C11138192 Group1 45 \"B11152577\" \"Group1\" \"900\" \"756\" B12226507 Group1 26 \"B11156098\" \"Group1\" \"456\" \"886\" B12226546 Group1 55 \"B11133232\" \"Group1\" \"456\" \"MissingData\" Example 4: Print the first column of file2.txt followed (horizontally) by the second column of file4.txt . awk '{print $1}' file2.txt will read and print the first column of file2.txt . Conversely, awk '{print $2}' file4.txt will read and print the second column of file4.txt . You must use the following syntax to concatenate these two results horizontally: $ paste <(awk '{print $1}' file2.txt) <(awk '{print $2}' file4.txt) \"AnonymizedID\"\u2003SubjectGroup \"B11130912\"\u2003Group1 \"B11137244\"\u2003Group1 \"B11154534\"\u2003Group2 \"B11144100\"\u2003Group3 \"B11137244\"\u2003Group3 \"B12226566\"\u2003Group2 \"B11134987\"\u2003Group2 \"B11144345\"\u2003Group1 \"C11137159\"\u2003Group2 \"B11156453\"\u2003Group3 \"B11110676\"\u2003Group3 \"C11138929\"\u2003Group3 \"B11154532\"\u2003Group3 \"B11155267\"\u2003Group3 \"B11137120\"\u2003Group3 \"B33191224\"\u2003Group3 \"B11155267\"\u2003Group1 \"C11138999\"\u2003Group2 \"B11131605\"\u2003Group1 \"B11137784\"\u2003Group1 \"B11156098\"\u2003Group1 \"B11133232\"\u2003Group1 \"B11135292\"\u2003Group1 \"C11138912\"\u2003MISSING \"B11150911\"\u2003Group1 \"B11152577\"\u2003Group1 \"B11156098\"\u2003Group1 \"B11133232\" Example 5: Print the first column of file1.csv followed (horizontally) by the second column of file3.csv . Separate the columns with a comma. In this example, we use the same syntax as the example before, but because file1.csv and file3.csv use comma as the column separator, you have to use the -F',' flag in the awk commands. Additionally, remember to use the flag -d ',' for the paste command in order to separate the pasted columns with a comma. $ paste -d ',' <(awk -F',' '{print $1}' file1.csv) <(awk -F',' '{print $2}' file3.csv) \"Anonymized ID\",Subject Group \"B33199522\",MISSING \"B33199603\",Group1 \"B11137879\",Group1 \"B11144410\",Group1 \"B11110455\",Group1 \"B11135291\",Group1 \"B11153927\",Group1 \"B11177579\",Group1 \"B11177806\",Group1 \"B11157958\",Group3 \"B11110690\",Group3 \"B11152799\",Group3 \"B11154358\",Group3 \"B11110925\",Group2 b \"B11135291\",Group2 b \"B11135072\",Group2 b \"B33199603\",Group1 \"B11137879\",Group3 \"B11110603\",Group2 b \"B11110927\",Group3 \"B11147712\",Group3 \"B33191224\",Group1 \"B11131290\",Group3 \"B11157974\",Group1 \"B33191224\",Group1 \"B11141503\",Group2 b \"C11137159\",Group1 \"B33199522\",","title":"Horizontal concatenation"},{"location":"txt_csv/#reading-specific-lines","text":"Example 1: Print the first line of file1.csv . In order to print only the first line of the file, we first read it using the cat command, and then we select the first line from the previous output using head -n 1 . $ cat file1.csv | head -n 1 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" Example 2: Print the first two lines of file1.csv . In order to print only the first two lines of the file we first read it using the cat command, and then we select those lines from the previous output using head -n 2 . $ cat file1.csv | head -n 2 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" Example 3: Print the first three lines of file1.csv . $ cat file1.csv | head -n 3 \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" Example 4: Print the last line of file1.csv . In order to print only the last line of the file we first read it using the cat command, and then we select the last line from the previous output using tail -n 1 . $ cat file1.csv | tail -n 1 \"B33199522\",\"Group1\",\"0\",\"\" Example 5: Print the last two lines of file1.csv . $ cat file1.csv | tail -n 2 \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\" Example 6: Print the last three lines of file1.csv in reverse . As we learned previously, the flag -r of tail command can be used to print things in reversed order. $ cat file1.csv | tail -r -n 3 \"B33199522\",\"Group1\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B11141503\",\"Group3\",\"0\",\"\" Example 7: Print from the second line until the end of the file for file1.csv (omit the first line). $ cat file1.csv | head -n+2 \"B33199522\",\"Group1\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" \"B33199522\",\"Group1\",\"0\",\"\"","title":"Reading specific lines"},{"location":"txt_csv/#searching-a-value","text":"In the following examples we will read specific columns or lines in a file or a list of files, that contain a searched value. Example 1: Print the line(s) of file3.csv that contain the string C11137439 . Using awk : $ awk '/C11137439/' file3.csv C11137439,Group3,79 C11137439,Group3,15 Using grep : $ grep C11137439 file3.csv C11137439,Group3,79 C11137439,Group3,15 Example 2: Print the line(s) of file3.csv that contain the string AAA (which is stored in a variable). Using awk : $ VAR=C11137439 $ awk -v var=$VAR '$0~var' file3.csv C11137439,Group3,79 C11137439,Group3,15 Using grep : $ grep $VAR file3.csv C11137439,Group3,79 C11137439,Group3,15 Example 3: Print the line(s) of file3.csv that contain the strings C11137439 or B11119909 . To search for more than one expression, add the flag -e in front of each expression. $ grep -e \"C11137439\" -e \"B11119909\" file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 Example 4: Print the line(s) of file3.csv that contain the strings C11137439 , B11119909 or B11110893 . $ grep -e \"C11137439\" -e \"B11119909\" -e \"B11110893\" file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 B11110893,Group1,28 Example 5: Print the line(s) of file3.csv that contain the strings C11137439 or B11119909 (which are stored in a file called patterns.txt ). $ cat patterns.txt C11137439 B11119909 $ grep -f patterns.txt file3.csv C11137439,Group3,79 C11137439,Group3,15 B11119909,Group2 b,61 Example 6: Print the line(s) of file3.csv that do not contain the string C11137439 . $ grep -v \"C11137439\" file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 7: Print the line(s) of any file in the current directory that contain the string C11137439 . $ awk '/C11137439/' * C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 C11137439 Group3 79 C11137439 $ grep C11137439 * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 patterns.txt:C11137439 To omit the file names using grep , use the flag -h : $ grep -h C11137439 * C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 C11137439 Group3 79 C11137439 If you wanted to include the line number for each match, you can add the flag -n : $ grep -n \"C11137439\" * file3.csv:21:C11137439,Group3,79 file3.csv:22:C11137439,Group3,15 file4.txt:15:C11137439 Group3 15 file4.txt:16:C11137439 Group3 79 patterns.txt:1:C11137439 $ grep -h -n \"C11137439\" * 21:C11137439,Group3,79 22:C11137439,Group3,15 15:C11137439 Group3 15 16:C11137439 Group3 79 1:C11137439 If you want to show only the first three matches, you can add the flag -m 3 (to print only three lines): $ grep -m 3 \"C11137439\" * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file4.txt:C11137439 Group3 15 $ grep -m 3 \"C11137439\" * -h C11137439,Group3,79 C11137439,Group3,15 C11137439 Group3 15 Example 8: Print the number of lines in each file of the current directory that contain C11137439 . $ grep -c \"C11137439\" * file1.csv:0 file1_reordered.csv:0 file2.txt:0 file3.csv:2 file4.txt:2 patterns.txt:1 patterns2.txt:0 Example 9: Print only the name of the files in the current directory that contain C11137439 . $ grep -l \"C11137439\" * file3.csv file4.txt patterns.txt Example 10: Print the line(s) of any file in the current directory that contain C11137439 , each line followed by the next three lines in the corresponding file (if there are three or more lines after the matched one). $ grep -A 3 \"C11137439\" * file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- patterns.txt:C11137439 patterns.txt-B11119909 Example 11: Print the line(s) of any file in the current directory that contain C11137439 , each line preceded by the previous three lines in the corresponding file (if there are three or more lines before the matched one). $ grep -B 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 -- patterns.txt:C11137439 Example 12: Print the line(s) of any file in the current directory that contain C11137439 , each line preceded by the previous three lines and followed by the next three lines in the corresponding file (if there is three or more lines before/after the matched one). $ grep -C 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- -- patterns.txt:C11137439 patterns.txt-B11119909 $ grep -A 3 -B 3 \"C11137439\" * file3.csv-C11137544,Group1,21 file3.csv-C11137443,Group3,11 file3.csv-C11137123,Group2 b,69 file3.csv:C11137439,Group3,79 file3.csv:C11137439,Group3,15 file3.csv-C11133100,Group1,23 file3.csv-D11144030,Group3,13 file3.csv-B11108399,Group1,23 -- -- file4.txt-C11137159 Group3 12 file4.txt-C11137167 Group3 14 file4.txt-C11137167 Group3 16 file4.txt:C11137439 Group3 15 file4.txt:C11137439 Group3 79 file4.txt-C11137443 Group3 15 file4.txt-C11137544 Group1 22 file4.txt-C11137123 Group2 68 -- -- patterns.txt:C11137439 patterns.txt-B11119909 Example 13: Print the line(s) of any file in the current directory that contain \"B11133232\" (including the quotation marks). $ awk '/\"B11133232\"/' * \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" $ grep \\\"B11133232\\\" * file2.txt:\"B11133232\" \"Group1\" \"500\" \"MissingData\" file2.txt:\"B11133232\" \"Group1\" \"456\" \"MissingData\" IF you want to make sure the quotation marks are included in the grep search, you must include the backslash before the quotation marks ( \\\" ). Otherwise, Bash will interpret the search value as B11133232 and not \"B11133232\" . Example 14: Print the line(s) of file3.csv that contain B11108399 or B11108326 . This search has the following rules: We're looking for words that start with the following seven characters: B111083 . The 8th character can be a 9 or a 2 . The last character can be a 9 or a 6 . So, in the grep command, we replace the 8th character by [92] to indicate that it can have any of those two values, and the last character by [96] to indicate that it can have value 9 or 6 . $ grep B111083[92][96] file3.csv B11108399,Group1,23 B11108326,Group1,59 Example 15: Print the line(s) of file3.csv that contain the values Group1 or Group2 . $ grep Group[12] file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137123,Group2 b,69 C11133100,Group1,23 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 16: Print the first column of file2.txt and file3.csv for those lines that contain the values Group1 or Group2 . Remember that you have to use the flag -F',' with awk when the columns of the file are separated by commas and not spaces. Space-separated file: $ grep Group[12] file2.txt | awk '{print $1}' \"B11130912\" \"B11137244\" \"B11154534\" \"B11144100\" \"B11137244\" \"B12226566\" \"B11134987\" \"B11144345\" \"B11110676\" \"C11138929\" \"B11154532\" \"B11137120\" \"B33191224\" \"C11138999\" \"B11131605\" \"B11137784\" \"B11156098\" \"B11133232\" \"C11138912\" \"B11150911\" \"B11152577\" \"B11156098\" \"B11133232\" Comma-separated file: $ grep Group[12] file3.csv | awk -F',' '{print $1}' C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11131039 C11135566 B11119903 C11137544 C11137123 C11133100 B11108399 B11108326 B11119909 B11110893 Example 17: Print the first and second columns of file2.txt and file3.csv for those lines that contain the values Group1 or Group2 . Space-separated file: $ grep Group[12] file2.txt | awk '{print $1,$2}' \"B11130912\" \"Group2b\" \"B11137244\" \"Group1\" \"B11154534\" \"Group1\" \"B11144100\" \"Group1\" \"B11137244\" \"Group1\" \"B12226566\" \"Group2b\" \"B11134987\" \"Group1\" \"B11144345\" \"Group1\" \"B11110676\" \"Group1\" \"C11138929\" \"Group2b\" \"B11154532\" \"Group1\" \"B11137120\" \"Group2b\" \"B33191224\" \"Group2b\" \"C11138999\" \"Group2b\" \"B11131605\" \"Group1\" \"B11137784\" \"Group1\" \"B11156098\" \"Group1\" \"B11133232\" \"Group1\" \"C11138912\" \"Group2b\" \"B11150911\" \"Group2b\" \"B11152577\" \"Group1\" \"B11156098\" \"Group1\" \"B11133232\" \"Group1\" Comma-separated file: $ grep Group[12] file3.csv | awk -F',' '{print $1,$2}' C11138192 Group1 B12226507 Group1 B12226546 Group1 C11138122 Group1 C11138184 Group1 C11138797 Group1 C11138152 Group1 C11138150 Group1 C11131039 Group2 b C11135566 Group2 b B11119903 Group2 b C11137544 Group1 C11137123 Group2 b C11133100 Group1 B11108399 Group1 B11108326 Group1 B11119909 Group2 b B11110893 Group1 Example 18: Print the line(s) of file3.csv and file4.txt that have value 11 in the third column. Space-separated file: $ awk '$3 == \"11\" {print $1,$2}' file4.txt D11144030 Group3 C11137159 Group3 Comma-separated file: $ awk -F',' '$3 == \"11\" {print $1,$2}' file3.csv C11137443 Group3 Example 19: Print the first and second columns of those lines in file3.csv and file4.txt that have value 11 in the third column. Space-separated file: $ awk '$3 == \"11\" {print $1,$2}' file4.txt D11144030 Group3 C11137159 Group3 Comma-separated file: $ awk -F',' '$3 == \"11\" {print $1,$2}' file3.csv C11137443 Group3 Example 20: Print the line(s) of file1.csv and file2.txt that have value \"Group1\" (including the colons) in the second column. Space-separated file: $ awk '$2 == \"\\\"Group1\\\"\"' file2.txt \"B11137244\" \"Group1\" \"450\" \"555\" \"B11154534\" \"Group1\" \"456\" \"456\" \"B11144100\" \"Group1\" \"450\" \"886\" \"B11137244\" \"Group1\" \"450\" \"456\" \"B11134987\" \"Group1\" \"900\" \"MissingData\" \"B11144345\" \"Group1\" \"900\" \"776\" \"B11110676\" \"Group1\" \"900\" \"10\" \"B11154532\" \"Group1\" \"456\" \"886\" \"B11131605\" \"Group1\" \"456\" \"MissingData\" \"B11137784\" \"Group1\" \"900\" \"436\" \"B11156098\" \"Group1\" \"500\" \"886\" \"B11133232\" \"Group1\" \"500\" \"MissingData\" \"B11152577\" \"Group1\" \"900\" \"756\" \"B11156098\" \"Group1\" \"456\" \"886\" \"B11133232\" \"Group1\" \"456\" \"MissingData\" Comma-separated file: $ awk -F',' '$2 == \"\\\"Group1\\\"\"' file1.csv \"B33199522\",\"Group1\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11153927\",\"Group1\",\"0\",\"\" \"B11177806\",\"Group1\",\"MD\",\"\" \"B11152799\",\"Group1\",\"0\",\"\" \"B11154358\",\"Group1\",\"0\",\"\" \"B11110925\",\"Group1\",\"0\",\"\" \"B11137879\",\"Group1\",\"0\",\"\" \"B11110603\",\"Group1\",\"0\",\"\" \"B11110927\",\"Group1\",\"0\",\"\" \"B11147712\",\"Group1\",\"0\",\"\" \"B11157974\",\"Group1\",\"0\",\"\" \"B33199522\",\"Group1\",\"0\",\"\" Example 21: Print the line(s) of file1.csv and file2.txt that do not have value \"Group1\" (including the quotation marks) in the second column. Space-separated file: $ awk '$2 != \"\\\"Group1\\\"\"' file2.txt \"AnonymizedID\" \"SubjectGroup\" \"TEST1\" \"TEST2\" \"B11130912\" \"Group2b\" \"900\" \"MissingData\" \"B12226566\" \"Group2b\" \"450\" \"MissingData\" \"C11137159\" \"Group3\" \"MissingData\" \"MissingData\" \"B11156453\" \"Group4\" \"456\" \"2\" \"C11138929\" \"Group2b\" \"2\" \"MissingData\" \"B11155267\" \"Group3\" \"900\" \"10\" \"B11137120\" \"Group2b\" \"450\" \"456\" \"B33191224\" \"Group2b\" \"450\" \"776\" \"B11155267\" \"Group3\" \"900\" \"10\" \"C11138999\" \"Group2b\" \"900\" \"MissingData\" \"B11135292\" \"Group3\" \"MissingData\" \"MissingData\" \"C11138912\" \"Group2b\" \"900\" \"MissingData\" \"B11150911\" \"Group2b\" \"900\" \"117\" Comma-separated file: $ awk -F',' '$2 != \"\\\"Group1\\\"\"' file1.csv \"Anonymized ID\",\"Subject Group\",\"HASCONDITION\",\"CONDITION\" \"B33199603\",\"Group3\",\"0\",\"\" \"B11144410\",\"Group2 b\",\"0\",\"\" \"B11110455\",\"Group2 b\",\"0\",\"\" \"B11135291\",\"Group3\",\"0\",\"\" \"B11177579\",\"Group2 b\",\"0\",\"\" \"B11157958\",\"Group3\",\"0\",\"\" \"B11110690\",\"Group3\",\"0\",\"\" \"B11135291\",\"Group3\",\"9\",\"mTBI\" \"B11135072\",\"MISSING\",\"0\",\"\" \"B33199603\",\"Group3\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11131290\",\"Group2 b\",\"0\",\"\" \"B33191224\",\"Group2 b\",\"0\",\"\" \"B11141503\",\"Group3\",\"0\",\"\" \"C11137159\",\"Group3\",\"9\",\"mTBI\" Example 22: Print the first column of those lines in file1.csv and file2.txt that do not have value \"Group1\" (including the quotation marks) in the second column. Space-separated file: $ awk '$2 != \"\\\"Group1\\\"\" {print $1}' file2.txt \"AnonymizedID\" \"B11130912\" \"B12226566\" \"C11137159\" \"B11156453\" \"C11138929\" \"B11155267\" \"B11137120\" \"B33191224\" \"B11155267\" \"C11138999\" \"B11135292\" \"C11138912\" \"B11150911\" Comma-separated file: $ awk -F',' '$2 != \"\\\"Group1\\\"\" {print $1}' file1.csv \"Anonymized ID\" \"B33199603\" \"B11144410\" \"B11110455\" \"B11135291\" \"B11177579\" \"B11157958\" \"B11110690\" \"B11135291\" \"B11135072\" \"B33199603\" \"B33191224\" \"B11131290\" \"B33191224\" \"B11141503\" \"C11137159\" Example 23: Print the first column of those lines in file3.csv and file4.txt that have age (third column) greater than 20. Space-separated file: $ awk '$3 > \"20\" {print $1}' file4.txt AnonymizedID B11108326 B11110893 B11119909 B11119903 C11131039 C11133100 C11135566 C11137439 C11137544 C11137123 C11138150 C11138797 C11138184 C11138122 C11138122 C11138192 B12226507 B12226546 Comma-separated file: $ awk -F',' '$3 > \"20\" {print $1}' file3.csv Anonymized ID C11138122 C11138192 B12226507 B12226546 C11138122 C11138184 C11138797 C11138152 C11138150 C11131039 C11135566 B11119903 C11137544 C11137123 C11137439 C11133100 B11108399 B11108326 B11119909 B11110893 Example 24: Print the first column of those lines in file3.csv and file4.txt that have age (third column) less than 20. Space-separated file: $ awk '$3 < \"20\" {print $1}' file4.txt D11144030 D11144030 C11137159 C11137159 C11137167 C11137167 C11137439 C11137443 C11138152 Comma-separated file: $ awk -F',' '$3 < \"20\" {print $1}' file3.csv C11137167 C11137159 C11137167 C11137159 C11137443 C11137439 D11144030 Example 25: Print the line(s) of file3.csv that have value \"Group1\" or \"Group3\" in the second column. When there is more than one rule, the easiest and more organized way to run the command is to put all the rules in a text file and call that text file using the flag -f . In the following example, patterns3.txt contains the rules to filter the lines that are to be printed ( $2 == \"Group1\" and $2 == \"Group3\" ). $ cat patterns3.txt $2 == \"Group1\" $2 == \"Group3\" $ awk -F',' -f patterns3.txt file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137544,Group1,21 C11137443,Group3,11 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11110893,Group1,28 $ cat patterns4.txt $2 == \"Group1\" || $2 == \"Group3\" $ awk -F',' -f test.txt file3.csv C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137544,Group1,21 C11137443,Group3,11 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11110893,Group1,28 In this example, we obtained the same result using either patterns3.txt or patterns4.txt . When you want to select any line that contains any pattern in a list of patterns, you can either put each pattern in a different line of the text file or use the or ( || ) symbol to concatenate all the patterns or rules. Example 26: Print the first column of those lines in file3.csv that have value \"Group1\" in the second column, and value greater than 60 in the third column. Or that have value \"Group3\" in the second column value less than 20 in the third column. In this example, we want to print any line that contains one of the following rules: Second column equals Group1 and third greater than 60: $2 == \"Group1\" && $3 > 60 Second column equals and Group3 third less than 20: $2 == \"Group3\" && $3 < 20 So, the content of our pattern file must be: $ cat patterns5.txt $2 == \"Group1\" && $3 > 60 $2 == \"Group3\" && $3 < 20 To print all the columns from the selected lines: $ awk -F',' -f patterns5.txt file3.csv B12226507,Group1,68 B12226546,Group1,67 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11137443,Group3,11 C11137439,Group3,15 D11144030,Group3,13 To print the first column: $ awk -F',' -f patterns5.txt file3.csv | awk -F',' '{print $1}' B12226507 B12226546 C11137167 C11137159 C11137167 C11137159 C11137443 C11137439 D11144030 The following page contains a summary of other patterns that can be included in a pattern file: https://ss64.com/bash/awk.html .","title":"Searching a value"},{"location":"txt_csv/#searching-a-pattern","text":"Example 1: Print the line(s) of file3.csv that start with B . $ grep '^B' file3.csv B12226507,Group1,68 B12226546,Group1,67 B11119903,Group2 b,83 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 2: Print the line(s) of test7.csv that end with 13 . $ grep '13$' file3.csv C11137159,Group3,13 C11137159,Group3,13 D11144030,Group3,13 Example 3: Print the line(s) of test7.csv that end with 13 (when this pattern is stored in a file called patterns2.txt ). $ cat patterns2.txt 13$ $ grep -f patterns2.txt file3.csv C11137159,Group3,13 C11137159,Group3,13 D11144030,Group3,13 Example 4: Print all the non-empty lines (lines with more than 0 fields NF > 0 ) in file3.csv and file4.txt . Space-separated file: $ awk 'NF > 0' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Comma-separated file: $ awk -F',' 'NF > 0' file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Example 5: Print all the lines that have more than two fields ( NF > 2 ) in file3.csv and file4.txt . Space-separated file: $ awk 'NF > 2' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Comma-separated file: $ awk -F',' 'NF > 2' file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28","title":"Searching a pattern"},{"location":"txt_csv/#find-and-replace-text","text":"Replace all occurrences of C11137159 in file3.csv with XXXXXXXXX and save the modified content in file3_mod.csv . Command to execute the substitution: sed 's/C11137159/XXXXXXXXX/' file3.csv > file3_mod.csv Content of file3.csv before the substitution: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content of file3.csv after the substitution: $ cat file3_mod.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 XXXXXXXXX,Group3,13 C11137167,Group3,16 XXXXXXXXX,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28","title":"Find and replace text"},{"location":"txt_csv/#find-and-replace-patterns","text":"In the following examples, instead of replacing a fix string as we did before, we will replace a group of characters (i.e. all upper-case characters in the file) by a single character or another group of characters (i.e. replace with lower-case characters). The groups of characters that can be used are listed in the following table: Expression Group of characters [:alnum:] Letters and digits [:alpha:] Letters [:blank:] Horizontal white space [:cntrl:] Control characters [:digit:] Digits [:graph:] Printable characters, excluding space [:lower:] Lower-case letters [:print:] Printable characters, including space [:punct:] Punctuation characters [:space:] Horizontal or vertical white space [:upper:] Upper-case letters [:xdigit:] Hexadecimal digits Example 1: Replace all upper-case letters in file3.csv by lower-case. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:upper:]' '[:lower:]' anonymized id,subject group,age c11138122,missing,21 c11138192,group1,54 b12226507,group1,68 b12226546,group1,67 c11138122,group1,24 c11138184,group1,59 c11138797,group1,22 c11138152,group1,53 c11138150,group1,41 c11137167,group3,14 c11137159,group3,13 c11137167,group3,16 c11137159,group3,13 c11131039,group2 b,67 c11135566,group2 b,73 b11119903,group2 b,83 c11137544,group1,21 c11137443,group3,11 c11137123,group2 b,69 c11137439,group3,79 c11137439,group3,15 c11133100,group1,23 d11144030,group3,13 b11108399,group1,23 b11108326,group1,59 b11119909,group2 b,61 b11110893,group1,28 Example 2: Replace all lower-case letters in file3.csv by upper-case. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:lower:]' '[:upper:]' ANONYMIZED ID,SUBJECT GROUP,AGE C11138122,MISSING,21 C11138192,GROUP1,54 B12226507,GROUP1,68 B12226546,GROUP1,67 C11138122,GROUP1,24 C11138184,GROUP1,59 C11138797,GROUP1,22 C11138152,GROUP1,53 C11138150,GROUP1,41 C11137167,GROUP3,14 C11137159,GROUP3,13 C11137167,GROUP3,16 C11137159,GROUP3,13 C11131039,GROUP2 B,67 C11135566,GROUP2 B,73 B11119903,GROUP2 B,83 C11137544,GROUP1,21 C11137443,GROUP3,11 C11137123,GROUP2 B,69 C11137439,GROUP3,79 C11137439,GROUP3,15 C11133100,GROUP1,23 D11144030,GROUP3,13 B11108399,GROUP1,23 B11108326,GROUP1,59 B11119909,GROUP2 B,61 B11110893,GROUP1,28 Example 3: Replace all alphabetical characters in file3.csv by the number 0. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:alpha:]' 0 0000000000 00,0000000 00000,000 011138122,0000000,21 011138192,000001,54 012226507,000001,68 012226546,000001,67 011138122,000001,24 011138184,000001,59 011138797,000001,22 011138152,000001,53 011138150,000001,41 011137167,000003,14 011137159,000003,13 011137167,000003,16 011137159,000003,13 011131039,000002 0,67 011135566,000002 0,73 011119903,000002 0,83 011137544,000001,21 011137443,000003,11 011137123,000002 0,69 011137439,000003,79 011137439,000003,15 011133100,000001,23 011144030,000003,13 011108399,000001,23 011108326,000001,59 011119909,000002 0,61 011110893,000001,28 Example 4: Replace all digits in file3.csv by the letter X . Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:digit:]' X Anonymized ID,Subject Group,AGE CXXXXXXXX,MISSING,XX CXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX b,XX BXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX b,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX CXXXXXXXX,GroupX,XX DXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX,XX BXXXXXXXX,GroupX b,XX BXXXXXXXX,GroupX,XX Example 5: Replace all punctuation characters in file3.csv by a space. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:punct:]' ' ' Anonymized ID Subject Group AGE C11138122 MISSING 21 C11138192 Group1 54 B12226507 Group1 68 B12226546 Group1 67 C11138122 Group1 24 C11138184 Group1 59 C11138797 Group1 22 C11138152 Group1 53 C11138150 Group1 41 C11137167 Group3 14 C11137159 Group3 13 C11137167 Group3 16 C11137159 Group3 13 C11131039 Group2 b 67 C11135566 Group2 b 73 B11119903 Group2 b 83 C11137544 Group1 21 C11137443 Group3 11 C11137123 Group2 b 69 C11137439 Group3 79 C11137439 Group3 15 C11133100 Group1 23 D11144030 Group3 13 B11108399 Group1 23 B11108326 Group1 59 B11119909 Group2 b 61 B11110893 Group1 28 Example 5: Replace all white spaces in file3.csv by an underscore. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr '[:blank:]' '_' Anonymized_ID,Subject_Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2_b,67 C11135566,Group2_b,73 B11119903,Group2_b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2_b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2_b,61 B11110893,Group1,28","title":"Find and replace patterns"},{"location":"txt_csv/#replace-range-of-letters-or-numbers","text":"Example 6: Replace any A , B or C (letters in the range A-C) in file3.csv by the letter D . Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr 'A-C' 'D' Dnonymized ID,Subject Group,DGE D11138122,MISSING,21 D11138192,Group1,54 D12226507,Group1,68 D12226546,Group1,67 D11138122,Group1,24 D11138184,Group1,59 D11138797,Group1,22 D11138152,Group1,53 D11138150,Group1,41 D11137167,Group3,14 D11137159,Group3,13 D11137167,Group3,16 D11137159,Group3,13 D11131039,Group2 b,67 D11135566,Group2 b,73 D11119903,Group2 b,83 D11137544,Group1,21 D11137443,Group3,11 D11137123,Group2 b,69 D11137439,Group3,79 D11137439,Group3,15 D11133100,Group1,23 D11144030,Group3,13 D11108399,Group1,23 D11108326,Group1,59 D11119909,Group2 b,61 D11110893,Group1,28 Example 7: Replace A by W, B by X , C by Y , and D by Z in file3.csv (replace letters in the range A-D with letters in the range W-Z). Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr 'A-D' 'W-Z' Wnonymized IZ,Subject Group,WGE Y11138122,MISSING,21 Y11138192,Group1,54 X12226507,Group1,68 X12226546,Group1,67 Y11138122,Group1,24 Y11138184,Group1,59 Y11138797,Group1,22 Y11138152,Group1,53 Y11138150,Group1,41 Y11137167,Group3,14 Y11137159,Group3,13 Y11137167,Group3,16 Y11137159,Group3,13 Y11131039,Group2 b,67 Y11135566,Group2 b,73 X11119903,Group2 b,83 Y11137544,Group1,21 Y11137443,Group3,11 Y11137123,Group2 b,69 Y11137439,Group3,79 Y11137439,Group3,15 Y11133100,Group1,23 Z11144030,Group3,13 X11108399,Group1,23 X11108326,Group1,59 X11119909,Group2 b,61 X11110893,Group1,28 Example 8: Remove all spaces in file3.csv : you can use the -d flag for deletion. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr -d '[:blank:]' AnonymizedID,SubjectGroup,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2b,67 C11135566,Group2b,73 B11119903,Group2b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2b,61 B11110893,Group1,28 Example 9: Remove any repeated characters ( [:alnum:] ) in file3.csv : In order to delete any repeated (continuous) character or sequence use the -s flag. Original content of the file: $ cat file3.csv Anonymized ID,Subject Group,AGE C11138122,MISSING,21 C11138192,Group1,54 B12226507,Group1,68 B12226546,Group1,67 C11138122,Group1,24 C11138184,Group1,59 C11138797,Group1,22 C11138152,Group1,53 C11138150,Group1,41 C11137167,Group3,14 C11137159,Group3,13 C11137167,Group3,16 C11137159,Group3,13 C11131039,Group2 b,67 C11135566,Group2 b,73 B11119903,Group2 b,83 C11137544,Group1,21 C11137443,Group3,11 C11137123,Group2 b,69 C11137439,Group3,79 C11137439,Group3,15 C11133100,Group1,23 D11144030,Group3,13 B11108399,Group1,23 B11108326,Group1,59 B11119909,Group2 b,61 B11110893,Group1,28 Content after replacements: $ cat file3.csv | tr -s '[:alnum:]' Anonymized ID,Subject Group,AGE C13812,MISING,21 C138192,Group1,54 B126507,Group1,68 B126546,Group1,67 C13812,Group1,24 C138184,Group1,59 C138797,Group1,2 C138152,Group1,53 C138150,Group1,41 C137167,Group3,14 C137159,Group3,13 C137167,Group3,16 C137159,Group3,13 C131039,Group2 b,67 C1356,Group2 b,73 B1903,Group2 b,83 C13754,Group1,21 C13743,Group3,1 C137123,Group2 b,69 C137439,Group3,79 C137439,Group3,15 C1310,Group1,23 D14030,Group3,13 B10839,Group1,23 B108326,Group1,59 B1909,Group2 b,61 B10893,Group1,28","title":"Replace range of letters or numbers"},{"location":"txt_csv/#print-files-information","text":"Example 1: Print the number of lines in file3.csv and file4.txt . Comma-separated file: $ awk '{print NF}' file3.csv | wc -l 28 $ nlines=$(awk '{print NF}' file3.csv | wc -l) $ echo $nlines 28 Space-separated file: $ awk '{print NF}' file4.txt | wc -l 29 $ nlines=$(awk '{print NF}' file4.txt | wc -l) $ echo $nlines 29 Example 2: Print the number of columns in file3.csv and file4.txt . Comma-separated file: $ awk -F',' '{print NF}' file3.csv | sort \u2013nu 3 $ ncols=$(awk -F',' '{print NF}' file3.csv | sort -nu) $ echo $ncols 3 Space-separated file: $ awk '{print NF}' file4.txt | sort -nu 3 $ ncols=$(awk '{print NF}' file4.txt | sort -nu) $ echo $ncols 3 Example 3: Print the length of each line of file4.txt . To get the length of a string you can use the function length() , and pass as parameter $0 which obtains all the fields (the whole line). Print each line: $ awk '{print $0}' file4.txt AnonymizedID SubjectGroup AGE B11108326 Group1 59 B11108399 Group1 23 B11110893 Group1 28 B11119909 Group2 61 D11144030 Group3 11 D11144030 Group3 13 B11119903 Group2 84 C11131039 Group2 67 C11133100 Group1 23 C11135566 Group2 72 C11137159 Group3 11 C11137159 Group3 12 C11137167 Group3 14 C11137167 Group3 16 C11137439 Group3 15 C11137439 Group3 79 C11137443 Group3 15 C11137544 Group1 22 C11137123 Group2 68 C11138150 Group1 44 C11138152 Group1 10 C11138797 Group1 24 C11138184 Group1 57 C11138122 Group1 23 C11138122 MISSING 25 C11138192 Group1 45 B12226507 Group1 26 B12226546 Group1 55 Print the length of each line: $ awk '{print length($0)}' file4.txt 29 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 20 19 19 19 Example 4: Print the length of the second field ( length($2) ) in file3.csv and file4.txt . Comma-separated file: $ awk '{print length($2)}' file4.txt 12 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 6 Space-separated file: $ awk -F',' '{print length($2)}' file3.csv 13 7 6 6 6 6 6 6 6 6 6 6 6 6 8 8 8 6 6 8 6 6 6 6 6 6 8 6 Example 5: Print all the lines of file4.txt in upper-case. To convert a string to upper-case use the function toupper() and pass as parameter $0 which contains the whole line. $ awk '{print toupper($0)}' file4.txt ANONYMIZEDID SUBJECTGROUP AGE B11108326 GROUP1 59 B11108399 GROUP1 23 B11110893 GROUP1 28 B11119909 GROUP2 61 D11144030 GROUP3 11 D11144030 GROUP3 13 B11119903 GROUP2 84 C11131039 GROUP2 67 C11133100 GROUP1 23 C11135566 GROUP2 72 C11137159 GROUP3 11 C11137159 GROUP3 12 C11137167 GROUP3 14 C11137167 GROUP3 16 C11137439 GROUP3 15 C11137439 GROUP3 79 C11137443 GROUP3 15 C11137544 GROUP1 22 C11137123 GROUP2 68 C11138150 GROUP1 44 C11138152 GROUP1 10 C11138797 GROUP1 24 C11138184 GROUP1 57 C11138122 GROUP1 23 C11138122 MISSING 25 C11138192 GROUP1 45 B12226507 GROUP1 26 B12226546 GROUP1 55 Example 6: Print all the lines of file4.txt in lower-case. To convert a string to lower-case use the function tolower() and pass as parameter $0 which contains the whole line. $ awk '{print tolower($0)}' file4.txt anonymizedid subjectgroup age b11108326 group1 59 b11108399 group1 23 b11110893 group1 28 b11119909 group2 61 d11144030 group3 11 d11144030 group3 13 b11119903 group2 84 c11131039 group2 67 c11133100 group1 23 c11135566 group2 72 c11137159 group3 11 c11137159 group3 12 c11137167 group3 14 c11137167 group3 16 c11137439 group3 15 c11137439 group3 79 c11137443 group3 15 c11137544 group1 22 c11137123 group2 68 c11138150 group1 44 c11138152 group1 10 c11138797 group1 24 c11138184 group1 57 c11138122 group1 23 c11138122 missing 25 c11138192 group1 45 b12226507 group1 26 b12226546 group1 55 Some other functions that can be used in addition to toupper() and tolower() can be found here .","title":"Print files information"},{"location":"variables/","text":"Variables An important aspect of programming is the ability to use a variables. For example, I can use the variable desktop to represent the string \"/Users/myuser/Desktop\" . Or the variable year to represent the number 2025 . Variables make the code more readable, short and organized, and prevent typing errors. They are also useful in cases in which the actual value of a variable is not known before executing the program, or when you need to save the output of one command to use as input for another command. In Bash you don't specify data types. However, if the value that you are assigning is a string, you should use quotation marks between the beginning and the end of your string, especially if the string contains spaces. Be careful not to include any white space between the variable name, the equals sign, and the value. Additionally, be aware that the quotation marks used in Bash are \" , which is different than those used in Microsoft Word. They look similar, but Bash won't recognize the later ones. So, if you copy-paste from Microsoft Word a command that includes quotation marks, you will get an error. Declaring variables Numbers, strings and characters should be declared in a different manner: YEAR=2018 MONTH=\"August\" NAME=\"Monica Keith\" GENDER='F' Common mistakes when declaring variables: The following commands will produce errors because there is a white space before and/or after the equal sign, or because the quotation marks are missing when declaring a string that contains a space. Bellow each erroneous command you can see the error that Bash produces. $ NAME =\"Monica Keith\" -bash: NAME: command not found $ NAME= \"Monica Keith\" -bash: Monica Keith: command not found $ NAME = \"Monica Keith\" -bash: NAME: command not found $ NAME=Monica Keith -bash: Keith: command not found Once you assign a value to a variable, you can reference it with a dollar sign, located immediately before the variable name. You can also include curly brackets at the beginning and the end of the variable name to prevent errors in your code when referencing strings that have spaces or special characters. Referencing variables In the following example, I will declare variable VAR1 with value 2 , and variable VAR2 with value \"Subject\" . Then, I will use the echo to print the value of the two variables. $ VAR1=2 $ VAR2=\"Subject\" $ echo ${VAR1} 2 $ echo ${VAR2} Subject Common mistakes: When referencing a variable, be careful not to include any space before or after the brackets. The following examples will produce an error because of the inclusion of a space around the brackets: $ echo ${ VAR2} -bash: ${ VAR2}: bad substitution $ echo ${VAR2 } -bash: ${VAR2 }: bad substitution $ echo ${ VAR2 } -bash: ${ VAR2 }: bad substitution The following erroneous reference (with a space between the dollar sign and the first bracket) will not cause an error, but will not substitute ${VAR2} for the correct value. It will just print $ {VAR2} instead of Subject . $ echo $ {VAR2} {VAR2} Concatenating variables You can concatenate different variables and characters to form new strings. To do this, you will need to reference the variables using the curly brackets and use quotation marks at the beginning and the end of your final string. For example, if you want to use the previously declared variables VAR1 and VAR2 to generate the String Subject_02 , you can concatenate them the following way: $ echo ${VAR2} Subject $ echo ${VAR1} 2 $ echo \"${VAR2}_0${VAR1}\" Subject_02 Here are a few more examples on how to declare and concatenate variables: $ ID=\"Subject_202\" $ VOLUME=20 $ MEASURE=\"mm\" $ echo \"${ID}: ${VOLUME}${MEASURE}\" Subject_202: 20mm $ VAR1=\"MacOS\" $ VAR2=\"Linux\" $ VAR3=\"Windows\" $ echo \"(${VAR1},${VAR2},${VAR3})\" (MacOS,Linux,Windows) Common mistakes: It is very common when you are referencing many variables or concatenating variables to create a long string to forget the closing quotation mark. For example, writing $ echo \"(${VAR1},${VAR2},${VAR3}) instead of $ echo \"(${VAR1},${VAR2},${VAR3})\" When that happens and you click enter in the keyboard, the command line won't allow you to enter any more commands. You will see the symbol > and if you continue pressing enter it will do nothing. This is because the command line is waiting for you to close the open String. To close the string, just add the missing quotation mark or cancel and ignore what you have written so far in the current line by pressing CTR+C. Variable names You can assign any value to a variable. However, a variable cannot have just any name. There are a few rules for assigning variable names. A variable name should not be a number: this type of variable is only used to read arguments on a shell script. For example, $1 refers to the first argument of a script, $2 to the second argument, etc. Later you will learn the meaning and use of script arguments . Variable names must start with an alphabetical letter or an underscore: variable names can contain any number, but it should not be located at the beginning. Do not use $ or ${} to declare a variable: these characters are used only to reference variables. Do not assign the name PATH to any variable: if you do so, you won't get any error right away. But it will mess up the execution of other programs. PATH is a system variable that specifies a set of directories where executable programs are located. For example, when you install a software that runs in the command line, the path to the executable of that program will be included in the system variable PATH . So, if you rename that variable, you won't be able to execute the program again in the current terminal. If you forget about this rule and mistakenly re-write the value of this variable, close the current terminal and open a new one. Every time you open a new terminal, this system variable will be re-set to the correct value (which is stored in the bash_profile). At any moment you can know the value of your PATH by typing echo ${PATH} . You will see something like this, although this significantly varies between computers depending on which programs you have installed and referenced in the bash_profile file. bash $ echo ${PATH} /usr/local/fsl/bin:/Applications/freesurfer/bin:/Applications/freesurfer/fsfast/bin:/Applications/freesurfer/tktools:/usr/local/fsl/bin:/Applications/freesurfer/mni/bin:/Users/bunbury/bin:/Applications/MATLAB_R2018a.app/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin Another Unix reserved name that you should not use is BASH . There is a long list of Unix reserved words that I will not include here but you will learn as you get more experienced. Avoid using the following reserved characters from appearing in variable names: / > < | : & . * . Here are some examples of valid and invalid variable names: Valid Invalid Reason V 1 You cant use numbers as variable names. VAR 1VAR A variable name cant start with a number. VAR1 2_VAR A variable name cant start with a number. VAR_1 .VAR A variable name cant start with a reserved character ( . ). _VAR1 $VAR A variable name cant start with a reserved character ( $ ). This syntax is used to reference, not to declare a variable. _1VAR ${VAR} A variable name cant start with a reserved character ( $ ). This syntax is used to reference, not to declare a variable. VARIABLE_NAME {VAR} A variable name cant contain brackets. PATH1 PATH PATH is a reserved word and should not be used as a variable in your scripts. BASH1 BASH BASH is a reserved word and should not be used as a variable in your scripts. Variable names can be in lower and/or upper case. However, they are case sensitive. If you declare a variable as VAR1 , but you reference it as ${var1} , Bash will not recognize the value. You must reference it as ${VAR1} . Reading user input The command read is the counterpart of echo . Instead of printing things in the terminal the way echo does, read reads input from the user and saves it in the specified variable (in the example below VAR ). The command read is followed by the name of the variable where you want to save the information. In the following example, I am going to read the input from the user and save it in the variable VAR . Generally, Bash will read everything that is written until the user presses the Enter key and save all the information in the corresponding variable. Saving user input into a new variables: $ echo \"Username:\" Username: $ read VAR Noemi $ echo \"You typed: ${VAR}\" You typed: Noemi There are some flags that can be added to the command read to change the way in which information is displayed or captured: Valid Invalid -s Silent mode: the characters that the user inputs are not displayed (used when asking the user to input a password). -p \"MESSAGE\" Displays MESSAGE where the user must write the input. Generally with instructions about what the user must input. -n NUM_CHARS The input line ends after reading NUM_CHARS characters, rather than waiting for the user to press Enter in the keyboard. -d 'CHAR_NEW_LINE' CHAR_NEW_LINE is used to determine the end of the input line (if different than Enter). -r Backslash does not act as an escape character but instead is part of the line. -t NSECONDS Bash will stop reading the user input after NSECONDS . Whatever was entered in that time is captured as the input line. -a ARRAY_NAME The words that the user inputs are assigned to sequential indices of the array ARRAY_NAME . The array is emptied before assigning the values if it already exists. -u FILEDESCRIPTOR Read input from FILEDESCRIPTOR . The following examples will show how to use the flags mentioned in the previous table. In this section, I will not explain the use of flags -a and -u because we haven't learned yet about arrays or file manipulation . These will be explained in the corresponding chapters. Some of the examples will also show common mistakes that will make Bash show an error. Usage of read -s : In the following example, the flag -s causes the user input to be silenced, so when the user writes the password, it is not shown in the screen. If the user input is ThisIsMyPassword , then that string is saved in the variable PASSWORD . While the user is writing its password and until it presses Enter, you will see the following symbol underneath $ read -s PASSWORD : . Afterwards, the symbol will disappear. In the example below of a wrong syntax, the mistake is that the variable PASSWORD is written before the flag -s . The variable must go at the end of the command independently of which flags are used. As a result, Bash is not silencing the user input, is giving the invalid identifier error, and is not saving any string in the variable. Correct syntax: $ read -s PASSWORD $ echo ${PASSWORD} ThisIsMyPassword Wrong syntax: $ read PASSWORD -s ThisIsMyPassword -bash: read: `-s': not a valid identifier Usage of read -p : The flag -p is useful if you want to prompt a message so that the user knows what the input should be. The examples in the following table combine the flags -p and -s to indicate the user to input a password and hide the password while its being typed. The prompt message should go right after the flag -p . The following table shows some examples of commands written using a wrong syntax (as well as the correct way to write them). In the first example, the error is that the prompt message is not located right after the flag -p (instead, it is located after the flag -s ). In the second example, the error is that the variable PASSWORD is not located at the end of the command. In the third example, the problem is that the prompt message (Please input your password) is not surrounded by quotation marks. So, for Bash only the first word of that sentence (Please) is the prompt message, and the next word (input) is read as the variable name. The rest of the command (your password) is ignored. That is why when reading ${PASSWORD} , nothing is echoed, the variable is empty because nothing was saved with that variable name. Instead, the input was saved in ${input} . This is the reason why the prompt message should always be surrounded by quotation marks. Correct syntax: $ read -p \"Please input your password: \" -s PASSWORD Please input your password: $ echo ${PASSWORD} ThisIsMyPassword Wrong syntax: $ read -p -s \"Please input your password\" PASSWORD -s -bash: read: `Please input your password': not a valid identifier $ read PASSWORD -s -p \"Please input your password\" ThisIsMyPassword -bash: read: `-s': not a valid identifier $ read -s -p Please input your password ThisIsMyPassword $ echo $PASSWORD $ echo ${input} ThisIsMyPassword Usage of read -n : In the following example, -n 1 forces Bash to accept only one character in the input. So, the terminal will finish reading after one character. Here we are combining flags -n and -p to also prompt a message to the user. In the wrong syntax, 1 (the number of characters to be accepted) and the prompt message are located in the wrong place. The number of characters accepted should always go after -n and the prompt message should always go after -p . Correct syntax: $ read -n 1 -p \"Do you wish to continue? (y/n)\" VAR Do you wish to continue? (y/n)y $ echo $VAR y $ read -p \"Do you wish to continue? (y/n)\" -n 1 VAR Do you wish to continue? (y/n)y $ echo $VAR y Wrong syntax: $ read -n -p 1 \"Do you wish to continue? (y/n)\" VAR -bash: read: -p: invalid number Usage of read -d : In the following example the end of the line is determined by the character # instead of Enter (using the flag -d ). As soon as the user types # , Bash finishes reading and saves the input in the variable VAR . Correct syntax: $ read -d '#' VAR $ echo $VAR SomeText Wrong syntax: In this example we are missing the apostrophes ( ' ) around the character # . So, everything after # is being considered as comment and not as part of the command. $ read -d # VAR -bash: read: -d: option requires an argument read: usage: read [-ers] [-u fd] [-t timeout] [-p prompt] [-a array] [-n nchars] [-d delim] [name ...] Keep in mind that Bash will convert any carriage return to spaces: $ read -d '#' VAR lala aaaa # $ echo $VAR lala aaaa The backslash: In Bash, certain characters have special meanings. For example, the dollar sign is used to reference a variable. When you type ${VAR} , Bash will print the value of VAR , instead of the actual string \"\\${VAR}\". The backslash is used to remove those special meanings from the character followed by it. $ VAR=\"Some text\" $ echo ${VAR} Some text $ echo \\${VAR} ${VAR} When using the flag -r , the backslash is part of the line instead of being used as an escape character. The following examples show that when we use -r backslash is part of the input string, and when we don't, it's used as a scape character. $ read -r VAR C:\\Documents\\Newsletters\\Summer2018.pdf $ echo ${VAR} C:\\Documents\\Newsletters\\Summer2018.pdf $ read VAR C:\\Documents\\Newsletters\\Summer2018.pdf $ echo ${VAR} C:DocumentsNewslettersSummer2018.pdf $ read -r MESSAGE In HTML \\n is used to indicate a new line $ echo ${MESSAGE} In HTML \\n is used to indicate a new line $ read MESSAGE In HTML \\n is used to indicate a new line $ echo ${MESSAGE} In HTML n is used to indicate a new line Reading from other sources So far, we have used the command read to save the user input into a variable. This command can also be used to read from other sources (i.e. other variables or files). Reading content from a variable: In the following example, read reads the content of the variable VAR , but only keeps the first character (because it is using the -n 1 flag): $ VAR=yes $ read -n 1 R <<< ${VAR} $ echo ${R} y Reading and saving the output of a function: read also allows you to read the output of a function and save it into a variable. In this example, we are saving the output of the pwd into the variable CURRENT_DIR . pwd is a function that prints the current folder in which you are located in the command line. $ pwd /Users/myUserName $ read CURRENT_DIR <<< $(pwd) $ echo ${CURRENT_DIR} /Users/myUserName","title":"Variables"},{"location":"variables/#variables","text":"An important aspect of programming is the ability to use a variables. For example, I can use the variable desktop to represent the string \"/Users/myuser/Desktop\" . Or the variable year to represent the number 2025 . Variables make the code more readable, short and organized, and prevent typing errors. They are also useful in cases in which the actual value of a variable is not known before executing the program, or when you need to save the output of one command to use as input for another command. In Bash you don't specify data types. However, if the value that you are assigning is a string, you should use quotation marks between the beginning and the end of your string, especially if the string contains spaces. Be careful not to include any white space between the variable name, the equals sign, and the value. Additionally, be aware that the quotation marks used in Bash are \" , which is different than those used in Microsoft Word. They look similar, but Bash won't recognize the later ones. So, if you copy-paste from Microsoft Word a command that includes quotation marks, you will get an error.","title":"Variables"},{"location":"variables/#declaring-variables","text":"Numbers, strings and characters should be declared in a different manner: YEAR=2018 MONTH=\"August\" NAME=\"Monica Keith\" GENDER='F' Common mistakes when declaring variables: The following commands will produce errors because there is a white space before and/or after the equal sign, or because the quotation marks are missing when declaring a string that contains a space. Bellow each erroneous command you can see the error that Bash produces. $ NAME =\"Monica Keith\" -bash: NAME: command not found $ NAME= \"Monica Keith\" -bash: Monica Keith: command not found $ NAME = \"Monica Keith\" -bash: NAME: command not found $ NAME=Monica Keith -bash: Keith: command not found Once you assign a value to a variable, you can reference it with a dollar sign, located immediately before the variable name. You can also include curly brackets at the beginning and the end of the variable name to prevent errors in your code when referencing strings that have spaces or special characters.","title":"Declaring variables"},{"location":"variables/#referencing-variables","text":"In the following example, I will declare variable VAR1 with value 2 , and variable VAR2 with value \"Subject\" . Then, I will use the echo to print the value of the two variables. $ VAR1=2 $ VAR2=\"Subject\" $ echo ${VAR1} 2 $ echo ${VAR2} Subject Common mistakes: When referencing a variable, be careful not to include any space before or after the brackets. The following examples will produce an error because of the inclusion of a space around the brackets: $ echo ${ VAR2} -bash: ${ VAR2}: bad substitution $ echo ${VAR2 } -bash: ${VAR2 }: bad substitution $ echo ${ VAR2 } -bash: ${ VAR2 }: bad substitution The following erroneous reference (with a space between the dollar sign and the first bracket) will not cause an error, but will not substitute ${VAR2} for the correct value. It will just print $ {VAR2} instead of Subject . $ echo $ {VAR2} {VAR2}","title":"Referencing variables"},{"location":"variables/#concatenating-variables","text":"You can concatenate different variables and characters to form new strings. To do this, you will need to reference the variables using the curly brackets and use quotation marks at the beginning and the end of your final string. For example, if you want to use the previously declared variables VAR1 and VAR2 to generate the String Subject_02 , you can concatenate them the following way: $ echo ${VAR2} Subject $ echo ${VAR1} 2 $ echo \"${VAR2}_0${VAR1}\" Subject_02 Here are a few more examples on how to declare and concatenate variables: $ ID=\"Subject_202\" $ VOLUME=20 $ MEASURE=\"mm\" $ echo \"${ID}: ${VOLUME}${MEASURE}\" Subject_202: 20mm $ VAR1=\"MacOS\" $ VAR2=\"Linux\" $ VAR3=\"Windows\" $ echo \"(${VAR1},${VAR2},${VAR3})\" (MacOS,Linux,Windows) Common mistakes: It is very common when you are referencing many variables or concatenating variables to create a long string to forget the closing quotation mark. For example, writing $ echo \"(${VAR1},${VAR2},${VAR3}) instead of $ echo \"(${VAR1},${VAR2},${VAR3})\" When that happens and you click enter in the keyboard, the command line won't allow you to enter any more commands. You will see the symbol > and if you continue pressing enter it will do nothing. This is because the command line is waiting for you to close the open String. To close the string, just add the missing quotation mark or cancel and ignore what you have written so far in the current line by pressing CTR+C.","title":"Concatenating variables"},{"location":"variables/#variable-names","text":"You can assign any value to a variable. However, a variable cannot have just any name. There are a few rules for assigning variable names. A variable name should not be a number: this type of variable is only used to read arguments on a shell script. For example, $1 refers to the first argument of a script, $2 to the second argument, etc. Later you will learn the meaning and use of script arguments . Variable names must start with an alphabetical letter or an underscore: variable names can contain any number, but it should not be located at the beginning. Do not use $ or ${} to declare a variable: these characters are used only to reference variables. Do not assign the name PATH to any variable: if you do so, you won't get any error right away. But it will mess up the execution of other programs. PATH is a system variable that specifies a set of directories where executable programs are located. For example, when you install a software that runs in the command line, the path to the executable of that program will be included in the system variable PATH . So, if you rename that variable, you won't be able to execute the program again in the current terminal. If you forget about this rule and mistakenly re-write the value of this variable, close the current terminal and open a new one. Every time you open a new terminal, this system variable will be re-set to the correct value (which is stored in the bash_profile). At any moment you can know the value of your PATH by typing echo ${PATH} . You will see something like this, although this significantly varies between computers depending on which programs you have installed and referenced in the bash_profile file. bash $ echo ${PATH} /usr/local/fsl/bin:/Applications/freesurfer/bin:/Applications/freesurfer/fsfast/bin:/Applications/freesurfer/tktools:/usr/local/fsl/bin:/Applications/freesurfer/mni/bin:/Users/bunbury/bin:/Applications/MATLAB_R2018a.app/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin Another Unix reserved name that you should not use is BASH . There is a long list of Unix reserved words that I will not include here but you will learn as you get more experienced. Avoid using the following reserved characters from appearing in variable names: / > < | : & . * . Here are some examples of valid and invalid variable names: Valid Invalid Reason V 1 You cant use numbers as variable names. VAR 1VAR A variable name cant start with a number. VAR1 2_VAR A variable name cant start with a number. VAR_1 .VAR A variable name cant start with a reserved character ( . ). _VAR1 $VAR A variable name cant start with a reserved character ( $ ). This syntax is used to reference, not to declare a variable. _1VAR ${VAR} A variable name cant start with a reserved character ( $ ). This syntax is used to reference, not to declare a variable. VARIABLE_NAME {VAR} A variable name cant contain brackets. PATH1 PATH PATH is a reserved word and should not be used as a variable in your scripts. BASH1 BASH BASH is a reserved word and should not be used as a variable in your scripts. Variable names can be in lower and/or upper case. However, they are case sensitive. If you declare a variable as VAR1 , but you reference it as ${var1} , Bash will not recognize the value. You must reference it as ${VAR1} .","title":"Variable names"},{"location":"variables/#reading-user-input","text":"The command read is the counterpart of echo . Instead of printing things in the terminal the way echo does, read reads input from the user and saves it in the specified variable (in the example below VAR ). The command read is followed by the name of the variable where you want to save the information. In the following example, I am going to read the input from the user and save it in the variable VAR . Generally, Bash will read everything that is written until the user presses the Enter key and save all the information in the corresponding variable. Saving user input into a new variables: $ echo \"Username:\" Username: $ read VAR Noemi $ echo \"You typed: ${VAR}\" You typed: Noemi There are some flags that can be added to the command read to change the way in which information is displayed or captured: Valid Invalid -s Silent mode: the characters that the user inputs are not displayed (used when asking the user to input a password). -p \"MESSAGE\" Displays MESSAGE where the user must write the input. Generally with instructions about what the user must input. -n NUM_CHARS The input line ends after reading NUM_CHARS characters, rather than waiting for the user to press Enter in the keyboard. -d 'CHAR_NEW_LINE' CHAR_NEW_LINE is used to determine the end of the input line (if different than Enter). -r Backslash does not act as an escape character but instead is part of the line. -t NSECONDS Bash will stop reading the user input after NSECONDS . Whatever was entered in that time is captured as the input line. -a ARRAY_NAME The words that the user inputs are assigned to sequential indices of the array ARRAY_NAME . The array is emptied before assigning the values if it already exists. -u FILEDESCRIPTOR Read input from FILEDESCRIPTOR . The following examples will show how to use the flags mentioned in the previous table. In this section, I will not explain the use of flags -a and -u because we haven't learned yet about arrays or file manipulation . These will be explained in the corresponding chapters. Some of the examples will also show common mistakes that will make Bash show an error. Usage of read -s : In the following example, the flag -s causes the user input to be silenced, so when the user writes the password, it is not shown in the screen. If the user input is ThisIsMyPassword , then that string is saved in the variable PASSWORD . While the user is writing its password and until it presses Enter, you will see the following symbol underneath $ read -s PASSWORD : . Afterwards, the symbol will disappear. In the example below of a wrong syntax, the mistake is that the variable PASSWORD is written before the flag -s . The variable must go at the end of the command independently of which flags are used. As a result, Bash is not silencing the user input, is giving the invalid identifier error, and is not saving any string in the variable. Correct syntax: $ read -s PASSWORD $ echo ${PASSWORD} ThisIsMyPassword Wrong syntax: $ read PASSWORD -s ThisIsMyPassword -bash: read: `-s': not a valid identifier Usage of read -p : The flag -p is useful if you want to prompt a message so that the user knows what the input should be. The examples in the following table combine the flags -p and -s to indicate the user to input a password and hide the password while its being typed. The prompt message should go right after the flag -p . The following table shows some examples of commands written using a wrong syntax (as well as the correct way to write them). In the first example, the error is that the prompt message is not located right after the flag -p (instead, it is located after the flag -s ). In the second example, the error is that the variable PASSWORD is not located at the end of the command. In the third example, the problem is that the prompt message (Please input your password) is not surrounded by quotation marks. So, for Bash only the first word of that sentence (Please) is the prompt message, and the next word (input) is read as the variable name. The rest of the command (your password) is ignored. That is why when reading ${PASSWORD} , nothing is echoed, the variable is empty because nothing was saved with that variable name. Instead, the input was saved in ${input} . This is the reason why the prompt message should always be surrounded by quotation marks. Correct syntax: $ read -p \"Please input your password: \" -s PASSWORD Please input your password: $ echo ${PASSWORD} ThisIsMyPassword Wrong syntax: $ read -p -s \"Please input your password\" PASSWORD -s -bash: read: `Please input your password': not a valid identifier $ read PASSWORD -s -p \"Please input your password\" ThisIsMyPassword -bash: read: `-s': not a valid identifier $ read -s -p Please input your password ThisIsMyPassword $ echo $PASSWORD $ echo ${input} ThisIsMyPassword Usage of read -n : In the following example, -n 1 forces Bash to accept only one character in the input. So, the terminal will finish reading after one character. Here we are combining flags -n and -p to also prompt a message to the user. In the wrong syntax, 1 (the number of characters to be accepted) and the prompt message are located in the wrong place. The number of characters accepted should always go after -n and the prompt message should always go after -p . Correct syntax: $ read -n 1 -p \"Do you wish to continue? (y/n)\" VAR Do you wish to continue? (y/n)y $ echo $VAR y $ read -p \"Do you wish to continue? (y/n)\" -n 1 VAR Do you wish to continue? (y/n)y $ echo $VAR y Wrong syntax: $ read -n -p 1 \"Do you wish to continue? (y/n)\" VAR -bash: read: -p: invalid number Usage of read -d : In the following example the end of the line is determined by the character # instead of Enter (using the flag -d ). As soon as the user types # , Bash finishes reading and saves the input in the variable VAR . Correct syntax: $ read -d '#' VAR $ echo $VAR SomeText Wrong syntax: In this example we are missing the apostrophes ( ' ) around the character # . So, everything after # is being considered as comment and not as part of the command. $ read -d # VAR -bash: read: -d: option requires an argument read: usage: read [-ers] [-u fd] [-t timeout] [-p prompt] [-a array] [-n nchars] [-d delim] [name ...] Keep in mind that Bash will convert any carriage return to spaces: $ read -d '#' VAR lala aaaa # $ echo $VAR lala aaaa The backslash: In Bash, certain characters have special meanings. For example, the dollar sign is used to reference a variable. When you type ${VAR} , Bash will print the value of VAR , instead of the actual string \"\\${VAR}\". The backslash is used to remove those special meanings from the character followed by it. $ VAR=\"Some text\" $ echo ${VAR} Some text $ echo \\${VAR} ${VAR} When using the flag -r , the backslash is part of the line instead of being used as an escape character. The following examples show that when we use -r backslash is part of the input string, and when we don't, it's used as a scape character. $ read -r VAR C:\\Documents\\Newsletters\\Summer2018.pdf $ echo ${VAR} C:\\Documents\\Newsletters\\Summer2018.pdf $ read VAR C:\\Documents\\Newsletters\\Summer2018.pdf $ echo ${VAR} C:DocumentsNewslettersSummer2018.pdf $ read -r MESSAGE In HTML \\n is used to indicate a new line $ echo ${MESSAGE} In HTML \\n is used to indicate a new line $ read MESSAGE In HTML \\n is used to indicate a new line $ echo ${MESSAGE} In HTML n is used to indicate a new line","title":"Reading user input"},{"location":"variables/#reading-from-other-sources","text":"So far, we have used the command read to save the user input into a variable. This command can also be used to read from other sources (i.e. other variables or files). Reading content from a variable: In the following example, read reads the content of the variable VAR , but only keeps the first character (because it is using the -n 1 flag): $ VAR=yes $ read -n 1 R <<< ${VAR} $ echo ${R} y Reading and saving the output of a function: read also allows you to read the output of a function and save it into a variable. In this example, we are saving the output of the pwd into the variable CURRENT_DIR . pwd is a function that prints the current folder in which you are located in the command line. $ pwd /Users/myUserName $ read CURRENT_DIR <<< $(pwd) $ echo ${CURRENT_DIR} /Users/myUserName","title":"Reading from other sources"},{"location":"videos/","text":"Manipulating videos","title":"Videos"},{"location":"videos/#manipulating-videos","text":"","title":"Manipulating videos"}]}
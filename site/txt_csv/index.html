<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="Monica Keith">
    
    <link rel="shortcut icon" href="../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Text and CSV files - Bash Tutorial</title>
    <link href="../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../js/jquery-3.2.1.min.js"></script>
    <script src="../js/bootstrap-3.3.7.min.js"></script>
    <script src="../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Manipulating text and csv files", url: "#_top", children: [
              {title: "Writing files", url: "#writing-files" },
              {title: "Reading files", url: "#reading-files" },
              {title: "The read command", url: "#the-read-command" },
              {title: "awk", url: "#awk" },
              {title: "grep", url: "#grep" },
              {title: "Examples: awk and grep", url: "#examples-awk-and-grep" },
              {title: "paste", url: "#paste" },
              {title: "Reading specific lines", url: "#reading-specific-lines" },
              {title: "Searching a value", url: "#searching-a-value" },
              {title: "Searching a pattern", url: "#searching-a-pattern" },
              {title: "Find and replace text", url: "#find-and-replace-text" },
              {title: "Find and replace patterns", url: "#find-and-replace-patterns" },
              {title: "Replace range of letters or numbers", url: "#replace-range-of-letters-or-numbers" },
              {title: "Print files information", url: "#print-files-information" },
          ]},
        ];

    </script>
    <script src="../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../img_files/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../img_files/" class="btn btn-xs btn-link">
        Image files
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../files/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../files/" class="btn btn-xs btn-link">
        File manipulation
      </a>
    </div>
    
  </div>

    

    <h1 id="manipulating-text-and-csv-files">Manipulating text and csv files</h1>
<h2 id="writing-files">Writing files</h2>
<h3 id="echo"><code>echo</code></h3>
<p>So far we have used <code>echo</code> to print text into the terminal. You can also use this utility to print text into a file (and create a new file if it doesn't exist):</p>
<p><code>echo "some text" &gt;&gt; someFile.txt</code> appends <code>some text</code> in a new line of <code>someFile.txt</code> and adds the new line character at the end. If <code>someFile.txt</code> didn't exist, the file is created.</p>
<p>If you add the flag <code>-n</code>, Bash won't print the trailing newline character: <code>echo -n "some text" &gt;&gt; someFile.txt</code>.</p>
<p>If you add the flag <code>-e</code>, Bash will interpret the character scape sequences in the text (see table below in the <code>printf</code> section for a list of scape sequences).</p>
<p>If you use <code>&gt;</code> instead of <code>&gt;&gt;</code>, the previous contents of the file (if it existed) will be erased and replaced with the new text that you are echoing.</p>
<h3 id="printf"><code>printf</code></h3>
<p><code>printf</code> is a powerful tool that allows you to format the information before printing it in a file, the command line or another variable. For example, you can specify the format of any number that you print and the number of decimal points you want to use. You could even use this tool to change the format of a variable (i.e. from scientific notation to float) and save the result in a new variable instead of a file. You can also add tab or any character scape sequence to your text.</p>
<p>Syntax: <code>printf &lt;format&gt; &lt;arguments&gt;</code></p>
<p><code>printf</code> uses the format specified in <code>&lt;format&gt;</code> to print the objects (strings, numbers or variables) specified in <code>&lt;arguments&gt;</code>. In contrast with the <code>echo</code> command, <code>printf</code> does not print the text in a new line by default, in order to add a new line the following character scape sequence should be added at the end of <code>&lt;format&gt;</code>: <code>\n</code>.</p>
<h3 id="format">Format</h3>
<p><code>&lt;format&gt;</code> is a string that contains alphanumerical characters, character scape sequences and format specifications, each of which causes printing of the next successive argument. The table below shows the strings that can be used for formatting.</p>
<p>One should specify one format per argument. For example, in the command <code>printf "%d %s" 10 "my_string"</code>, <code>"%d %s"</code> is the format, which indicates that the first argument after the format (<code>10</code>) should be printed as a decimal (<code>%d</code>). Then, there should be a space, and then the second argument (<code>my_string</code>) should be printed as a string (<code>%s</code>).</p>
<p>In <code>printf "%d %s\n" 10 "my_string"</code>, <code>%d %s\n</code> is the format, which indicates that the first argument after the format (<code>10</code>) should be printed as a decimal (<code>%d</code>), followed by a space. The second argument (<code>string</code>) should be printed as a string (<code>%s</code>). It also indicates that after the second argument there should be a new-line character (<code>\n</code>). <code>\n</code> is a scape sequence. The list of <a href="#scape-sequences">scape sequences</a> can be found bellow. If any of the arguments is a string with special characters, spaces or <a href="#scape-sequences">scape sequences</a>, make sure to always surround it with quotation marks.</p>
<table>
<thead>
<tr>
<th>Format option</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>%%</code></td>
<td>Prints the symbol <code>%</code> and no argument is used. For example, <code>printf "%%"</code> just prints a <code>%</code>.</td>
</tr>
<tr>
<td><code>%b</code></td>
<td>Prints the corresponding argument as a string. The <a href="#scape-sequences">scape sequences</a> are interpreted instead of reading them as literal strings. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision).</td>
</tr>
<tr>
<td><code>%c</code></td>
<td>Prints the first character of the corresponding argument if it is a string or the first digit if it's a number. <code>printf "%c %c" "some string" 199</code> will print <code>s 1</code>.</td>
</tr>
<tr>
<td><code>%d</code></td>
<td>The corresponding argument is a positive or negative integer number. If no precision is specified, it just prints the number. Otherwise, adds zeros before the integer to achieve the number of digits specified in the precision. For example, <code>printf "%d %.5d\n" -2 2</code> prints <code>-2 00002</code>.</td>
</tr>
<tr>
<td><code>%e</code></td>
<td>Prints the corresponding argument, which should be a number, in scientific notation. There will be one digit before the decimal point and six digits after the decimal point if no precision is specified (or the number of digits specified in the precision). Infinity is printed as <code>inf</code> and NaN as <code>nan</code>. For example, <code>234.567</code> equals <code>2.34567 × 102</code> in scientific notation. So, if we use <code>printf "%e" 234.567</code>, the result will be <code>2.345670e+02</code>.</td>
</tr>
<tr>
<td><code>%f</code></td>
<td>Prints the corresponding argument, which should be a number, in floating-point. The number of digits after the decimal point equals the precision or six digits if no precision was specified. Infinity is printed as <code>inf</code> and NaN as <code>nan</code>. For example, <code>printf "%f\n" 2.34567890123</code> will print <code>2.345679</code> and <code>printf "%.3f\n" -2.34567890123</code> will print <code>-2.346</code>.</td>
</tr>
<tr>
<td><code>%s</code></td>
<td>Prints the corresponding argument as a string. The <a href="#scape-sequences">scape sequences</a> are interpreted as literal strings. So, <code>printf "%s,%s" "text1" "text2\ttext3"</code> will print <code>text1,text2ttext3</code>, no tab introduced. It will stop when the number of characters specified in the precision is reached or at the end of the string if the precision is not specified (or if the string has less characters than the precision). For example, <code>printf "%s" "example"</code> will print <code>example</code>, and <code>printf "%.3s" "example"</code> will print <code>exa</code>.</td>
</tr>
</tbody>
</table>
<h3 id="scape-sequences">Scape sequences</h3>
<table>
<thead>
<tr>
<th>Character scape sequence</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\b</code></td>
<td>Do not print the previous character (acts as backspace). For example, <code>printf "%b" "abcdef"</code> will print <code>abcdef</code>, while <code>printf "%b" "abc\bdef"</code> will print <code>abdef</code>.</td>
</tr>
<tr>
<td><code>\c</code></td>
<td>Suppresses any output after the sequence. For example, <code>printf "%b" "Hello\c World"</code> will print only <code>Hello</code>. <code>World</code> will not be printed.</td>
</tr>
<tr>
<td><code>\n</code></td>
<td>Write a new-line character. For example, <code>printf "%b" "abc\ndef"</code> will print <code>abc</code> in one line, and <code>def</code> in another line.</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>Moves the cursor to the beginning of the current line. So, the following characters will replace the ones at the beginning of the line. For example, <code>printf "%b" "Happy World\rLala"</code> prints <code>Lalay World</code> because <code>Lala</code> is written at the beginning of the line and replaces <code>Happ</code>.</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>Write a tab character.</td>
</tr>
<tr>
<td><code>\v</code></td>
<td>Write a vertical tab.</td>
</tr>
<tr>
<td><code>\'</code></td>
<td>Write a single quote character.</td>
</tr>
<tr>
<td><code>\\</code></td>
<td>Write a backslash character.</td>
</tr>
</tbody>
</table>
<h3 id="save-result-to-a-variable">Save result to a variable</h3>
<p>You can save the output of <code>printf</code> into a variable instead of printing it. For example, if you have a number in scientific notation and you want to convert it to floating, you can type the following:</p>
<pre><code class="language-bash">$ FLOAT=$(printf &quot;%f&quot; 2.345670e+02)
$ echo $FLOAT
234.567000
</code></pre>
<h2 id="reading-files">Reading files</h2>
<h3 id="reading-line-by-line">Reading line by line</h3>
<p>The <code>cat</code> command, followed by the path of a file, can be used to visualize the content of the file in the command line:</p>
<pre><code class="language-bash">$ cat subjectList.txt
AA0083277
AA0084999
AC0208933
AC0148099
AD0190300
BB0299033
BC0345100
BD0365666
CA0372599
CA0381677
CB0384399
CC0384433
DD0385444
</code></pre>
<p>If you want to read a file line by line and run a set of instructions on each line, you can combine the <code>cat</code> and <code>for</code> commands. The following example reads the content of a file line by line (which contains a list of subject IDs) and copies that information into a new file with their group membership, which can be obtained from the first two letters of the subject ID. The first two letters of each line are extracted with <code>${line:0:2}</code>.</p>
<pre><code class="language-bash">$ for line in $(cat subjectList.txt)
&gt; do
&gt; echo &quot;${line:0:2},${line}&quot; &gt;&gt; subjectInfo.txt
&gt; don
</code></pre>
<p>The content of <code>subjectInfo.txt</code> after running those lines will be:</p>
<pre><code class="language-txt">AA,AA0083277
AA,AA0084999
AC,AC0208933
AC,AC0148099
AD,AD0190300
BB,BB0299033
BC,BC0345100
BD,BD0365666
CA,CA0372599
CA,CA0381677
CB,CB0384399
CC,CC0384433
DD,DD0385444
</code></pre>
<h3 id="doing-statistics">Doing statistics</h3>
<p>This is the content of <code>infoFile.txt</code>:</p>
<table>
<thead>
<tr>
<th>SubjectID</th>
<th>Group</th>
<th>Gender</th>
<th>Ethnicity</th>
<th>Handedness</th>
<th>Age</th>
<th>Movement</th>
</tr>
</thead>
<tbody>
<tr>
<td>AA0083277</td>
<td>Control</td>
<td>M</td>
<td>Hispanic</td>
<td>R</td>
<td>20</td>
<td>0.23525</td>
</tr>
<tr>
<td>AA0084999</td>
<td>Patient</td>
<td>M</td>
<td>Hispanic</td>
<td>R</td>
<td>18</td>
<td>0.14564</td>
</tr>
<tr>
<td>AC0208933</td>
<td>Control</td>
<td>F</td>
<td>Hispanic</td>
<td>R</td>
<td>17</td>
<td>0.18698</td>
</tr>
<tr>
<td>AC0148099</td>
<td>Control</td>
<td>M</td>
<td>NonHispanic</td>
<td>R</td>
<td>21</td>
<td>0.19789</td>
</tr>
<tr>
<td>AD0190300</td>
<td>Patient</td>
<td>M</td>
<td>NonHispanic</td>
<td>R</td>
<td>16</td>
<td>0.23454</td>
</tr>
<tr>
<td>BB0299033</td>
<td>Control</td>
<td>F</td>
<td>NonHispanic</td>
<td>R</td>
<td>22</td>
<td>0.19752</td>
</tr>
<tr>
<td>BC0345100</td>
<td>Control</td>
<td>M</td>
<td>NonHispanic</td>
<td>R</td>
<td>19</td>
<td>0.18789</td>
</tr>
<tr>
<td>BD0365666</td>
<td>Patient</td>
<td>F</td>
<td>NonHispanic</td>
<td>R</td>
<td>17</td>
<td>0.14386</td>
</tr>
<tr>
<td>CA0372599</td>
<td>Patient</td>
<td>F</td>
<td>NonHispanic</td>
<td>R</td>
<td>20</td>
<td>0.12384</td>
</tr>
<tr>
<td>CA0381677</td>
<td>Control</td>
<td>F</td>
<td>NonHispanic</td>
<td>L</td>
<td>17</td>
<td>0.13453</td>
</tr>
<tr>
<td>CB0384399</td>
<td>Control</td>
<td>F</td>
<td>Hispanic</td>
<td>R</td>
<td>18</td>
<td>0.45655</td>
</tr>
<tr>
<td>CC0384433</td>
<td>Control</td>
<td>M</td>
<td>NonHispanic</td>
<td>R</td>
<td>15</td>
<td>0.13465</td>
</tr>
<tr>
<td>DD0385444</td>
<td>Patient</td>
<td>M</td>
<td>Hispanic</td>
<td>R</td>
<td>16</td>
<td>0.32433</td>
</tr>
</tbody>
</table>
<p>In this example we will calculate the minimum, maximum and average movement in the MRI scanner for the subjects in each group and gender. These values should be shown with only three decimals. There are many ways to do that, some of them a lot more efficient than the one presented here, using functions that we have not learn yet but that will be introduced further down in this document. We will use in this case the <code>cat</code> command to read from the file, the <code>for</code> loop, and some non-integer and array operations that have been learned from previous chapters.</p>
<p>The <code>for</code> will read in each loop one line of the text file and extract the gender, group and movement values. Depending the group and gender, it will add the movement to one of the following arrays:</p>
<ul>
<li>CM: to save the movement of all male controls.</li>
<li>CF: to save the movement of all female controls.</li>
<li>PM: to save the movement of all male patients.</li>
<li>PF: to save the movement of all female patients.</li>
</ul>
<p>In Bash it is not necessary to initialize an array. Instead, you can start adding values. The first time that you add a value to a non-existent array, it will be automatically initialized. When you ask Bash the size of an array that hasn’t been initialized, it will return value zero.</p>
<p>These are the steps to follow in order to calculate the minimum, maximum and average movement from the file:</p>
<ol>
<li>Create a loop that reads each line of the file (except the first one which is just a heather with column names).</li>
<li>In each loop do the following:<ol>
<li>Split the line using the comma as a separator and save that in a variable called <code>ARRAY</code>.</li>
<li>Obtain the subject group, which is located in the 2nd column (position 1 of the array). Remember, Bash arrays start in the position 0 (not the position 1).</li>
<li>Obtain the subject gender, which is located in the 3rd column (position 2 of the array).</li>
<li>Obtain the subject movement, which is located in the 7th column (position 6 of the array).</li>
<li>Depending on the value of the group and gender, add movement to the corresponding array:<ul>
<li>If <code>group</code> equals <code>Control</code> and <code>gender</code> equals <code>M</code> (Male): Add the movement at the end of the array <code>CM</code>.<ul>
<li>If <code>CM</code> has zero values, the new item should be added to the position 0</li>
<li>If <code>CM</code> has one value, the new item should be added to the position 1 (because the existent item in the array will be in the position 0).</li>
<li>Every new item is added to the position that is equal to the current size of the array. The size of an array can be obtained with <code>${#array[@]}</code>.</li>
</ul>
</li>
<li>If <code>group</code> equals <code>Control</code> and <code>gender</code> equals <code>F</code> (Female): Add the movement at the end of the array <code>CF</code>.</li>
<li>If <code>group</code> equals <code>Patient</code> and <code>gender</code> equals <code>M</code>: Add the movement at the end of the array <code>PM</code>.</li>
<li>If <code>group</code> equals <code>Patient</code> and <code>gender</code> equals <code>F</code>: Add the movement at the end of the array <code>PF</code>.</li>
</ul>
</li>
</ol>
</li>
<li>Sort the four arrays with the previously learned command: <code>IFS=$'\n' sorted=($(sort &lt;&lt;&lt;"${array[*]}"))</code></li>
<li>Show the minimum, maximum and average value of each array:<ul>
<li>Use <code>printf</code> instead of <code>echo</code> in order to show only three decimals per number.</li>
<li>Minimum value: will be the first value in the sorted array.</li>
<li>Maximum value: will be the last value in the sorted array (in the position <code>SIZE_ARRAY–1</code>).</li>
<li>Average value: will equal to the sum of all values divided by the size of the array using <code>IFS='+' avg=$(echo "scale=1;(${array[*]})/${#array[@]}"|bc)</code>.</li>
</ul>
</li>
</ol>
<p>Now, lets see this in actual code:</p>
<p>First, loop through each line of the file, skipping the first row with the heathers using <code>if [ $((n++)) -gt 0 ]</code>:</p>
<pre><code class="language-bash">n=0
for line in $(cat infoFile.csv)
do
if [ $((n++)) -gt 0 ]
then
    IFS=',' read -a ARRAY &lt;&lt;&lt; &quot;${line}&quot;
    GRP=${ARRAY[1]}
    GEN=${ARRAY[2]}
    MOV=${ARRAY[6]}

    if [ &quot;$GRP&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;M&quot; ]
    then
        CM[${#CM[@]}]=${MOV}
    fi

    if [ &quot;$GRP&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;F&quot; ]
    then
        CF[${#CF[@]}]=${MOV}
    fi

    if [ &quot;$GRP&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;M&quot; ] &gt; then
        PM[${#PM[@]}]=${MOV}
    fi

    if [ &quot;$GRP&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;F&quot; ]
    then
        PF[${#PF[@]}]=${MOV}
    fi
fi
done
</code></pre>
<p>Then, get the minimum, maximum and average values of the CM array (Controls, Males):</p>
<pre><code class="language-bash">IFS=$'\n' sortedCM=($(sort &lt;&lt;&lt;&quot;${CM[*]}&quot;))
IFS='+' avg=$(echo &quot;scale=4;(${CM[*]})/${#CM[@]}&quot;|bc)
printf &quot;Male Controls:\nMin: %.3f\nMax: %.3f\nAve: %.3f\n&quot; ${sortedCM[0]} ${sortedCM[${#sortedCM[@]} -1]} $avg
</code></pre>
<p>Now get the minimum, maximum and average values of the CF array (Controls, Females):</p>
<pre><code class="language-bash">IFS=$'\n' sortedCF=($(sort &lt;&lt;&lt;&quot;${CF[*]}&quot;))
IFS='+' avg=$(echo &quot;scale=4;(${CF[*]})/${#CF[@]}&quot;|bc)
printf &quot;Male Controls:\nMin: %.3f\nMax: %.3f\nAve: %.3f\n&quot; ${sortedCF[0]} ${sortedCF[${#sortedCF[@]} -1]} $avg
</code></pre>
<p>Get the minimum, maximum and average values of the PM array (Patients, Males):</p>
<pre><code class="language-bash">IFS=$'\n' sortedPM=($(sort &lt;&lt;&lt;&quot;${PM[*]}&quot;))
IFS='+' avg=$(echo &quot;scale=4;(${PM[*]})/${#PM[@]}&quot;|bc)
printf &quot;Male Controls:\nMin: %.3f\nMax: %.3f\nAve: %.3f\n&quot; ${sortedPM[0]} ${sortedPM[${#sortedPM[@]} -1]} $avg
</code></pre>
<p>Get the minimum, maximum and average values of the PF array (Patients, Females):</p>
<pre><code class="language-bash">IFS=$'\n' sortedPF=($(sort &lt;&lt;&lt;&quot;${PF[*]}&quot;))
IFS='+' avg=$(echo &quot;scale=4;(${PF[*]})/${#PF[@]}&quot;|bc)
printf &quot;Male Controls:\nMin: %.3f\nMax: %.3f\nAve: %.3f\n&quot; ${sortedPF[0]}
</code></pre>
<p>The number of lines in the loop could be reduced by simplifying the <code>if</code> expressions. The code below is equivalent to loop above, but uses less lines. In the chapter of <a href="../condition_test/">Condition testing</a> I explain in detail how to simplify <code>if</code> expressions:</p>
<pre><code class="language-bash">n=0
for line in $(cat infoFile.csv)
do
if [ $((n++)) -gt 0 ]
then
    IFS=',' read -a ARRAY &lt;&lt;&lt; &quot;${line}&quot;
    GRP=${ARRAY[1]}
    GEN=${ARRAY[2]}
    MOV=${ARRAY[6]}
    [ &quot;$GRP&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;M&quot; ] &amp;&amp; CM[${#CM[@]}]=${MOV}
    [ &quot;$GRP&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;F&quot; ] &amp;&amp; CF[${#CF[@]}]=${MOV}
    [ &quot;$GRP&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;M&quot; ] &amp;&amp; PM[${#PM[@]}]=${MOV}
    [ &quot;$GRP&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;$GEN&quot; == &quot;F&quot; ] &amp;&amp; PF[${#PF[@]}]=${MOV}
fi
done
</code></pre>
<p>You could reduce even more the number of lines in the code of the loop:</p>
<pre><code class="language-bash">n=0
for line in $(cat infoFile.csv)
do
if [ $((n++)) -gt 0 ]
then
    IFS=',' read -a ARRAY &lt;&lt;&lt; &quot;${line}&quot;
    [ &quot;${ARRAY[1]}&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;${ARRAY[2]}&quot; == &quot;M&quot; ] &amp;&amp; CM[${#CM[@]}]=${ARRAY[6]}
    [ &quot;${ARRAY[1]}&quot; == &quot;Control&quot; ] &amp;&amp; [ &quot;${ARRAY[2]}&quot; == &quot;F&quot; ] &amp;&amp; CF[${#CF[@]}]=${ARRAY[6]}
    [ &quot;${ARRAY[1]}&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;${ARRAY[2]}&quot; == &quot;M&quot; ] &amp;&amp; PM[${#PM[@]}]=${ARRAY[6]}
    [ &quot;${ARRAY[1]}&quot; == &quot;Patient&quot; ] &amp;&amp; [ &quot;${ARRAY[2]}&quot; == &quot;F&quot; ] &amp;&amp; PF[${#PF[@]}]=${ARRAY[6]}
fi
done
</code></pre>
<h3 id="dealing-with-spaces">Dealing with spaces</h3>
<p>In the previous example we read line by line a file using a <code>for</code> loop and the <code>cat</code> utility. This works most of the times. However, if you try to read this way a file in which one or more of the lines contain a space, Bash will read each word separated by a space as a separate line.</p>
<p>For example, if file <code>test.txt</code> has the following content:</p>
<pre><code class="language-txt">a b
c d
e f
g h
i j
</code></pre>
<p>When you try to read each line using a file, this is the result you will get:</p>
<pre><code class="language-bash">$ for line in $(cat test.txt)
&gt; do
&gt; echo $((i++)) $line
&gt; done
0 a
1 b
2 c
3 d
4 e
5 f
6 g
7 h
8 i
9 j
</code></pre>
<p>To fix this problem you have to tell Bash that newline (<code>\n</code>) is the only separator. You do this by declaring the system variable <code>IFS=$'\n'</code>.</p>
<pre><code class="language-bash">$ IFS=$'\n'
$ for line in $(cat test.txt)
&gt; do
&gt; echo $((i++)) $line
&gt; done
0 a b
1 c d
2 e f
3 g h
4 i j
</code></pre>
<h3 id="loading-into-an-array">Loading into an array</h3>
<pre><code class="language-bash">$ ARRAY=($(cat test.txt))
$ echo ${ARRAY[0]}
a b
$ echo ${ARRAY[1]}
c d
$ echo ${ARRAY[2]}
e f
$ echo ${ARRAY[3]}
g h
$ echo ${ARRAY[4]}
i j
</code></pre>
<h2 id="the-read-command">The <code>read</code> command</h2>
<p>So far, we have learned that using the <code>for</code> loop and the <code>cat</code> utility you can read each line of a file and separate it into different fields using a separator. However, csv files can become very difficult to separate into fields if some of them contain a comma (the same character that is being used as a separator), a space, or both.</p>
<p>Example: Obtain the last field of <code>line</code> using the concepts learned before.</p>
<pre><code class="language-bash">$ line=&quot;SUBJ20&quot;,&quot; Age 22-30&quot;,&quot;VISIT1&quot;,&quot;1&quot;,&quot;DIAGN: Major Depressive Disorder, Single Episode, In Full Remission&quot;
$ IFS=',' read -a ARRAY &gt;&gt;&gt; &quot;$line&quot;
$ echo &quot;The last fifth of line is: &quot;${ARRAY[4]}
The fifth field of line is: DIAGN: Major Depressive Disorder
</code></pre>
<p>However, this is not the correct result. The fifth field of <code>line</code> is <code>"DIAGN: Major Depressive Disorder, Single Episode, In Full Remission"</code>. But because we are using a comma as a separator, Bash is separating this field into separate columns. To solve this problem, you can read from the file descriptor and save each field in a separate variable using <code>read</code>. With <code>read</code> if one of the columns contains a comma, but is surrounded by quotation marks, it will read the text inside the quotation marks as a single field.</p>
<p>Suppose that you have a file called <code>example.csv</code> with the following content:</p>
<pre><code class="language-txt">&quot;SUBJ1&quot;,&quot;Age 22-30&quot;,&quot;VISIT1&quot;,&quot;DIAGN: Major Depressive Disorder, Single Episode&quot;
&quot;SUBJ2&quot;,&quot;Age 22-30&quot;,&quot;VISIT1&quot;,&quot;DIAGN: Bipolar, Schizophrenia&quot;
&quot;SUBJ3&quot;,&quot;Age 22-30&quot;,&quot;VISIT1&quot;,&quot;DIAGN: Major Depressive Disorder&quot;
&quot;SUBJ4&quot;,&quot;Age 22-30&quot;,&quot;VISIT1&quot;,&quot;DIAGN: Autism, Dyslexia, ADHD&quot;
</code></pre>
<p>You want to read each line of the file and save the first and last fields into a new file called <code>result.csv</code>. You would accomplish that with the following code:</p>
<p>Assign the file descriptor 3 (or any integer number) to example.csv:</p>
<pre><code class="language-bash">exec 3&lt; example.csv
</code></pre>
<p>Obtain the number of lines in the input file:</p>
<pre><code class="language-bash">$ N=$(cat example.csv | wc -l)
$ echo $N
4
</code></pre>
<p>Iterate through all the lines of the file:</p>
<pre><code class="language-bash">$ i=0
$ while [ $((i++)) -lt $N ]
&gt; do
&gt; IFS=',' read -u 3 f1 f2 f3 f4 # Save each field in a different variable. Variable f1 will contain the 1st field, variable f2 the second field, etc.
&gt; echo &quot;$f1,$f4&quot; &gt;&gt; result.csv # Write the value of the first and last fields into the output file.
&gt; done
</code></pre>
<p>You <strong>must</strong> close the file descriptor using the following command (replace number 3 by the corresponding file descriptor):</p>
<pre><code class="language-bash">exec 3&lt;&amp;-
</code></pre>
<p>Finally, read the content of the output file</p>
<pre><code class="language-bash">$ cat result.csv
&quot;SUBJ1&quot;,&quot;DIAGN: Major Depressive Disorder, Single Episode&quot;
&quot;SUBJ2&quot;,&quot;DIAGN: Bipolar, Schizophrenia&quot;
&quot;SUBJ3&quot;,&quot;DIAGN: Major Depressive Disorder&quot;
&quot;SUBJ4&quot;,&quot;DIAGN: Autism, Dyslexia, ADHD&quot;
</code></pre>
<p>In the following example we are going to read the same csv file from above called <code>example.csv</code>. The file has four columns. We are going to use the <code>while</code> loop to iterate through each line of the file and save the fields in variables <code>f1</code>, <code>f2</code>, <code>f3</code>, <code>f4</code>. Before starting to iterate, we have to tell Bash that comma will be the separator in each line with <code>IFS=','</code>.</p>
<pre><code class="language-bash">$ IFS=','
$ i=1
$ while read f1 f2 f3 f4
&gt; do
&gt; echo &quot;Line $((i++)):&quot;
&gt; echo &quot;Field 1: $f1&quot;
&gt; echo &quot;Field 2: $f2&quot;
&gt; echo &quot;Field 3: $f3&quot;
&gt; echo &quot;Field 4: $f4&quot;
&gt; done &lt; example.csv
Line 1:
Field 1: &quot;SUBJ1&quot;
Field 2: &quot;Age 22-30&quot;
Field 3: &quot;VISIT1&quot;
Field 4: &quot;DIAGN: Major Depressive Disorder, Single Episode&quot;
Line 2:
Field 1: &quot;SUBJ2&quot;
Field 2: &quot;Age 22-30&quot;
Field 3: &quot;VISIT1&quot;
Field 4: &quot;DIAGN: Bipolar, Schizophrenia&quot;
Line 3:
Field 1: &quot;SUBJ3&quot;
Field 2: &quot;Age 22-30&quot;
Field 3: &quot;VISIT1&quot;
Field 4: &quot;DIAGN: Major Depressive Disorder&quot;
Line 4:
Field 1: &quot;SUBJ4&quot;
Field 2: &quot;Age 22-30&quot;
Field 3: &quot;VISIT1&quot;
Field 4: &quot;DIAGN: Autism, Dyslexia, ADHD&quot;
</code></pre>
<h2 id="awk"><code>awk</code></h2>
<p><code>awk</code> is a Bash command that scans files and process their content using patterns. It reads each line of a file or a group of files searching for the specified pattern and each time that it finds the pattern, performs an associated action. This tool can extract specific lines or columns from files, merge files, search the content of one file in the other, etc.</p>
<p>When reading each line of the specified files, <code>awk</code> will separate it into fields (columns) using the blank space as a separator. If your file uses a different separator (i.e. a comma), you must specify your separator using the <code>-F</code> flag (see syntax below). The different fields will be denoted <code>$1</code>, <code>$2</code>, <code>$3</code>... etc. <code>$0</code> will refer to the entire line. If the field separator (<code>FS</code>) is null, each line will be split into one field per character.</p>
<p>See the <a href="#examples-awk-and-grep">examples section</a> for a better understanding of this command.</p>
<p>Syntax: <code>awk [ -F fs ] [ -v var=value ] [ 'pattern {action}' ] [ files ] | [ other functions ]</code></p>
<table>
<thead>
<tr>
<th>Command Section</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-F fs</code> (optional)</td>
<td>Defines the input field separator to be the regular expression <code>fs</code>. Use this flag when the columns of your file use a separator other than a space.</td>
</tr>
<tr>
<td><code>-v var=variableName</code> (optional)</td>
<td>When the value that is being search is stored in a variable, you should use this flag. See below for examples on how to use this flag.</td>
</tr>
<tr>
<td><code>files</code></td>
<td>List of files to be searched.</td>
</tr>
<tr>
<td>other functions (optional)</td>
<td>You can apply to the output of <code>awk</code> other functions such as <code>head</code>, <code>tail</code>, <code>paste</code>, <code>grep</code>, etc.</td>
</tr>
</tbody>
</table>
<h2 id="grep"><code>grep</code></h2>
<p><code>grep</code> searches a given pattern or text in a file or list of files. <code>grep</code> is able to find simple patterns and basic regular expressions, <code>egrep</code> can perform search of extended regular expressions. <code>fgrep</code> is quicker than both tools, but can only handle fixed patterns. <code>zgrep</code>, <code>zegrep</code>, and <code>zfgrep</code> act like <code>grep</code>, <code>egrep</code>, and <code>fgrep</code>, respectively, but accept compressed files as input.</p>
<p>See the <a href="#examples-awk-and-grep">examples section</a> for a better understanding of this command.</p>
<p>Syntax: <code>grep [flag] [pattern] [file(s)]</code></p>
<table>
<thead>
<tr>
<th><code>grep</code> Format</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>grep my_string files</code></td>
<td>Search the list of files for lines that <em>contain</em> <code>my_string</code>.</td>
</tr>
<tr>
<td><code>grep '^my_expression' files</code></td>
<td>Search for any lines that <em>start with</em> <code>my_expression</code> in the list of files. If <code>my_expression</code> contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. <code>grep '^string' file.txt</code> will search for any lines in <code>file.txt</code> that start with string.</td>
</tr>
<tr>
<td><code>grep 'my_expression$' files</code></td>
<td>Search for any lines that <em>end with</em> <code>my_expression</code> in the list of files. If <code>my_expression</code> contains a back slash, the special meaning of the next special character is turned off. If expression contains a dot that is not preceded by a black slash, it will match a single character of any value in the position of the dot. <code>grep 'string$' file.txt</code> matches any lines in <code>file.txt</code> that end with <code>string</code>. <code>grep '^string$' file.txt</code> matches any lines in <code>file.txt</code> that start and end with <code>string</code>.</td>
</tr>
<tr>
<td><code>grep '[characters]' files</code></td>
<td>Search for any lines that <em>contain any of the characters</em> enclosed between the brackets. Use a hyphen for a range of values. <code>grep '[abcde]' file.txt</code> matches any lines in <code>file.txt</code> that contain <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> or <code>e</code>. <code>grep '[Ss]tring' file.txt</code> matches any lines in <code>file.txt</code> that contain the words string or String. <code>grep 'B[ai][dt]' file.txt</code> matches any lines in <code>file.txt</code> that contain the words <code>Bad</code>, <code>Bat</code>, <code>Bid</code> or <code>Bit</code> (the second character can be <code>a</code> or <code>i</code> and the third character <code>d</code> or <code>t</code>). <code>grep '[0-9][0-9]' file.txt</code> matches any lines in <code>file.txt</code> that contain a pair of numeric digits. <code>grep '[a-zA-Z]' file.txt</code> matches any lines in <code>file.txt</code> with at least one letter. <code>grep '^$' file.txt</code> matches any empty lines.</td>
</tr>
<tr>
<td><code>grep '[^characters]' files</code></td>
<td>Search for any lines that <em>don't contain</em> any of the characters enclosed between he brackets. Use a hyphen for a range of values. <code>grep '[^a-zA-Z0-9]' file.txt</code> matches any lines in <code>file.txt</code> that don't contain any letter or number (any lines that contain only special characters).</td>
</tr>
<tr>
<td><code>grep 'character*' files</code></td>
<td>The character preceding the asterisk is optional when matching lines. <code>grep '"*smug"*' file.txt</code> matches any lines in <code>file.txt</code> that contain <code>smug</code> or <code>"smug"</code> (with or without the quotes that precede the asterisks).</td>
</tr>
<tr>
<td><code>grep 'my_expression\{n\}' files</code></td>
<td>Match exactly <code>n</code> occurrences of <code>my_expression</code>. <code>grep '[0-9]\{3\}-[0-9]\{4\}' file.txt</code> matches any lines in <code>file.txt</code> that contain three digits, followed by a line and four digits.</td>
</tr>
<tr>
<td><code>grep 'expression \{n,\}' files</code></td>
<td>Match <code>n</code> or more occurrences of expression. <code>grep '[0-9]\{3,\}' file.txt</code> matches any lines in <code>file.txt</code> that contain three or more digits.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-A num</code></td>
<td>Print <code>num</code> lines of trailing context after each match.</td>
</tr>
<tr>
<td><code>-B num</code></td>
<td>Print <code>num</code> lines of leading context before each match.</td>
</tr>
<tr>
<td><code>-C num</code></td>
<td>Print <code>num</code> lines of leading and trailing context surrounding each match. If <code>num</code> is not specified, <code>num=2</code>.</td>
</tr>
<tr>
<td><code>-c</code></td>
<td>Print the number of matched lines per file instead of the actual lines.</td>
</tr>
<tr>
<td><code>--color=when</code></td>
<td>Mark up the matching text with the expression stored in the <code>GREP_COLOR</code> environment variable. The possible values of <code>when</code> can be: <code>never</code>, <code>always</code> or <code>auto</code>.</td>
</tr>
<tr>
<td><code>-d action</code></td>
<td>Specify the demanded action for directories. The possible values of action are: <code>read</code> (default), which means that the directories are read in the same manner as normal files; <code>skip</code> to silently ignore the directories, and <code>recourse</code> to read them recursively, which has the same effect as the <code>-R</code> and <code>-r</code> option.</td>
</tr>
<tr>
<td><code>-e pattern</code></td>
<td>To search for more than one pattern/expression, add the flag <code>-e</code> in front of each pattern/expression.</td>
</tr>
<tr>
<td><code>--exclude</code></td>
<td>If specified, it excludes files matching the given filename pattern from the search. Note that <code>--exclude</code> patterns take priority over <code>--include</code> patterns. Patterns are matched to the full path specified, not only to the filename component.</td>
</tr>
<tr>
<td><code>--exclude-dir filename_pattern</code></td>
<td>If <code>-R</code> is specified, it excludes directories matching the given <code>filename_pattern</code> from the search.</td>
</tr>
<tr>
<td><code>-f file</code></td>
<td>Read one or more newline separated patterns from <code>file</code>. Empty pattern lines match every input line. Newlines are not considered part of a pattern. If <code>file</code> is empty, nothing is matched.</td>
</tr>
<tr>
<td><code>-h</code></td>
<td>Omit the filename headers with output lines.</td>
</tr>
<tr>
<td><code>--help</code></td>
<td>Print a brief help message.</td>
</tr>
<tr>
<td><code>--include</code></td>
<td>If specified, only files matching the given filename pattern are searched. Note that <code>--exclude</code> patterns take priority over <code>--include</code> patterns. Patterns are matched to the full path specified, not only to the filename component.</td>
</tr>
<tr>
<td><code>--include-dir filename_pattern</code></td>
<td>If <code>-R</code> is specified, only directories matching the given <code>filename_pattern</code> are searched. Note that <code>--exclude-dir</code> patterns take priority over <code>--include-dir</code> patterns.</td>
</tr>
<tr>
<td><code>-L</code></td>
<td>Only the names of files not containing selected lines are listed.</td>
</tr>
<tr>
<td><code>-l</code></td>
<td>Only the names of files containing selected lines are listed.</td>
</tr>
<tr>
<td><code>-m num</code></td>
<td>Stop reading the file after num matches.</td>
</tr>
<tr>
<td><code>-n</code></td>
<td>Each output line is preceded by its relative line number in the file, starting at line 1. The line number counter is reset for each file processed. This option is ignored if <code>-c</code>, <code>-L</code>, <code>-l</code>, or <code>-q</code> is specified.</td>
</tr>
<tr>
<td><code>--null</code></td>
<td>Prints a zero-byte after the file name.</td>
</tr>
<tr>
<td><code>-O</code></td>
<td>If <code>-R</code> is specified, follow symbolic links only if they were explicitly listed on the command line. The default is not to follow symbolic links.</td>
</tr>
<tr>
<td><code>-o</code></td>
<td>Prints only the matching part of the lines.</td>
</tr>
<tr>
<td><code>-q</code></td>
<td>Suppress normal output.</td>
</tr>
<tr>
<td><code>-R</code> or <code>-r</code></td>
<td>Recursively search subdirectories listed.</td>
</tr>
<tr>
<td><code>-S</code></td>
<td>If <code>-R</code> is specified, all symbolic links are followed. The default is not to follow symbolic links.</td>
</tr>
<tr>
<td><code>-s</code></td>
<td>Suppress error messages from nonexistent or unreadable files.</td>
</tr>
<tr>
<td><code>-V</code></td>
<td>Display version information and exit.</td>
</tr>
<tr>
<td><code>-v</code></td>
<td>Selected lines are those not matching any of the specified patterns.</td>
</tr>
<tr>
<td><code>-w</code></td>
<td>The expression is searched for as a whole word.</td>
</tr>
<tr>
<td><code>-x</code></td>
<td>Show only the cases where the whole line equals the expression.</td>
</tr>
<tr>
<td><code>-Z</code> or <code>-z</code></td>
<td>Accepts compressed input files.</td>
</tr>
<tr>
<td><code>--line-buffered</code></td>
<td>Force output to be line buffered. By default, output is line buffered when standard output is a terminal and block buffered otherwise.</td>
</tr>
</tbody>
</table>
<h2 id="examples-awk-and-grep">Examples: <code>awk</code> and <code>grep</code></h2>
<p>The following examples will show how to read and manipulate files using different command line tools. Each example will read one or more of the following files. <code>file1.csv</code> and <code>file3.csv</code> use comma as the separator between columns. On the other hand, <code>file2.txt</code> and file <code>file4.txt</code> use a space as the separator between columns.</p>
<p>Content of <code>file1.csv</code>:</p>
<pre><code class="language-txt">&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11137879&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11144410&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110455&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11135291&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11153927&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11177579&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11177806&quot;,&quot;Group1&quot;,&quot;MD&quot;,&quot;&quot;
&quot;B11157958&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110690&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11152799&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11154358&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110925&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11135291&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
&quot;B11135072&quot;,&quot;MISSING&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11137879&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110603&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110927&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11147712&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33191224&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11131290&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11157974&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33191224&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11141503&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;C11137159&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p>Content of <code>file2.txt</code>:</p>
<pre><code class="language-txt">&quot;AnonymizedID&quot; &quot;SubjectGroup&quot; &quot;TEST1&quot; &quot;TEST2&quot;
&quot;B11130912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;555&quot;
&quot;B11154534&quot; &quot;Group1&quot; &quot;456&quot; &quot;456&quot;
&quot;B11144100&quot; &quot;Group1&quot; &quot;450&quot; &quot;886&quot;
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;456&quot;
&quot;B12226566&quot; &quot;Group2b&quot; &quot;450&quot; &quot;MissingData&quot;
&quot;B11134987&quot; &quot;Group1&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11144345&quot; &quot;Group1&quot; &quot;900&quot; &quot;776&quot;
&quot;C11137159&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
&quot;B11156453&quot; &quot;Group4&quot; &quot;456&quot; &quot;2&quot;
&quot;B11110676&quot; &quot;Group1&quot; &quot;900&quot; &quot;10&quot;
&quot;C11138929&quot; &quot;Group2b&quot; &quot;2&quot; &quot;MissingData&quot;
&quot;B11154532&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
&quot;B11137120&quot; &quot;Group2b&quot; &quot;450&quot; &quot;456&quot;
&quot;B33191224&quot; &quot;Group2b&quot; &quot;450&quot; &quot;776&quot;
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
&quot;C11138999&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11131605&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
&quot;B11137784&quot; &quot;Group1&quot; &quot;900&quot; &quot;436&quot;
&quot;B11156098&quot; &quot;Group1&quot; &quot;500&quot; &quot;886&quot;
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;
&quot;B11135292&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
&quot;C11138912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11150911&quot; &quot;Group2b&quot; &quot;900&quot; &quot;117&quot;
&quot;B11152577&quot; &quot;Group1&quot; &quot;900&quot; &quot;756&quot;
&quot;B11156098&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<p>Content of <code>file3.csv</code>:</p>
<pre><code class="language-txt">Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content of <code>file4.txt</code>:</p>
<pre><code class="language-txt">AnonymizedID SubjectGroup AGE
B11108326 Group1 59
B11108399 Group1 23
B11110893 Group1 28
B11119909 Group2 61
D11144030 Group3 11
D11144030 Group3 13
B11119903 Group2 84
C11131039 Group2 67
C11133100 Group1 23
C11135566 Group2 72
C11137159 Group3 11
C11137159 Group3 12
C11137167 Group3 14
C11137167 Group3 16
C11137439 Group3 15
C11137439 Group3 79
C11137443 Group3 15
C11137544 Group1 22
C11137123 Group2 68
C11138150 Group1 44
C11138152 Group1 10
C11138797 Group1 24
C11138184 Group1 57
C11138122 Group1 23
C11138122 MISSING 25
C11138192 Group1 45
B12226507 Group1 26
B12226546 Group1 55
</code></pre>
<h3 id="reading-specific-columns">Reading specific columns</h3>
<p><strong>Example 1:</strong> Print the first column of each file.</p>
<p>In order to print the first column of these files, we will use <code>awk</code>. As it was shown before, this command has some optional flags followed by an action statement, and then the list of files. In this case, the action statement is <code>'{print $1}'</code>, because we want to print only the first column (<code>$1</code>). </p>
<p><code>file2.txt</code> and <code>file4.txt</code> use a space as a column separator (which is the separator for default). So, to access the first column of these files we don't need the <code>-F</code> flag. However, <code>file1.csv</code> and <code>file3.csv</code> use a comma as a separator. So, in order for <code>awk</code> to distinguish the different columns, we have to use the <code>-F</code> flag with a comma (<code>-F','</code>).</p>
<p>Space-separated files:</p>
<pre><code class="language-bash">$ awk '{print $1}' file2.txt
&quot;AnonymizedID&quot;
&quot;B11130912&quot;
&quot;B11137244&quot;
&quot;B11154534&quot;
&quot;B11144100&quot;
&quot;B11137244&quot;
&quot;B12226566&quot;
&quot;B11134987&quot;
&quot;B11144345&quot;
&quot;C11137159&quot;
&quot;B11156453&quot;
&quot;B11110676&quot;
&quot;C11138929&quot;
&quot;B11154532&quot;
&quot;B11155267&quot;
&quot;B11137120&quot;
&quot;B33191224&quot;
&quot;B11155267&quot;
&quot;C11138999&quot;
&quot;B11131605&quot;
&quot;B11137784&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;
&quot;B11135292&quot;
&quot;C11138912&quot;
&quot;B11150911&quot;
&quot;B11152577&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;

$ awk '{print $1}' file4.txt
AnonymizedID
B11108326
B11110893
B11119909
D11144030
D11144030
B11119903
C11131039
C11133100
C11135566
C11137159
C11137159
C11137167
C11137167
C11137439
C11137439
C11137443
C11137544
C11137123
C11138150
C11138152
C11138797
C11138184
C11138122
C11138122
C11138192
B12226507
B12226546
</code></pre>
<p>Comma-separated files:</p>
<pre><code class="language-bash">$ awk -F',' '{print $1}' file1.csv
&quot;Anonymized ID&quot;
&quot;B33199522&quot;
&quot;B33199603&quot;
&quot;B11137879&quot;
&quot;B11144410&quot;
&quot;B11110455&quot;
&quot;B11135291&quot;
&quot;B11153927&quot;
&quot;B11177579&quot;
&quot;B11177806&quot;
&quot;B11157958&quot;
&quot;B11110690&quot;
&quot;B11152799&quot;
&quot;B11154358&quot;
&quot;B11110925&quot;
&quot;B11135291&quot;
&quot;B11135072&quot;
&quot;B33199603&quot;
&quot;B11137879&quot;
&quot;B11131605&quot;
&quot;B11110927&quot;
&quot;B11147712&quot;
&quot;B33191224&quot;
&quot;B11131290&quot;
&quot;B11157974&quot;
&quot;B33191224&quot;
&quot;B11141503&quot;
&quot;C11137159&quot;
&quot;B33199522&quot;

$ awk -F',' '{print $1}' file3.csv
AnonymizedID
C11138122
C11138192
B12226507
B12226546
C11138122
C11138184
C11138797
C11138152
C11138150
C11137167
C11137159
C11137167
C11137159
C11131039
C11135566
B11119903
C11137544
C11137443
C11137123
C11137439
C11137439
C11133100
D11144030
B11108399
B11108326
B11119909
B11110893
</code></pre>
<p>To precede each line by the line number, add <code>NR</code> after <code>print</code> in the <code>awk</code> command to indicate that you want to print the Number Row before the column 1 (<code>$1</code>):</p>
<p>Space-separated files:</p>
<pre><code class="language-bash">$ awk '{print NR,$1}' file2.txt
1 &quot;AnonymizedID&quot;
2 &quot;B11130912&quot;
3 &quot;B11137244&quot;
4 &quot;B11154534&quot;
5 &quot;B11144100&quot;
6 &quot;B11137244&quot;
7 &quot;B12226566&quot;
8 &quot;B11134987&quot;
9 &quot;B11144345&quot;
10 &quot;C11137159&quot;
11 &quot;B11156453&quot;
12 &quot;B11110676&quot;
13 &quot;C11138929&quot;
14 &quot;B11154532&quot;
15 &quot;B11155267&quot;
16 &quot;B11137120&quot;
17 &quot;B33191224&quot;
18 &quot;B11155267&quot;
19 &quot;C11138999&quot;
20 &quot;B11131605&quot;
21 &quot;B11137784&quot;
22 &quot;B11156098&quot;
23 &quot;B11133232&quot;
24 &quot;B11135292&quot;
25 &quot;C11138912&quot;
26 &quot;B11150911&quot;
27 &quot;B11152577&quot;
28 &quot;B11156098&quot;
29 &quot;B11133232&quot;

$ awk '{print NR, $1}' file4.txt
1 AnonymizedID
2 B11108326
3 B11110893
4 B11119909
5 D11144030
6 D11144030
7 B11119903
8 C11131039
9 C11133100
10 C11135566
11 C11137159
12 C11137159
13 C11137167
14 C11137167
15 C11137439
16 C11137439
17 C11137443
18 C11137544
19 C11137123
20 C11138150
21 C11138152
22 C11138797
23 C11138184
24 C11138122
25 C11138122
26 C11138192
27 B12226507
28 B12226546
</code></pre>
<p>Comma-separated files:</p>
<pre><code class="language-bash">$ awk -F',' '{print NR, $1}' file1.csv
1 &quot;Anonymized ID&quot;
2 &quot;B33199522&quot;
3 &quot;B33199603&quot;
4 &quot;B11137879&quot;
5 &quot;B11144410&quot;
6 &quot;B11110455&quot;
7 &quot;B11135291&quot;
8 &quot;B11153927&quot;
9 &quot;B11177579&quot;
10 &quot;B11177806&quot;
11 &quot;B11157958&quot;
12 &quot;B11110690&quot;
13 &quot;B11152799&quot;
14 &quot;B11154358&quot;
15 &quot;B11110925&quot;
16 &quot;B11135291&quot;
17 &quot;B11135072&quot;
18 &quot;B33199603&quot;
19 &quot;B11137879&quot;
20 &quot;B11131605&quot;
21 &quot;B11110927&quot;
22 &quot;B11147712&quot;
23 &quot;B33191224&quot;
24 &quot;B11131290&quot;
25 &quot;B11157974&quot;
26 &quot;B33191224&quot;
27 &quot;B11141503&quot;
28 &quot;C11137159&quot;
29 &quot;B33199522&quot;

$ awk -F',' '{print NR, $1}' file3.csv
1 Anonymized ID
2 C11138122
3 C11138192
4 B12226507
5 B12226546
6 C11138122
7 C11138184
8 C11138797
9 C11138152
10 C11138150
11 C11137167
12 C11137159
13 C11137167
14 C11137159
15 C11131039
16 C11135566
17 B11119903
18 C11137544
19 C11137443
20 C11137123
21 C11137439
22 C11137439
23 C11133100
24 D11144030
25 B11108399
26 B11108326
27 B11119909
28 B11110893
</code></pre>
<p><strong>Example 2:</strong> Print the first column of <code>file1.csv</code> and <code>file2.txt</code> <strong>in reverse order</strong>.</p>
<p>In order to print starting with the last line and ending with the first line, you can use the command <code>tail</code> with the flag <code>-r</code> (for reverse) after <code>awk</code>. Bash will first execute the <code>awk</code> command, which is written before the pipe (<code>|</code>), and then it will run <code>tail</code>, which inverts the order of the previous output. Remember that for <code>file1.csv</code> you need to use <code>-F','</code> to indicate that the columns are separated by commas and not spaces.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print $1}' file2.txt | tail -r
&quot;B11133232&quot;
&quot;B11156098&quot;
&quot;B11152577&quot;
&quot;B11150911&quot;
&quot;C11138912&quot;
&quot;B11135292&quot;
&quot;B11133232&quot;
&quot;B11156098&quot;
&quot;B11137784&quot;
&quot;B11131605&quot;
&quot;C11138999&quot;
&quot;B11155267&quot;
&quot;B33191224&quot;
&quot;B11137120&quot;
&quot;B11155267&quot;
&quot;B11154532&quot;
&quot;C11138929&quot;
&quot;B11110676&quot;
&quot;B11156453&quot;
&quot;C11137159&quot;
&quot;B11144345&quot;
&quot;B11134987&quot;
&quot;B12226566&quot;
&quot;B11137244&quot;
&quot;B11144100&quot;
&quot;B11154534&quot;
&quot;B11137244&quot;
&quot;B11130912&quot;
&quot;AnonymizedID&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '{print $1}' file1.csv | tail -r
&quot;B33199522&quot;
&quot;C11137159&quot;
&quot;B11141503&quot;
&quot;B33191224&quot;
&quot;B11157974&quot;
&quot;B11131290&quot;
&quot;B33191224&quot;
&quot;B11147712&quot;
&quot;B11110927&quot;
&quot;B11110603&quot;
&quot;B11137879&quot;
&quot;B33199603&quot;
&quot;B11135072&quot;
&quot;B11135291&quot;
&quot;B11110925&quot;
&quot;B11154358&quot;
&quot;B11152799&quot;
&quot;B11110690&quot;
&quot;B11157958&quot;
&quot;B11177806&quot;
&quot;B11177579&quot;
&quot;B11153927&quot;
&quot;B11135291&quot;
&quot;B11110455&quot;
&quot;B11144410&quot;
&quot;B11137879&quot;
&quot;B33199603&quot;
&quot;B33199522&quot;
&quot;Anonymized ID&quot;
</code></pre>
<p>The same as in example 1, to precede each line by the line number, add <code>NR</code> after <code>print</code> in the <code>awk</code> command to indicate that you want to print the Number Row before the column 1 (<code>$1</code>):</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print NR, $1}' file2.txt | tail -r
29 &quot;B11133232&quot;
28 &quot;B11156098&quot;
27 &quot;B11152577&quot;
26 &quot;B11150911&quot;
25 &quot;C11138912&quot;
24 &quot;B11135292&quot;
23 &quot;B11133232&quot;
22 &quot;B11156098&quot;
21 &quot;B11137784&quot;
20 &quot;B11131605&quot;
19 &quot;C11138999&quot;
18 &quot;B11155267&quot;
17 &quot;B33191224&quot;
16 &quot;B11137120&quot;
15 &quot;B11155267&quot;
14 &quot;B11154532&quot;
13 &quot;C11138929&quot;
12 &quot;B11110676&quot;
11 &quot;B11156453&quot;
10 &quot;C11137159&quot;
9 &quot;B11144345&quot;
8 &quot;B11134987&quot;
7 &quot;B12226566&quot;
6 &quot;B11137244&quot;
5 &quot;B11144100&quot;
4 &quot;B11154534&quot;
3 &quot;B11137244&quot;
2 &quot;B11130912&quot;
1 &quot;AnonymizedID&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '{print NR, $1}' file1.csv | tail -r
29 &quot;B33199522&quot;
28 &quot;C11137159&quot;
27 &quot;B11141503&quot;
26 &quot;B33191224&quot;
25 &quot;B11157974&quot;
24 &quot;B11131290&quot;
23 &quot;B33191224&quot;
22 &quot;B11147712&quot;
21 &quot;B11110927&quot;
20 &quot;B11110603&quot;
19 &quot;B11137879&quot;
18 &quot;B33199603&quot;
17 &quot;B11135072&quot;
16 &quot;B11135291&quot;
15 &quot;B11110925&quot;
14 &quot;B11154358&quot;
13 &quot;B11152799&quot;
12 &quot;B11110690&quot;
11 &quot;B11157958&quot;
10 &quot;B11177806&quot;
9 &quot;B11177579&quot;
8 &quot;B11153927&quot;
7 &quot;B11135291&quot;
6 &quot;B11110455&quot;
5 &quot;B11144410&quot;
4 &quot;B11137879&quot;
3 &quot;B33199603&quot;
2 &quot;B33199522&quot;
1 &quot;Anonymized ID&quot;
</code></pre>
<p><strong>Example 3:</strong> Print the second and third columns of <code>file2.txt</code>.</p>
<p>In the previous examples we used the action statement <code>'{print $1}'</code> to print the first column. Since we now want to print the second and third columns instead of the first one, we replace <code>$1</code> by <code>$2,$3</code>. If you wanted to print columns 4 and 5 instead, you would simply use <code>$4,$5</code>, etc.</p>
<pre><code class="language-bash">$ awk '{print $2,$3}' file2.txt
&quot;SubjectGroup&quot; &quot;TEST1&quot;
&quot;Group2b&quot; &quot;900&quot;
&quot;Group1&quot; &quot;450&quot;
&quot;Group1&quot; &quot;456&quot;
&quot;Group1&quot; &quot;450&quot;
&quot;Group1&quot; &quot;450&quot;
&quot;Group2b&quot; &quot;450&quot;
&quot;Group1&quot; &quot;900&quot;
&quot;Group1&quot; &quot;900&quot;
&quot;Group3&quot; &quot;MissingData&quot;
&quot;Group4&quot; &quot;456&quot;
&quot;Group1&quot; &quot;900&quot;
&quot;Group2b&quot; &quot;2&quot;
&quot;Group1&quot; &quot;456&quot;
&quot;Group3&quot; &quot;900&quot;
&quot;Group2b&quot; &quot;450&quot;
&quot;Group2b&quot; &quot;450&quot;
&quot;Group3&quot; &quot;900&quot;
&quot;Group2b&quot; &quot;900&quot;
&quot;Group1&quot; &quot;456&quot;
&quot;Group1&quot; &quot;900&quot;
&quot;Group1&quot; &quot;500&quot;
&quot;Group1&quot; &quot;500&quot;
&quot;Group3&quot; &quot;MissingData&quot;
&quot;Group2b&quot; &quot;900&quot;
&quot;Group2b&quot; &quot;900&quot;
&quot;Group1&quot; &quot;900&quot;
&quot;Group1&quot; &quot;456&quot;
&quot;Group1&quot; &quot;456&quot;
</code></pre>
<p>To precede each line by the line number, add <code>NR</code> after <code>print</code> in the <code>awk</code> command to indicate that you want to print the Number Row before the column 1 (<code>$1</code>):</p>
<pre><code class="language-bash">$ awk '{print NR,$2,$3}' file2.txt
1 &quot;SubjectGroup&quot; &quot;TEST1&quot;
2 &quot;Group2b&quot; &quot;900&quot;
3 &quot;Group1&quot; &quot;450&quot;
4 &quot;Group1&quot; &quot;456&quot;
5 &quot;Group1&quot; &quot;450&quot;
6 &quot;Group1&quot; &quot;450&quot;
7 &quot;Group2b&quot; &quot;450&quot;
8 &quot;Group1&quot; &quot;900&quot;
9 &quot;Group1&quot; &quot;900&quot;
10 &quot;Group3&quot; &quot;MissingData&quot;
11 &quot;Group4&quot; &quot;456&quot;
12 &quot;Group1&quot; &quot;900&quot;
13 &quot;Group2b&quot; &quot;2&quot;
14 &quot;Group1&quot; &quot;456&quot;
15 &quot;Group3&quot; &quot;900&quot;
16 &quot;Group2b&quot; &quot;450&quot;
17 &quot;Group2b&quot; &quot;450&quot;
18 &quot;Group3&quot; &quot;900&quot;
19 &quot;Group2b&quot; &quot;900&quot;
20 &quot;Group1&quot; &quot;456&quot;
21 &quot;Group1&quot; &quot;900&quot;
22 &quot;Group1&quot; &quot;500&quot;
23 &quot;Group1&quot; &quot;500&quot;
24 &quot;Group3&quot; &quot;MissingData&quot;
25 &quot;Group2b&quot; &quot;900&quot;
26 &quot;Group2b&quot; &quot;900&quot;
27 &quot;Group1&quot; &quot;900&quot;
28 &quot;Group1&quot; &quot;456&quot;
29 &quot;Group1&quot; &quot;456&quot;
</code></pre>
<p><strong>Example 4:</strong> Print the second and third columns of <code>file1.csv</code> <strong>in reverse order</strong>.</p>
<p>In order to print the output in reverse order for <code>file1.csv</code>, use the <code>tail -r</code> command after the <code>awk</code>.</p>
<pre><code class="language-bash">$ awk -F',' '{print $2,$3}' file1.csv | tail -r
&quot;Group1&quot; &quot;0&quot;
&quot;Group3&quot; &quot;9&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;MISSING&quot; &quot;0&quot;
&quot;Group3&quot; &quot;9&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;Group1&quot; &quot;MD&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group2 b&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Group3&quot; &quot;0&quot;
&quot;Group1&quot; &quot;0&quot;
&quot;Subject Group&quot; &quot;HASCONDITION&quot;
</code></pre>
<p>To precede each line by the line number, add <code>NR</code> after <code>print</code> in the <code>awk</code> command to indicate that you want to print the Number Row before the column 1 (<code>$1</code>):</p>
<pre><code class="language-bash">$ awk -F',' '{print NR,$2,$3}' file1.csv | tail -r
29 &quot;Group1&quot; &quot;0&quot;
28 &quot;Group3&quot; &quot;9&quot;
27 &quot;Group3&quot; &quot;0&quot;
26 &quot;Group2 b&quot; &quot;0&quot;
25 &quot;Group1&quot; &quot;0&quot;
24 &quot;Group2 b&quot; &quot;0&quot;
23 &quot;Group2 b&quot; &quot;0&quot;
22 &quot;Group1&quot; &quot;0&quot;
21 &quot;Group1&quot; &quot;0&quot;
20 &quot;Group1&quot; &quot;0&quot;
19 &quot;Group1&quot; &quot;0&quot;
18 &quot;Group3&quot; &quot;0&quot;
17 &quot;MISSING&quot; &quot;0&quot;
16 &quot;Group3&quot; &quot;9&quot;
15 &quot;Group1&quot; &quot;0&quot;
14 &quot;Group1&quot; &quot;0&quot;
13 &quot;Group1&quot; &quot;0&quot;
12 &quot;Group3&quot; &quot;0&quot;
11 &quot;Group3&quot; &quot;0&quot;
10 &quot;Group1&quot; &quot;MD&quot;
9 &quot;Group2 b&quot; &quot;0&quot;
8 &quot;Group1&quot; &quot;0&quot;
7 &quot;Group3&quot; &quot;0&quot;
6 &quot;Group2 b&quot; &quot;0&quot;
5 &quot;Group2 b&quot; &quot;0&quot;
4 &quot;Group1&quot; &quot;0&quot;
3 &quot;Group3&quot; &quot;0&quot;
2 &quot;Group1&quot; &quot;0&quot;
1 &quot;Subject Group&quot; &quot;HASCONDITION&quot;
</code></pre>
<p><strong>Example 5:</strong> Print all the columns of <code>file1.csv</code> showing the lines <strong>in reverse order</strong>.</p>
<p>To print all the columns of a file using <code>awk</code>, use <code>$0</code> (instead of a column number). Or use the command <code>cat</code>.</p>
<p>Using <code>awk</code>: <code>awk -F',' '{print $0}' file1.csv | tail -r</code></p>
<p>Using <code>cat</code>: <code>cat file1.csv | tail -r</code></p>
<p><strong>Example 6:</strong> Print all the columns of <code>file1.csv</code> <strong>in reversed order</strong>, and save the re-ordered columns in a new file called <code>file1_reordered.csv</code>.</p>
<p>If you were going to print the columns one to three in normal order, you would use <code>'{print $1,$2,$3}'</code>. To print them in reverse order, you just reverse the order of the columns in <code>print</code>, like so: <code>'{print $3,$2,$1}'</code>. To save the output to a file instead of showing it in the terminal, use <code>&gt;&gt; file_name</code>, as explained in previous sections. Remember to use the <code>-F','</code> flag to indicate that the columns are separated by commas, and not the default space.</p>
<pre><code class="language-bash">awk -F',' '{print $3,$2,$1}' file1.csv &gt;&gt; file1_reordered.csv
</code></pre>
<p><strong>Example 7:</strong> Print the columns and lines of <code>file1.csv</code> in reverse order</p>
<p>Use the same command as before, adding <code>| tail -r</code> at the end to invert also the lines.</p>
<pre><code class="language-bash">awk -F',' '{print $3,$2,$1}' file1.csv | tail -r
</code></pre>
<p><strong>Example 8:</strong> Read the second column of <code>file1.csv</code> and save it into an array.</p>
<p>When saving a column of a file into an array, you must specify that the elements of the array are separated by new lines (<code>'\n'</code>). You do this using the command <code>IFS=$'\n'</code>.</p>
<p>The elements of the array will be saved in the variable <code>ARRAY</code>. Remember that to access the individual elements of <code>ARRAY</code> you use <code>${ARRAY[index]}</code>. With <code>index</code> starting at 0. So, to access the first element the command is <code>echo ${ARRAY[0]}</code>. To access the second element it is <code>echo ${ARRAY[1]}</code>, etc. Type <code>echo ${ARRAY[@]}</code> to view all the elements of the array.</p>
<p>Remember, the system variable <code>IFS</code> contains the separator that is being used to separate each field within the lines of a file. You can change the value of this variable at any time by using <code>IFS='character'</code>, where <code>character</code> is the one separating the fields.</p>
<pre><code class="language-bash">$ IFS=$'\n'
$ ARRAY=($(awk -F',' '{print $2}' file1.csv))
$ echo ${ARRAY[0]}
&quot;Subject Group&quot;
$ echo ${ARRAY[1]}
&quot;Group1&quot;
$ echo ${ARRAY[@]}
&quot;Subject Group&quot; &quot;Group1&quot; &quot;Group3&quot; &quot;Group1&quot; &quot;Group2 b&quot; &quot;Group2 b&quot; &quot;Group3&quot; &quot;Group1&quot; &quot;Group2 b&quot; &quot;Group1&quot; &quot;Group3&quot; &quot;Group3&quot; &quot;Group1&quot; &quot;Group1&quot; &quot;Group1&quot; &quot;Group3&quot; &quot;MISSING&quot; &quot;Group3&quot; &quot;Group1&quot; &quot;Group1&quot; &quot;Group1&quot; &quot;Group1&quot; &quot;Group2 b&quot; &quot;Group2 b&quot; &quot;Group1&quot; &quot;Group2 b&quot; &quot;Group3&quot; &quot;Group3&quot; &quot;Group1&quot;
$ echo ${#ARRAY[@]}
29
</code></pre>
<p><strong>Example 9:</strong> Print the first column of <code>file2.txt</code> followed by the first column of <code>file4.txt</code>.</p>
<p>To print a specific column for more than one file, you use the same command, adding the list of files you want to print after the first one. However, all the files in the list must use the same column separator. Since the column separator for this list of files is a space (the default), you don't need to use the <code>-F</code> flag.</p>
<pre><code class="language-bash">awk '{print $1}' file2.txt file4.txt
</code></pre>
<p><strong>Example 10:</strong> Print the first column of <code>file3.csv</code> followed by the first column of <code>file1.csv</code>.</p>
<p>Since the column separator for this list of files is a comma, you need to use the <code>-F','</code> flag.</p>
<pre><code class="language-bash">awk -F',' '{print $1}' file3.csv file1.csv
</code></pre>
<h3 id="sorting-columns">Sorting columns</h3>
<p><strong>Example 1:</strong> Print the first column of <code>file1.csv</code> and <code>file2.txt</code> in <strong>alphabetical order</strong>.</p>
<p>First, use <code>awk</code> to print the desired column. Then, use <code>sort</code> to sort it in alphabetical order.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print $1}' file2.txt | sort
&quot;AnonymizedID&quot;
&quot;B11110676&quot;
&quot;B11130912&quot;
&quot;B11131605&quot;
&quot;B11133232&quot;
&quot;B11133232&quot;
&quot;B11134987&quot;
&quot;B11135292&quot;
&quot;B11137120&quot;
&quot;B11137244&quot;
&quot;B11137244&quot;
&quot;B11137784&quot;
&quot;B11144100&quot;
&quot;B11144345&quot;
&quot;B11150911&quot;
&quot;B11152577&quot;
&quot;B11154532&quot;
&quot;B11154534&quot;
&quot;B11155267&quot;
&quot;B11155267&quot;
&quot;B11156098&quot;
&quot;B11156098&quot;
&quot;B11156453&quot;
&quot;B12226566&quot;
&quot;B33191224&quot;
&quot;C11137159&quot;
&quot;C11138912&quot;
&quot;C11138929&quot;
&quot;C11138999&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F ',' '{print $1}' file1.csv | sort
&quot;Anonymized ID&quot;
&quot;B11110455&quot;
&quot;B11110603&quot;
&quot;B11110690&quot;
&quot;B11110925&quot;
&quot;B11110927&quot;
&quot;B11131290&quot;
&quot;B11135072&quot;
&quot;B11135291&quot;
&quot;B11135291&quot;
&quot;B11137879&quot;
&quot;B11137879&quot;
&quot;B11141503&quot;
&quot;B11144410&quot;
&quot;B11147712&quot;
&quot;B11152799&quot;
&quot;B11153927&quot;
&quot;B11154358&quot;
&quot;B11157958&quot;
&quot;B11157974&quot;
&quot;B11177579&quot;
&quot;B11177806&quot;
&quot;B33191224&quot;
&quot;B33191224&quot;
&quot;B33199522&quot;
&quot;B33199522&quot;
&quot;B33199603&quot;
&quot;B33199603&quot;
&quot;C11137159&quot;
</code></pre>
<p><strong>Example2:</strong> Print the first column of <code>file1.csv</code> and <code>file2.txt</code> <strong>in alphabetical removing any duplicate values</strong>.</p>
<p>Use <code>awk</code> to print the desired column, followed by <code>sort | uniq</code> to sort and remove the duplicates on the result.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print $1}' file2.txt | sort | uniq
&quot;AnonymizedID&quot;
&quot;B11130912&quot;
&quot;B11137244&quot;
&quot;B11154534&quot;
&quot;B11144100&quot;
&quot;B11137244&quot;
&quot;B12226566&quot;
&quot;B11134987&quot;
&quot;B11144345&quot;
&quot;C11137159&quot;
&quot;B11156453&quot;
&quot;B11110676&quot;
&quot;C11138929&quot;
&quot;B11154532&quot;
&quot;B11155267&quot;
&quot;B11137120&quot;
&quot;B33191224&quot;
&quot;B11155267&quot;
&quot;C11138999&quot;
&quot;B11131605&quot;
&quot;B11137784&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;
&quot;B11135292&quot;
&quot;C11138912&quot;
&quot;B11150911&quot;
&quot;B11152577&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;
</code></pre>
<p>Comma-separated file</p>
<pre><code class="language-bash">$ awk -F ',' '{print $1}' file1.csv | sort | uniq
&quot;Anonymized ID&quot;
&quot;B33199522&quot;
&quot;B33199603&quot;
&quot;B11137879&quot;
&quot;B11144410&quot;
&quot;B11110455&quot;
&quot;B11135291&quot;
&quot;B11153927&quot;
&quot;B11177579&quot;
&quot;B11177806&quot;
&quot;B11157958&quot;
&quot;B11110690&quot;
&quot;B11152799&quot;
&quot;B11154358&quot;
&quot;B11110925&quot;
&quot;B11135291&quot;
&quot;B11135072&quot;
&quot;B33199603&quot;
&quot;B11137879&quot;
&quot;B11110603&quot;
&quot;B11110927&quot;
&quot;B11147712&quot;
&quot;B33191224&quot;
&quot;B11131290&quot;
&quot;B11157974&quot;
&quot;B33191224&quot;
&quot;B11141503&quot;
&quot;C11137159&quot;
&quot;B33199522&quot;
</code></pre>
<p><strong>Example 4:</strong> Print the first column of <code>file1.csv</code> and <code>file3.csv</code> combined, in alphabetical order and with no duplicates.</p>
<p>Use <code>awk</code> with the list of files to be read (<code>file1.csv file3.csv</code>) as arguments. Then, use <code>| sort</code> to organize the output in alphabetical order, and finally use <code>| uniq</code> to remove the duplicates.</p>
<p>In this case, because the strings in <code>file1.csv</code> all start by colons, while the values in <code>file3.csv</code> don't, then all the values of <code>file1.csv</code> will be printed before those of <code>file3.csv</code>, because alphabetically, special characters such as <code>"</code> go before any letter (including A). So, for Bash <code>"B11110455"</code> goes before <code>Anonymized ID</code>.</p>
<pre><code class="language-bash">$ awk -F ',' '{print $1}' file1.csv file3.csv | sort | uniq
&quot;Anonymized ID&quot;
&quot;B11110455&quot;
&quot;B11110603&quot;
&quot;B11110690&quot;
&quot;B11110925&quot;
&quot;B11110927&quot;
&quot;B11131290&quot;
&quot;B11135072&quot;
&quot;B11135291&quot;
&quot;B11137879&quot;
&quot;B11141503&quot;
&quot;B11144410&quot;
&quot;B11147712&quot;
&quot;B11152799&quot;
&quot;B11153927&quot;
&quot;B11154358&quot;
&quot;B11157958&quot;
&quot;B11157974&quot;
&quot;B11177579&quot;
&quot;B11177806&quot;
&quot;B33191224&quot;
&quot;B33199522&quot;
&quot;B33199603&quot;
&quot;C11137159&quot;
Anonymized ID
B11108326
B11108399
B11110893
B11119903
B11119909
B12226507
B12226546
C11131039
C11133100
C11135566
C11137123
C11137159
C11137167
C11137439
C11137443
C11137544
C11138122
C11138150
C11138152
C11138184
C11138192
C11138797
D11144030
</code></pre>
<h2 id="paste"><code>paste</code></h2>
<h3 id="horizontal-concatenation">Horizontal concatenation</h3>
<p><strong>Example1:</strong> Concatenate all the columns of <code>file2.txt</code> and <code>file4.txt</code> horizontally, using a space as separator between the columns of one file and the other.</p>
<pre><code class="language-bash">$ paste -d ' ' file2.txt file4.txt
&quot;AnonymizedID&quot; &quot;SubjectGroup&quot; &quot;TEST1&quot; &quot;TEST2&quot; AnonymizedID SubjectGroup AGE
B11108399 Group1 23b&quot; &quot;900&quot; &quot;MissingData&quot; B11108326 Group1 59
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;555&quot; B11110893 Group1 28
&quot;B11154534&quot; &quot;Group1&quot; &quot;456&quot; &quot;456&quot; B11119909 Group2 61
&quot;B11144100&quot; &quot;Group1&quot; &quot;450&quot; &quot;886&quot; D11144030 Group3 11
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;456&quot; D11144030 Group3 13
&quot;B12226566&quot; &quot;Group2b&quot; &quot;450&quot; &quot;MissingData&quot; B11119903 Group2 84
&quot;B11134987&quot; &quot;Group1&quot; &quot;900&quot; &quot;MissingData&quot; C11131039 Group2 67
&quot;B11144345&quot; &quot;Group1&quot; &quot;900&quot; &quot;776&quot; C11133100 Group1 23
&quot;C11137159&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot; C11135566 Group2 72
&quot;B11156453&quot; &quot;Group4&quot; &quot;456&quot; &quot;2&quot; C11137159 Group3 11
&quot;B11110676&quot; &quot;Group1&quot; &quot;900&quot; &quot;10&quot; C11137159 Group3 12
&quot;C11138929&quot; &quot;Group2b&quot; &quot;2&quot; &quot;MissingData&quot; C11137167 Group3 14
&quot;B11154532&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot; C11137167 Group3 16
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot; C11137439 Group3 15
&quot;B11137120&quot; &quot;Group2b&quot; &quot;450&quot; &quot;456&quot; C11137439 Group3 79
&quot;B33191224&quot; &quot;Group2b&quot; &quot;450&quot; &quot;776&quot; C11137443 Group3 15
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot; C11137544 Group1 22
&quot;C11138999&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot; C11137123 Group2 68
&quot;B11131605&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot; C11138150 Group1 44
&quot;B11137784&quot; &quot;Group1&quot; &quot;900&quot; &quot;436&quot; C11138152 Group1 10
&quot;B11156098&quot; &quot;Group1&quot; &quot;500&quot; &quot;886&quot; C11138797 Group1 24
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot; C11138184 Group1 57
&quot;B11135292&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot; C11138122 Group1 23
&quot;C11138912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot; C11138122 MISSING 25
&quot;B11150911&quot; &quot;Group2b&quot; &quot;900&quot; &quot;117&quot; C11138192 Group1 45
&quot;B11152577&quot; &quot;Group1&quot; &quot;900&quot; &quot;756&quot; B12226507 Group1 26
&quot;B11156098&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot; B12226546 Group1 55
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<p><strong>Example 2:</strong> Concatenate all the columns of <code>file2.txt</code> and <code>file4.txt</code> horizontally using a semicolon as separator between the columns of one file and the other.</p>
<pre><code class="language-bash">$ paste -d ';' file2.txt file4.txt
&quot;AnonymizedID&quot; &quot;SubjectGroup&quot; &quot;TEST1&quot; &quot;TEST2&quot;;AnonymizedID SubjectGroup AGE
B11108399 Group1 23b&quot; &quot;900&quot; &quot;MissingData&quot;;B11108326 Group1 59
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;555&quot;;B11110893 Group1 28
&quot;B11154534&quot; &quot;Group1&quot; &quot;456&quot; &quot;456&quot;;B11119909 Group2 61
&quot;B11144100&quot; &quot;Group1&quot; &quot;450&quot; &quot;886&quot;;D11144030 Group3 11
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;456&quot;;D11144030 Group3 13
&quot;B12226566&quot; &quot;Group2b&quot; &quot;450&quot; &quot;MissingData&quot;;B11119903 Group2 84
&quot;B11134987&quot; &quot;Group1&quot; &quot;900&quot; &quot;MissingData&quot;;C11131039 Group2 67
&quot;B11144345&quot; &quot;Group1&quot; &quot;900&quot; &quot;776&quot;;C11133100 Group1 23
&quot;C11137159&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;;C11135566 Group2 72
&quot;B11156453&quot; &quot;Group4&quot; &quot;456&quot; &quot;2&quot;;C11137159 Group3 11
&quot;B11110676&quot; &quot;Group1&quot; &quot;900&quot; &quot;10&quot;;C11137159 Group3 12
&quot;C11138929&quot; &quot;Group2b&quot; &quot;2&quot; &quot;MissingData&quot;;C11137167 Group3 14
&quot;B11154532&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;;C11137167 Group3 16
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;;C11137439 Group3 15
&quot;B11137120&quot; &quot;Group2b&quot; &quot;450&quot; &quot;456&quot;;C11137439 Group3 79
&quot;B33191224&quot; &quot;Group2b&quot; &quot;450&quot; &quot;776&quot;;C11137443 Group3 15
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;;C11137544 Group1 22
&quot;C11138999&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;;C11137123 Group2 68
&quot;B11131605&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;;C11138150 Group1 44
&quot;B11137784&quot; &quot;Group1&quot; &quot;900&quot; &quot;436&quot;;C11138152 Group1 10
&quot;B11156098&quot; &quot;Group1&quot; &quot;500&quot; &quot;886&quot;;C11138797 Group1 24
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;;C11138184 Group1 57
&quot;B11135292&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;;C11138122 Group1 23
&quot;C11138912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;;C11138122 MISSING 25
&quot;B11150911&quot; &quot;Group2b&quot; &quot;900&quot; &quot;117&quot;;C11138192 Group1 45
&quot;B11152577&quot; &quot;Group1&quot; &quot;900&quot; &quot;756&quot;;B12226507 Group1 26
&quot;B11156098&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;;B12226546 Group1 55
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;;
</code></pre>
<p><strong>Example 3:</strong> Concatenate all the columns of <code>file2.txt</code> and <code>file4.txt</code>. Use a newline character as separator between the columns of one file and the other.</p>
<p>As a result, the two files will be interlined. In the output you will have the first line of <code>file2.txt</code> followed by the first line of <code>file4.txt</code>, followed by the second line of <code>file2.txt</code>, then the second line of <code>file4.txt</code>, etc.</p>
<pre><code class="language-bash">$ paste -d '\n' file2.txt file4.txt
&quot;AnonymizedID&quot; &quot;SubjectGroup&quot; &quot;TEST1&quot; &quot;TEST2&quot;
AnonymizedID SubjectGroup AGE
&quot;B11130912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
B11108399 Group1 23
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;555&quot;
B11110893 Group1 28
&quot;B11154534&quot; &quot;Group1&quot; &quot;456&quot; &quot;456&quot;
B11119909 Group2 61
&quot;B11144100&quot; &quot;Group1&quot; &quot;450&quot; &quot;886&quot;
D11144030 Group3 11
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;456&quot;
D11144030 Group3 13
&quot;B12226566&quot; &quot;Group2b&quot; &quot;450&quot; &quot;MissingData&quot;
B11119903 Group2 84
&quot;B11134987&quot; &quot;Group1&quot; &quot;900&quot; &quot;MissingData&quot;
C11131039 Group2 67
&quot;B11144345&quot; &quot;Group1&quot; &quot;900&quot; &quot;776&quot;
C11133100 Group1 23
&quot;C11137159&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
C11135566 Group2 72
&quot;B11156453&quot; &quot;Group4&quot; &quot;456&quot; &quot;2&quot;
C11137159 Group3 11
&quot;B11110676&quot; &quot;Group1&quot; &quot;900&quot; &quot;10&quot;
C11137159 Group3 12
&quot;C11138929&quot; &quot;Group2b&quot; &quot;2&quot; &quot;MissingData&quot;
C11137167 Group3 14
&quot;B11154532&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
C11137167 Group3 16
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
C11137439 Group3 15
&quot;B11137120&quot; &quot;Group2b&quot; &quot;450&quot; &quot;456&quot;
C11137439 Group3 79
&quot;B33191224&quot; &quot;Group2b&quot; &quot;450&quot; &quot;776&quot;
C11137443 Group3 15
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
C11137544 Group1 22
&quot;C11138999&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
C11137123 Group2 68
&quot;B11131605&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
C11138150 Group1 44
&quot;B11137784&quot; &quot;Group1&quot; &quot;900&quot; &quot;436&quot;
C11138152 Group1 10
&quot;B11156098&quot; &quot;Group1&quot; &quot;500&quot; &quot;886&quot;
C11138797 Group1 24
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;
C11138184 Group1 57
&quot;B11135292&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
C11138122 Group1 23
&quot;C11138912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
C11138122 MISSING 25
&quot;B11150911&quot; &quot;Group2b&quot; &quot;900&quot; &quot;117&quot;
C11138192 Group1 45
&quot;B11152577&quot; &quot;Group1&quot; &quot;900&quot; &quot;756&quot;
B12226507 Group1 26
&quot;B11156098&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
B12226546 Group1 55
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<p><strong>Example 4:</strong> Print the first column of <code>file2.txt</code> followed (horizontally) by the second column of <code>file4.txt</code>.</p>
<p><code>awk '{print $1}' file2.txt</code> will read and print the first column of <code>file2.txt</code>. Conversely, <code>awk '{print $2}' file4.txt</code> will read and print the second column of <code>file4.txt</code>. You must use the following syntax to concatenate these two results horizontally:</p>
<pre><code class="language-bash">$ paste &lt;(awk '{print $1}' file2.txt) &lt;(awk '{print $2}' file4.txt)
&quot;AnonymizedID&quot; SubjectGroup
&quot;B11130912&quot; Group1
&quot;B11137244&quot; Group1
&quot;B11154534&quot; Group2
&quot;B11144100&quot; Group3
&quot;B11137244&quot; Group3
&quot;B12226566&quot; Group2
&quot;B11134987&quot; Group2
&quot;B11144345&quot; Group1
&quot;C11137159&quot; Group2
&quot;B11156453&quot; Group3
&quot;B11110676&quot; Group3
&quot;C11138929&quot; Group3
&quot;B11154532&quot; Group3
&quot;B11155267&quot; Group3
&quot;B11137120&quot; Group3
&quot;B33191224&quot; Group3
&quot;B11155267&quot; Group1
&quot;C11138999&quot; Group2
&quot;B11131605&quot; Group1
&quot;B11137784&quot; Group1
&quot;B11156098&quot; Group1
&quot;B11133232&quot; Group1
&quot;B11135292&quot; Group1
&quot;C11138912&quot; MISSING
&quot;B11150911&quot; Group1
&quot;B11152577&quot; Group1
&quot;B11156098&quot; Group1
&quot;B11133232&quot;
</code></pre>
<p><strong>Example 5:</strong> Print the first column of <code>file1.csv</code> followed (horizontally) by the second column of <code>file3.csv</code>. Separate the columns with a comma.</p>
<p>In this example, we use the same syntax as the example before, but because <code>file1.csv</code> and <code>file3.csv</code> use comma as the column separator, you have to use the <code>-F','</code> flag in the <code>awk</code> commands. Additionally, remember to use the flag <code>-d ','</code> for the paste command in order to separate the pasted columns with a comma.</p>
<pre><code class="language-bash">$ paste -d ',' &lt;(awk -F',' '{print $1}' file1.csv) &lt;(awk -F',' '{print $2}' file3.csv)
&quot;Anonymized ID&quot;,Subject Group
&quot;B33199522&quot;,MISSING
&quot;B33199603&quot;,Group1
&quot;B11137879&quot;,Group1
&quot;B11144410&quot;,Group1
&quot;B11110455&quot;,Group1
&quot;B11135291&quot;,Group1
&quot;B11153927&quot;,Group1
&quot;B11177579&quot;,Group1
&quot;B11177806&quot;,Group1
&quot;B11157958&quot;,Group3
&quot;B11110690&quot;,Group3
&quot;B11152799&quot;,Group3
&quot;B11154358&quot;,Group3
&quot;B11110925&quot;,Group2 b
&quot;B11135291&quot;,Group2 b
&quot;B11135072&quot;,Group2 b
&quot;B33199603&quot;,Group1
&quot;B11137879&quot;,Group3
&quot;B11110603&quot;,Group2 b
&quot;B11110927&quot;,Group3
&quot;B11147712&quot;,Group3
&quot;B33191224&quot;,Group1
&quot;B11131290&quot;,Group3
&quot;B11157974&quot;,Group1
&quot;B33191224&quot;,Group1
&quot;B11141503&quot;,Group2 b
&quot;C11137159&quot;,Group1
&quot;B33199522&quot;,
</code></pre>
<h2 id="reading-specific-lines">Reading specific lines</h2>
<p><strong>Example 1:</strong> Print the <strong>first</strong> line of <code>file1.csv</code>.</p>
<p>In order to print only the first line of the file, we first read it using the <code>cat</code> command, and then we select the first line from the previous output using <code>head -n 1</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | head -n 1
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
</code></pre>
<p><strong>Example 2:</strong> Print the <strong>first two</strong> lines of <code>file1.csv</code>.</p>
<p>In order to print only the first two lines of the file we first read it using the <code>cat</code> command, and then we select those lines from the previous output using <code>head -n 2</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | head -n 2
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 3:</strong> Print the <strong>first three</strong> lines of <code>file1.csv</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | head -n 3
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 4:</strong> Print the <strong>last</strong> line of <code>file1.csv</code>.</p>
<p>In order to print only the last line of the file we first read it using the <code>cat</code> command, and then we select the last line from the previous output using <code>tail -n 1</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | tail -n 1
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 5:</strong> Print the <strong>last two</strong> lines of <code>file1.csv</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | tail -n 2
&quot;C11137159&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 6:</strong> Print the <strong>last three</strong> lines of <code>file1.csv</code> in <strong>reverse</strong>.</p>
<p>As we learned previously, the flag <code>-r</code> of <code>tail</code> command can be used to print things in reversed order.</p>
<pre><code class="language-bash">$ cat file1.csv | tail -r -n 3
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;C11137159&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
&quot;B11141503&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 7:</strong> Print <strong>from the beginning until the second line</strong> of <code>file1.csv</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | head -n+2
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 8:</strong> Print <strong>from the beginning until the third line</strong> of <code>file1.csv</code>.</p>
<pre><code class="language-bash">$ cat file1.csv | head -n+3
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<h2 id="searching-a-value">Searching a value</h2>
<p>In the following examples we will read specific columns or lines in a file or a list of files, that contain a searched value.</p>
<p><strong>Example 1:</strong> Print the line(s) of <code>file3.csv</code> that contain the string <code>C11137439</code>.</p>
<p>Using <code>awk</code>:</p>
<pre><code class="language-bash">$ awk '/C11137439/' file3.csv
C11137439,Group3,79
C11137439,Group3,15
</code></pre>
<p>Using <code>grep</code>:</p>
<pre><code class="language-bash">$ grep C11137439 file3.csv
C11137439,Group3,79
C11137439,Group3,15
</code></pre>
<p><strong>Example 2:</strong> Print the line(s) of <code>file3.csv</code> that contain the string <code>AAA</code> (which is stored in a variable).</p>
<p>Using <code>awk</code>:</p>
<pre><code class="language-bash">$ VAR=C11137439
$ awk -v var=$VAR '$0~var' file3.csv
C11137439,Group3,79
C11137439,Group3,15
</code></pre>
<p>Using <code>grep</code>:</p>
<pre><code class="language-bash">$ grep $VAR file3.csv
C11137439,Group3,79
C11137439,Group3,15
</code></pre>
<p><strong>Example 3:</strong> Print the line(s) of <code>file3.csv</code> that contain the strings <code>C11137439</code> or <code>B11119909</code>.</p>
<p>To search for more than one expression, add the flag <code>-e</code> in front of each expression.</p>
<pre><code class="language-bash">$ grep -e &quot;C11137439&quot; -e &quot;B11119909&quot; file3.csv
C11137439,Group3,79
C11137439,Group3,15
B11119909,Group2 b,61
</code></pre>
<p><strong>Example 4:</strong> Print the line(s) of <code>file3.csv</code> that contain the strings <code>C11137439</code>, <code>B11119909</code> or <code>B11110893</code>.</p>
<pre><code class="language-bash">$ grep -e &quot;C11137439&quot; -e &quot;B11119909&quot; -e &quot;B11110893&quot; file3.csv
C11137439,Group3,79
C11137439,Group3,15
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 5:</strong> Print the line(s) of <code>file3.csv</code> that contain the strings <code>C11137439</code> or <code>B11119909</code> (which are stored in a file called <code>patterns.txt</code>).</p>
<pre><code class="language-bash">$ cat patterns.txt
C11137439
B11119909
</code></pre>
<pre><code class="language-bash">$ grep -f patterns.txt file3.csv
C11137439,Group3,79
C11137439,Group3,15
B11119909,Group2 b,61
</code></pre>
<p><strong>Example 6:</strong> Print the line(s) of <code>file3.csv</code> that do not contain the string <code>C11137439</code>.</p>
<pre><code class="language-bash">$ grep -v &quot;C11137439&quot; file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 7:</strong> Print the line(s) of any file in the current directory that contain the string <code>C11137439</code>.</p>
<pre><code class="language-bash">$ awk '/C11137439/' *
C11137439,Group3,79
C11137439,Group3,15
C11137439 Group3 15
C11137439 Group3 79
C11137439
</code></pre>
<pre><code class="language-bash">$ grep C11137439 *
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
file4.txt:C11137439 Group3 15
file4.txt:C11137439 Group3 79
patterns.txt:C11137439
</code></pre>
<p>To omit the file names using <code>grep</code>, use the flag <code>-h</code>:</p>
<pre><code class="language-bash">$ grep -h C11137439 *
C11137439,Group3,79
C11137439,Group3,15
C11137439 Group3 15
C11137439 Group3 79
C11137439
</code></pre>
<p>If you wanted to include the line number for each match, you can add the flag <code>-n</code>:</p>
<pre><code class="language-bash">$ grep -n &quot;C11137439&quot; *
file3.csv:21:C11137439,Group3,79
file3.csv:22:C11137439,Group3,15
file4.txt:15:C11137439 Group3 15
file4.txt:16:C11137439 Group3 79
patterns.txt:1:C11137439
</code></pre>
<pre><code class="language-bash">$ grep -h -n &quot;C11137439&quot; *
21:C11137439,Group3,79
22:C11137439,Group3,15
15:C11137439 Group3 15
16:C11137439 Group3 79
1:C11137439
</code></pre>
<p>If you want to show only the first three matches, you can add the flag <code>-m 3</code> (to print only three lines):</p>
<pre><code class="language-bash">$ grep -m 3 &quot;C11137439&quot; *
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
file4.txt:C11137439 Group3 15
</code></pre>
<pre><code class="language-bash">$ grep -m 3 &quot;C11137439&quot; * -h
C11137439,Group3,79
C11137439,Group3,15
C11137439 Group3 15
</code></pre>
<p><strong>Example 8:</strong> Print the number of lines in each file of the current directory that contain <code>C11137439</code>.</p>
<pre><code class="language-bash">$ grep -c &quot;C11137439&quot; *
file1.csv:0
file1_reordered.csv:0
file2.txt:0
file3.csv:2
file4.txt:2
patterns.txt:1
patterns2.txt:0
</code></pre>
<p><strong>Example 9:</strong> Print only the name of the files in the current directory that contain <code>C11137439</code>.</p>
<pre><code class="language-bash">$ grep -l &quot;C11137439&quot; *
file3.csv
file4.txt
patterns.txt
</code></pre>
<p><strong>Example 10:</strong> Print the line(s) of any file in the current directory that contain <code>C11137439</code>, each line followed by the next three lines in the corresponding file (if there are three or more lines after the matched one).</p>
<pre><code class="language-bash">$ grep -A 3 &quot;C11137439&quot; *
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
file3.csv-C11133100,Group1,23
file3.csv-D11144030,Group3,13
file3.csv-B11108399,Group1,23
--
file4.txt:C11137439 Group3 15
file4.txt:C11137439 Group3 79
file4.txt-C11137443 Group3 15
file4.txt-C11137544 Group1 22
file4.txt-C11137123 Group2 68
--
patterns.txt:C11137439
patterns.txt-B11119909
</code></pre>
<p><strong>Example 11:</strong> Print the line(s) of any file in the current directory that contain <code>C11137439</code>, each line preceded by the previous three lines in the corresponding file (if there are three or more lines before the matched one).</p>
<pre><code class="language-bash">$ grep -B 3 &quot;C11137439&quot; *
file3.csv-C11137544,Group1,21
file3.csv-C11137443,Group3,11
file3.csv-C11137123,Group2 b,69
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
--
file4.txt-C11137159 Group3 12
file4.txt-C11137167 Group3 14
file4.txt-C11137167 Group3 16
file4.txt:C11137439 Group3 15
file4.txt:C11137439 Group3 79
--
patterns.txt:C11137439
</code></pre>
<p><strong>Example 12:</strong> Print the line(s) of any file in the current directory that contain <code>C11137439</code>, each line preceded by the previous three lines and followed by the next three lines in the corresponding file (if there is three or more lines before/after the matched one).</p>
<pre><code class="language-bash">$ grep -C 3 &quot;C11137439&quot; *
file3.csv-C11137544,Group1,21
file3.csv-C11137443,Group3,11
file3.csv-C11137123,Group2 b,69
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
file3.csv-C11133100,Group1,23
file3.csv-D11144030,Group3,13
file3.csv-B11108399,Group1,23
--
--
file4.txt-C11137159 Group3 12
file4.txt-C11137167 Group3 14
file4.txt-C11137167 Group3 16
file4.txt:C11137439 Group3 15
file4.txt:C11137439 Group3 79
file4.txt-C11137443 Group3 15
file4.txt-C11137544 Group1 22
file4.txt-C11137123 Group2 68
--
--
patterns.txt:C11137439
patterns.txt-B11119909
</code></pre>
<pre><code class="language-bash">$ grep -A 3 -B 3 &quot;C11137439&quot; *
file3.csv-C11137544,Group1,21
file3.csv-C11137443,Group3,11
file3.csv-C11137123,Group2 b,69
file3.csv:C11137439,Group3,79
file3.csv:C11137439,Group3,15
file3.csv-C11133100,Group1,23
file3.csv-D11144030,Group3,13
file3.csv-B11108399,Group1,23
--
--
file4.txt-C11137159 Group3 12
file4.txt-C11137167 Group3 14
file4.txt-C11137167 Group3 16
file4.txt:C11137439 Group3 15
file4.txt:C11137439 Group3 79
file4.txt-C11137443 Group3 15
file4.txt-C11137544 Group1 22
file4.txt-C11137123 Group2 68
--
--
patterns.txt:C11137439
patterns.txt-B11119909
</code></pre>
<p><strong>Example 13:</strong> Print the line(s) of any file in the current directory that contain <code>"B11133232"</code> (including the quotation marks).</p>
<pre><code class="language-bash">$ awk '/&quot;B11133232&quot;/' *
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<pre><code class="language-bash">$ grep \&quot;B11133232\&quot; *
file2.txt:&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;
file2.txt:&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<p>IF you want to make sure the quotation marks are included in the <code>grep</code> search, you must include the backslash before the quotation marks (<code>\"</code>). Otherwise, Bash will interpret the search value as <code>B11133232</code> and not <code>"B11133232"</code>.</p>
<p><strong>Example 14:</strong> Print the line(s) of <code>file3.csv</code> that contain <code>B11108399</code> <em>or</em> <code>B11108326</code>.</p>
<p>This search has the following rules:</p>
<ul>
<li>We're looking for words that start with the following seven characters: <code>B111083</code>.</li>
<li>The 8th character can be a <code>9</code> or a <code>2</code>.</li>
<li>The last character can be a <code>9</code> or a <code>6</code>.</li>
</ul>
<p>So, in the <code>grep</code> command, we replace the 8th character by <code>[92]</code> to indicate that it can have any of those two values, and the last character by <code>[96]</code> to indicate that it can have value <code>9</code> or <code>6</code>.</p>
<pre><code class="language-bash">$ grep B111083[92][96] file3.csv
B11108399,Group1,23
B11108326,Group1,59
</code></pre>
<p><strong>Example 15:</strong> Print the line(s) of <code>file3.csv</code> that contain the values <code>Group1</code> or <code>Group2</code>.</p>
<pre><code class="language-bash">$ grep Group[12] file3.csv
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137123,Group2 b,69
C11133100,Group1,23
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 16:</strong> Print the first column of <code>file2.txt</code> and <code>file3.csv</code> for those lines that contain the values <code>Group1</code> or <code>Group2</code>.</p>
<p>Remember that you have to use the flag <code>-F','</code> with <code>awk</code> when the columns of the file are separated by commas and not spaces.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ grep Group[12] file2.txt | awk '{print $1}'
&quot;B11130912&quot;
&quot;B11137244&quot;
&quot;B11154534&quot;
&quot;B11144100&quot;
&quot;B11137244&quot;
&quot;B12226566&quot;
&quot;B11134987&quot;
&quot;B11144345&quot;
&quot;B11110676&quot;
&quot;C11138929&quot;
&quot;B11154532&quot;
&quot;B11137120&quot;
&quot;B33191224&quot;
&quot;C11138999&quot;
&quot;B11131605&quot;
&quot;B11137784&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;
&quot;C11138912&quot;
&quot;B11150911&quot;
&quot;B11152577&quot;
&quot;B11156098&quot;
&quot;B11133232&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ grep Group[12] file3.csv | awk -F',' '{print $1}'
C11138192
B12226507
B12226546
C11138122
C11138184
C11138797
C11138152
C11138150
C11131039
C11135566
B11119903
C11137544
C11137123
C11133100
B11108399
B11108326
B11119909
B11110893
</code></pre>
<p><strong>Example 17:</strong> Print the first and second columns of <code>file2.txt</code> and <code>file3.csv</code> for those lines that contain the values <code>Group1</code> or <code>Group2</code>.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ grep Group[12] file2.txt | awk '{print $1,$2}'
&quot;B11130912&quot; &quot;Group2b&quot;
&quot;B11137244&quot; &quot;Group1&quot;
&quot;B11154534&quot; &quot;Group1&quot;
&quot;B11144100&quot; &quot;Group1&quot;
&quot;B11137244&quot; &quot;Group1&quot;
&quot;B12226566&quot; &quot;Group2b&quot;
&quot;B11134987&quot; &quot;Group1&quot;
&quot;B11144345&quot; &quot;Group1&quot;
&quot;B11110676&quot; &quot;Group1&quot;
&quot;C11138929&quot; &quot;Group2b&quot;
&quot;B11154532&quot; &quot;Group1&quot;
&quot;B11137120&quot; &quot;Group2b&quot;
&quot;B33191224&quot; &quot;Group2b&quot;
&quot;C11138999&quot; &quot;Group2b&quot;
&quot;B11131605&quot; &quot;Group1&quot;
&quot;B11137784&quot; &quot;Group1&quot;
&quot;B11156098&quot; &quot;Group1&quot;
&quot;B11133232&quot; &quot;Group1&quot;
&quot;C11138912&quot; &quot;Group2b&quot;
&quot;B11150911&quot; &quot;Group2b&quot;
&quot;B11152577&quot; &quot;Group1&quot;
&quot;B11156098&quot; &quot;Group1&quot;
&quot;B11133232&quot; &quot;Group1&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ grep Group[12] file3.csv | awk -F',' '{print $1,$2}'
C11138192 Group1
B12226507 Group1
B12226546 Group1
C11138122 Group1
C11138184 Group1
C11138797 Group1
C11138152 Group1
C11138150 Group1
C11131039 Group2 b
C11135566 Group2 b
B11119903 Group2 b
C11137544 Group1
C11137123 Group2 b
C11133100 Group1
B11108399 Group1
B11108326 Group1
B11119909 Group2 b
B11110893 Group1
</code></pre>
<p><strong>Example 18:</strong> Print the line(s) of <code>file3.csv</code> and <code>file4.txt</code> that have value <code>11</code> in the third column.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$3 == &quot;11&quot; {print $1,$2}' file4.txt
D11144030 Group3
C11137159 Group3
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$3 == &quot;11&quot; {print $1,$2}' file3.csv
C11137443 Group3
</code></pre>
<p><strong>Example 19:</strong> Print the first and second columns of those lines in <code>file3.csv</code> and <code>file4.txt</code> that have value <code>11</code> in the third column.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$3 == &quot;11&quot; {print $1,$2}' file4.txt
D11144030 Group3
C11137159 Group3
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$3 == &quot;11&quot; {print $1,$2}' file3.csv
C11137443 Group3
</code></pre>
<p><strong>Example 20:</strong> Print the line(s) of <code>file1.csv</code> and <code>file2.txt</code> that have value <code>"Group1"</code> (including the colons) in the second column.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$2 == &quot;\&quot;Group1\&quot;&quot;' file2.txt
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;555&quot;
&quot;B11154534&quot; &quot;Group1&quot; &quot;456&quot; &quot;456&quot;
&quot;B11144100&quot; &quot;Group1&quot; &quot;450&quot; &quot;886&quot;
&quot;B11137244&quot; &quot;Group1&quot; &quot;450&quot; &quot;456&quot;
&quot;B11134987&quot; &quot;Group1&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11144345&quot; &quot;Group1&quot; &quot;900&quot; &quot;776&quot;
&quot;B11110676&quot; &quot;Group1&quot; &quot;900&quot; &quot;10&quot;
&quot;B11154532&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
&quot;B11131605&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
&quot;B11137784&quot; &quot;Group1&quot; &quot;900&quot; &quot;436&quot;
&quot;B11156098&quot; &quot;Group1&quot; &quot;500&quot; &quot;886&quot;
&quot;B11133232&quot; &quot;Group1&quot; &quot;500&quot; &quot;MissingData&quot;
&quot;B11152577&quot; &quot;Group1&quot; &quot;900&quot; &quot;756&quot;
&quot;B11156098&quot; &quot;Group1&quot; &quot;456&quot; &quot;886&quot;
&quot;B11133232&quot; &quot;Group1&quot; &quot;456&quot; &quot;MissingData&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$2 == &quot;\&quot;Group1\&quot;&quot;' file1.csv
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11137879&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11153927&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11177806&quot;,&quot;Group1&quot;,&quot;MD&quot;,&quot;&quot;
&quot;B11152799&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11154358&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110925&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11137879&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110603&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110927&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11147712&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11157974&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199522&quot;,&quot;Group1&quot;,&quot;0&quot;,&quot;&quot;
</code></pre>
<p><strong>Example 21:</strong> Print the line(s) of <code>file1.csv</code> and <code>file2.txt</code> that do not have value <code>"Group1"</code> (including the quotation marks) in the second column.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$2 != &quot;\&quot;Group1\&quot;&quot;' file2.txt
&quot;AnonymizedID&quot; &quot;SubjectGroup&quot; &quot;TEST1&quot; &quot;TEST2&quot;
&quot;B11130912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B12226566&quot; &quot;Group2b&quot; &quot;450&quot; &quot;MissingData&quot;
&quot;C11137159&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
&quot;B11156453&quot; &quot;Group4&quot; &quot;456&quot; &quot;2&quot;
&quot;C11138929&quot; &quot;Group2b&quot; &quot;2&quot; &quot;MissingData&quot;
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
&quot;B11137120&quot; &quot;Group2b&quot; &quot;450&quot; &quot;456&quot;
&quot;B33191224&quot; &quot;Group2b&quot; &quot;450&quot; &quot;776&quot;
&quot;B11155267&quot; &quot;Group3&quot; &quot;900&quot; &quot;10&quot;
&quot;C11138999&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11135292&quot; &quot;Group3&quot; &quot;MissingData&quot; &quot;MissingData&quot;
&quot;C11138912&quot; &quot;Group2b&quot; &quot;900&quot; &quot;MissingData&quot;
&quot;B11150911&quot; &quot;Group2b&quot; &quot;900&quot; &quot;117&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$2 != &quot;\&quot;Group1\&quot;&quot;' file1.csv
&quot;Anonymized ID&quot;,&quot;Subject Group&quot;,&quot;HASCONDITION&quot;,&quot;CONDITION&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11144410&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110455&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11135291&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11177579&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11157958&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11110690&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11135291&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
&quot;B11135072&quot;,&quot;MISSING&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33199603&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33191224&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11131290&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B33191224&quot;,&quot;Group2 b&quot;,&quot;0&quot;,&quot;&quot;
&quot;B11141503&quot;,&quot;Group3&quot;,&quot;0&quot;,&quot;&quot;
&quot;C11137159&quot;,&quot;Group3&quot;,&quot;9&quot;,&quot;mTBI&quot;
</code></pre>
<p><strong>Example 22:</strong> Print the first column of those lines in <code>file1.csv</code> and <code>file2.txt</code> that do not have value <code>"Group1"</code> (including the quotation marks) in the second column.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$2 != &quot;\&quot;Group1\&quot;&quot; {print $1}' file2.txt
&quot;AnonymizedID&quot;
&quot;B11130912&quot;
&quot;B12226566&quot;
&quot;C11137159&quot;
&quot;B11156453&quot;
&quot;C11138929&quot;
&quot;B11155267&quot;
&quot;B11137120&quot;
&quot;B33191224&quot;
&quot;B11155267&quot;
&quot;C11138999&quot;
&quot;B11135292&quot;
&quot;C11138912&quot;
&quot;B11150911&quot;
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$2 != &quot;\&quot;Group1\&quot;&quot; {print $1}' file1.csv
&quot;Anonymized ID&quot;
&quot;B33199603&quot;
&quot;B11144410&quot;
&quot;B11110455&quot;
&quot;B11135291&quot;
&quot;B11177579&quot;
&quot;B11157958&quot;
&quot;B11110690&quot;
&quot;B11135291&quot;
&quot;B11135072&quot;
&quot;B33199603&quot;
&quot;B33191224&quot;
&quot;B11131290&quot;
&quot;B33191224&quot;
&quot;B11141503&quot;
&quot;C11137159&quot;
</code></pre>
<p><strong>Example 23:</strong> Print the first column of those lines in <code>file3.csv</code> and <code>file4.txt</code> that have age (third column) greater than 20.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$3 &gt; &quot;20&quot; {print $1}' file4.txt
AnonymizedID
B11108326
B11110893
B11119909
B11119903
C11131039
C11133100
C11135566
C11137439
C11137544
C11137123
C11138150
C11138797
C11138184
C11138122
C11138122
C11138192
B12226507
B12226546
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$3 &gt; &quot;20&quot; {print $1}' file3.csv
Anonymized ID
C11138122
C11138192
B12226507
B12226546
C11138122
C11138184
C11138797
C11138152
C11138150
C11131039
C11135566
B11119903
C11137544
C11137123
C11137439
C11133100
B11108399
B11108326
B11119909
B11110893
</code></pre>
<p><strong>Example 24:</strong> Print the first column of those lines in <code>file3.csv</code> and <code>file4.txt</code> that have age (third column) less than 20.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '$3 &lt; &quot;20&quot; {print $1}' file4.txt
D11144030
D11144030
C11137159
C11137159
C11137167
C11137167
C11137439
C11137443
C11138152
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '$3 &lt; &quot;20&quot; {print $1}' file3.csv
C11137167
C11137159
C11137167
C11137159
C11137443
C11137439
D11144030
</code></pre>
<p><strong>Example 25:</strong> Print the line(s) of <code>file3.csv</code> that have value <code>"Group1"</code> or <code>"Group3"</code> in the second column.</p>
<p>When there is more than one rule, the easiest and more organized way to run the command is to put all the rules in a text file and call that text file using the flag <code>-f</code>. In the following example, <code>patterns3.txt</code> contains the rules to filter the lines that are to be printed (<code>$2 == "Group1" and $2 == "Group3"</code>).</p>
<pre><code class="language-bash">$ cat patterns3.txt
$2 == &quot;Group1&quot;
$2 == &quot;Group3&quot;
</code></pre>
<pre><code class="language-bash">$ awk -F',' -f patterns3.txt file3.csv
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11137544,Group1,21
C11137443,Group3,11
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11110893,Group1,28
</code></pre>
<pre><code class="language-bash">$ cat patterns4.txt
$2 == &quot;Group1&quot; || $2 == &quot;Group3&quot;

$ awk -F',' -f test.txt file3.csv
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11137544,Group1,21
C11137443,Group3,11
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11110893,Group1,28
</code></pre>
<p>In this example, we obtained the same result using either <code>patterns3.txt</code> or <code>patterns4.txt</code>. When you want to select any line that contains any pattern in a list of patterns, you can either put each pattern in a different line of the text file or use the or (<code>||</code>) symbol to concatenate all the patterns or rules.</p>
<p><strong>Example 26:</strong> Print the first column of those lines in <code>file3.csv</code> that have value <code>"Group1"</code> in the second column, and value greater than 60 in the third column. <em>Or</em> that have value <code>"Group3"</code> in the second column value less than 20 in the third column.</p>
<p>In this example, we want to print any line that contains one of the following rules:</p>
<ul>
<li>Second column equals Group1 and third greater than 60: <code>$2 == "Group1" &amp;&amp; $3 &gt; 60</code></li>
<li>Second column equals and Group3 third less than 20: <code>$2 == "Group3" &amp;&amp; $3 &lt; 20</code></li>
</ul>
<p>So, the content of our pattern file must be:</p>
<pre><code class="language-bash">$ cat patterns5.txt
$2 == &quot;Group1&quot; &amp;&amp; $3 &gt; 60
$2 == &quot;Group3&quot; &amp;&amp; $3 &lt; 20
</code></pre>
<p>To print all the columns from the selected lines:</p>
<pre><code class="language-bash">$ awk -F',' -f patterns5.txt file3.csv
B12226507,Group1,68
B12226546,Group1,67
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11137443,Group3,11
C11137439,Group3,15
D11144030,Group3,13
</code></pre>
<p>To print the first column:</p>
<pre><code class="language-bash">$ awk -F',' -f patterns5.txt file3.csv | awk -F',' '{print $1}'
B12226507
B12226546
C11137167
C11137159
C11137167
C11137159
C11137443
C11137439
D11144030
</code></pre>
<p>The following page contains a summary of other patterns that can be included in a pattern file: <a href="https://ss64.com/bash/awk.html">https://ss64.com/bash/awk.html</a>.</p>
<h2 id="searching-a-pattern">Searching a pattern</h2>
<p><strong>Example 1:</strong> Print the line(s) of <code>file3.csv</code> that start with <code>B</code>.</p>
<pre><code class="language-bash">$ grep '^B' file3.csv
B12226507,Group1,68
B12226546,Group1,67
B11119903,Group2 b,83
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 2:</strong> Print the line(s) of <code>test7.csv</code> that end with <code>13</code>.</p>
<pre><code class="language-bash">$ grep '13$' file3.csv
C11137159,Group3,13
C11137159,Group3,13
D11144030,Group3,13
</code></pre>
<p><strong>Example 3:</strong> Print the line(s) of <code>test7.csv</code> that end with <code>13</code> (when this pattern is stored in a file called <code>patterns2.txt</code>).</p>
<pre><code class="language-bash">$ cat patterns2.txt
13$

$ grep -f patterns2.txt file3.csv
C11137159,Group3,13
C11137159,Group3,13
D11144030,Group3,13
</code></pre>
<p><strong>Example 4:</strong> Print all the non-empty lines (lines with more than 0 fields <code>NF &gt; 0</code>) in <code>file3.csv</code> and <code>file4.txt</code>.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk 'NF &gt; 0' file4.txt
AnonymizedID SubjectGroup AGE
B11108326 Group1 59
B11108399 Group1 23
B11110893 Group1 28
B11119909 Group2 61
D11144030 Group3 11
D11144030 Group3 13
B11119903 Group2 84
C11131039 Group2 67
C11133100 Group1 23
C11135566 Group2 72
C11137159 Group3 11
C11137159 Group3 12
C11137167 Group3 14
C11137167 Group3 16
C11137439 Group3 15
C11137439 Group3 79
C11137443 Group3 15
C11137544 Group1 22
C11137123 Group2 68
C11138150 Group1 44
C11138152 Group1 10
C11138797 Group1 24
C11138184 Group1 57
C11138122 Group1 23
C11138122 MISSING 25
C11138192 Group1 45
B12226507 Group1 26
B12226546 Group1 55
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' 'NF &gt; 0' file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 5:</strong> Print all the lines that have more than two fields (<code>NF &gt; 2</code>) in <code>file3.csv</code> and <code>file4.txt</code>.</p>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk 'NF &gt; 2' file4.txt
AnonymizedID SubjectGroup AGE
B11108326 Group1 59
B11108399 Group1 23
B11110893 Group1 28
B11119909 Group2 61
D11144030 Group3 11
D11144030 Group3 13
B11119903 Group2 84
C11131039 Group2 67
C11133100 Group1 23
C11135566 Group2 72
C11137159 Group3 11
C11137159 Group3 12
C11137167 Group3 14
C11137167 Group3 16
C11137439 Group3 15
C11137439 Group3 79
C11137443 Group3 15
C11137544 Group1 22
C11137123 Group2 68
C11138150 Group1 44
C11138152 Group1 10
C11138797 Group1 24
C11138184 Group1 57
C11138122 Group1 23
C11138122 MISSING 25
C11138192 Group1 45
B12226507 Group1 26
B12226546 Group1 55
</code></pre>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' 'NF &gt; 2' file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<h2 id="find-and-replace-text">Find and replace text</h2>
<p>Replace all occurrences of <code>C11137159</code> in <code>file3.csv</code> with <code>XXXXXXXXX</code> and save the modified content in <code>file3_mod.csv</code>.</p>
<p>Command to execute the substitution:</p>
<pre><code class="language-bash">sed 's/C11137159/XXXXXXXXX/' file3.csv &gt; file3_mod.csv
</code></pre>
<p>Content of <code>file3.csv</code> before the substitution:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content of <code>file3.csv</code> after the substitution:</p>
<pre><code class="language-bash">$ cat file3_mod.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
XXXXXXXXX,Group3,13
C11137167,Group3,16
XXXXXXXXX,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<h2 id="find-and-replace-patterns">Find and replace patterns</h2>
<p>In the following examples, instead of replacing a fix string as we did before, we will replace a group of characters (i.e. all upper-case characters in the file) by a single character or another group of characters (i.e. replace with lower-case characters). The groups of characters that can be used are listed in the following table:</p>
<table>
<thead>
<tr>
<th>Expression</th>
<th>Group of characters</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>[:alnum:]</code></td>
<td>Letters and digits</td>
</tr>
<tr>
<td><code>[:alpha:]</code></td>
<td>Letters</td>
</tr>
<tr>
<td><code>[:blank:]</code></td>
<td>Horizontal white space</td>
</tr>
<tr>
<td><code>[:cntrl:]</code></td>
<td>Control characters</td>
</tr>
<tr>
<td><code>[:digit:]</code></td>
<td>Digits</td>
</tr>
<tr>
<td><code>[:graph:]</code></td>
<td>Printable characters, excluding space</td>
</tr>
<tr>
<td><code>[:lower:]</code></td>
<td>Lower-case letters</td>
</tr>
<tr>
<td><code>[:print:]</code></td>
<td>Printable characters, including space</td>
</tr>
<tr>
<td><code>[:punct:]</code></td>
<td>Punctuation characters</td>
</tr>
<tr>
<td><code>[:space:]</code></td>
<td>Horizontal or vertical white space</td>
</tr>
<tr>
<td><code>[:upper:]</code></td>
<td>Upper-case letters</td>
</tr>
<tr>
<td><code>[:xdigit:]</code></td>
<td>Hexadecimal digits</td>
</tr>
</tbody>
</table>
<p><strong>Example 1:</strong> Replace all upper-case letters in <code>file3.csv</code> by lower-case.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:upper:]' '[:lower:]'
anonymized id,subject group,age
c11138122,missing,21
c11138192,group1,54
b12226507,group1,68
b12226546,group1,67
c11138122,group1,24
c11138184,group1,59
c11138797,group1,22
c11138152,group1,53
c11138150,group1,41
c11137167,group3,14
c11137159,group3,13
c11137167,group3,16
c11137159,group3,13
c11131039,group2 b,67
c11135566,group2 b,73
b11119903,group2 b,83
c11137544,group1,21
c11137443,group3,11
c11137123,group2 b,69
c11137439,group3,79
c11137439,group3,15
c11133100,group1,23
d11144030,group3,13
b11108399,group1,23
b11108326,group1,59
b11119909,group2 b,61
b11110893,group1,28
</code></pre>
<p><strong>Example 2:</strong>  Replace all lower-case letters in <code>file3.csv</code> by upper-case.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:lower:]' '[:upper:]'
ANONYMIZED ID,SUBJECT GROUP,AGE
C11138122,MISSING,21
C11138192,GROUP1,54
B12226507,GROUP1,68
B12226546,GROUP1,67
C11138122,GROUP1,24
C11138184,GROUP1,59
C11138797,GROUP1,22
C11138152,GROUP1,53
C11138150,GROUP1,41
C11137167,GROUP3,14
C11137159,GROUP3,13
C11137167,GROUP3,16
C11137159,GROUP3,13
C11131039,GROUP2 B,67
C11135566,GROUP2 B,73
B11119903,GROUP2 B,83
C11137544,GROUP1,21
C11137443,GROUP3,11
C11137123,GROUP2 B,69
C11137439,GROUP3,79
C11137439,GROUP3,15
C11133100,GROUP1,23
D11144030,GROUP3,13
B11108399,GROUP1,23
B11108326,GROUP1,59
B11119909,GROUP2 B,61
B11110893,GROUP1,28
</code></pre>
<p><strong>Example 3:</strong> Replace all alphabetical characters in <code>file3.csv</code> by the number 0.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:alpha:]' 0
0000000000 00,0000000 00000,000
011138122,0000000,21
011138192,000001,54
012226507,000001,68
012226546,000001,67
011138122,000001,24
011138184,000001,59
011138797,000001,22
011138152,000001,53
011138150,000001,41
011137167,000003,14
011137159,000003,13
011137167,000003,16
011137159,000003,13
011131039,000002 0,67
011135566,000002 0,73
011119903,000002 0,83
011137544,000001,21
011137443,000003,11
011137123,000002 0,69
011137439,000003,79
011137439,000003,15
011133100,000001,23
011144030,000003,13
011108399,000001,23
011108326,000001,59
011119909,000002 0,61
011110893,000001,28
</code></pre>
<p><strong>Example 4:</strong> Replace all digits in <code>file3.csv</code> by the letter <code>X</code>.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:digit:]' X
Anonymized ID,Subject Group,AGE
CXXXXXXXX,MISSING,XX
CXXXXXXXX,GroupX,XX
BXXXXXXXX,GroupX,XX
BXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX b,XX
CXXXXXXXX,GroupX b,XX
BXXXXXXXX,GroupX b,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX b,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
CXXXXXXXX,GroupX,XX
DXXXXXXXX,GroupX,XX
BXXXXXXXX,GroupX,XX
BXXXXXXXX,GroupX,XX
BXXXXXXXX,GroupX b,XX
BXXXXXXXX,GroupX,XX
</code></pre>
<p><strong>Example 5:</strong> Replace all punctuation characters in <code>file3.csv</code> by a space.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:punct:]' ' '
Anonymized ID Subject Group AGE
C11138122 MISSING 21
C11138192 Group1 54
B12226507 Group1 68
B12226546 Group1 67
C11138122 Group1 24
C11138184 Group1 59
C11138797 Group1 22
C11138152 Group1 53
C11138150 Group1 41
C11137167 Group3 14
C11137159 Group3 13
C11137167 Group3 16
C11137159 Group3 13
C11131039 Group2 b 67
C11135566 Group2 b 73
B11119903 Group2 b 83
C11137544 Group1 21
C11137443 Group3 11
C11137123 Group2 b 69
C11137439 Group3 79
C11137439 Group3 15
C11133100 Group1 23
D11144030 Group3 13
B11108399 Group1 23
B11108326 Group1 59
B11119909 Group2 b 61
B11110893 Group1 28
</code></pre>
<p><strong>Example 5:</strong> Replace all white spaces in <code>file3.csv</code> by an underscore.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr '[:blank:]' '_'
Anonymized_ID,Subject_Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2_b,67
C11135566,Group2_b,73
B11119903,Group2_b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2_b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2_b,61
B11110893,Group1,28
</code></pre>
<h2 id="replace-range-of-letters-or-numbers">Replace range of letters or numbers</h2>
<p><strong>Example 6:</strong> Replace any <code>A</code>, <code>B</code> or <code>C</code> (letters in the range A-C) in <code>file3.csv</code> by the letter <code>D</code>.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr 'A-C' 'D'
Dnonymized ID,Subject Group,DGE
D11138122,MISSING,21
D11138192,Group1,54
D12226507,Group1,68
D12226546,Group1,67
D11138122,Group1,24
D11138184,Group1,59
D11138797,Group1,22
D11138152,Group1,53
D11138150,Group1,41
D11137167,Group3,14
D11137159,Group3,13
D11137167,Group3,16
D11137159,Group3,13
D11131039,Group2 b,67
D11135566,Group2 b,73
D11119903,Group2 b,83
D11137544,Group1,21
D11137443,Group3,11
D11137123,Group2 b,69
D11137439,Group3,79
D11137439,Group3,15
D11133100,Group1,23
D11144030,Group3,13
D11108399,Group1,23
D11108326,Group1,59
D11119909,Group2 b,61
D11110893,Group1,28
</code></pre>
<p><strong>Example 7:</strong> Replace <code>A</code> by <code>W,</code> <code>B</code> by <code>X</code>, <code>C</code> by <code>Y</code>, and <code>D</code> by <code>Z</code> in <code>file3.csv</code> (replace letters in the range A-D with letters in the range W-Z).</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr 'A-D' 'W-Z'
Wnonymized IZ,Subject Group,WGE
Y11138122,MISSING,21
Y11138192,Group1,54
X12226507,Group1,68
X12226546,Group1,67
Y11138122,Group1,24
Y11138184,Group1,59
Y11138797,Group1,22
Y11138152,Group1,53
Y11138150,Group1,41
Y11137167,Group3,14
Y11137159,Group3,13
Y11137167,Group3,16
Y11137159,Group3,13
Y11131039,Group2 b,67
Y11135566,Group2 b,73
X11119903,Group2 b,83
Y11137544,Group1,21
Y11137443,Group3,11
Y11137123,Group2 b,69
Y11137439,Group3,79
Y11137439,Group3,15
Y11133100,Group1,23
Z11144030,Group3,13
X11108399,Group1,23
X11108326,Group1,59
X11119909,Group2 b,61
X11110893,Group1,28
</code></pre>
<p><strong>Example 8:</strong> Remove all spaces in <code>file3.csv</code>: you can use the <code>-d</code> flag for deletion.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr -d '[:blank:]'
AnonymizedID,SubjectGroup,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2b,67
C11135566,Group2b,73
B11119903,Group2b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2b,61
B11110893,Group1,28
</code></pre>
<p><strong>Example 9:</strong> Remove any repeated characters (<code>[:alnum:]</code>) in <code>file3.csv</code>: In order to delete any repeated (continuous) character or sequence use the <code>-s</code> flag.</p>
<p>Original content of the file:</p>
<pre><code class="language-bash">$ cat file3.csv
Anonymized ID,Subject Group,AGE
C11138122,MISSING,21
C11138192,Group1,54
B12226507,Group1,68
B12226546,Group1,67
C11138122,Group1,24
C11138184,Group1,59
C11138797,Group1,22
C11138152,Group1,53
C11138150,Group1,41
C11137167,Group3,14
C11137159,Group3,13
C11137167,Group3,16
C11137159,Group3,13
C11131039,Group2 b,67
C11135566,Group2 b,73
B11119903,Group2 b,83
C11137544,Group1,21
C11137443,Group3,11
C11137123,Group2 b,69
C11137439,Group3,79
C11137439,Group3,15
C11133100,Group1,23
D11144030,Group3,13
B11108399,Group1,23
B11108326,Group1,59
B11119909,Group2 b,61
B11110893,Group1,28
</code></pre>
<p>Content after replacements:</p>
<pre><code class="language-bash">$ cat file3.csv | tr -s '[:alnum:]'
Anonymized ID,Subject Group,AGE
C13812,MISING,21
C138192,Group1,54
B126507,Group1,68
B126546,Group1,67
C13812,Group1,24
C138184,Group1,59
C138797,Group1,2
C138152,Group1,53
C138150,Group1,41
C137167,Group3,14
C137159,Group3,13
C137167,Group3,16
C137159,Group3,13
C131039,Group2 b,67
C1356,Group2 b,73
B1903,Group2 b,83
C13754,Group1,21
C13743,Group3,1
C137123,Group2 b,69
C137439,Group3,79
C137439,Group3,15
C1310,Group1,23
D14030,Group3,13
B10839,Group1,23
B108326,Group1,59
B1909,Group2 b,61
B10893,Group1,28
</code></pre>
<h2 id="print-files-information">Print files information</h2>
<p><strong>Example 1:</strong> Print the <em>number of lines</em> in <code>file3.csv</code> and <code>file4.txt</code>.</p>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk '{print NF}' file3.csv | wc -l
28
$ nlines=$(awk '{print NF}' file3.csv | wc -l)
$ echo $nlines
28
</code></pre>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print NF}' file4.txt | wc -l
29
$ nlines=$(awk '{print NF}' file4.txt | wc -l)
$ echo $nlines
29
</code></pre>
<p><strong>Example 2:</strong> Print the <em>number of columns</em> in <code>file3.csv</code> and <code>file4.txt</code>.</p>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '{print NF}' file3.csv | sort –nu
3

$ ncols=$(awk -F',' '{print NF}' file3.csv | sort -nu)
$ echo $ncols
3
</code></pre>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk '{print NF}' file4.txt | sort -nu
3

$ ncols=$(awk '{print NF}' file4.txt | sort -nu)
$ echo $ncols
3
</code></pre>
<p><strong>Example 3:</strong> Print the length of each line of <code>file4.txt</code>.</p>
<p>To get the length of a string you can use the function <code>length()</code>, and pass as parameter <code>$0</code> which obtains all the fields (the whole line).</p>
<p>Print each line:</p>
<pre><code class="language-bash">$ awk '{print $0}' file4.txt
AnonymizedID SubjectGroup AGE
B11108326 Group1 59
B11108399 Group1 23
B11110893 Group1 28
B11119909 Group2 61
D11144030 Group3 11
D11144030 Group3 13
B11119903 Group2 84
C11131039 Group2 67
C11133100 Group1 23
C11135566 Group2 72
C11137159 Group3 11
C11137159 Group3 12
C11137167 Group3 14
C11137167 Group3 16
C11137439 Group3 15
C11137439 Group3 79
C11137443 Group3 15
C11137544 Group1 22
C11137123 Group2 68
C11138150 Group1 44
C11138152 Group1 10
C11138797 Group1 24
C11138184 Group1 57
C11138122 Group1 23
C11138122 MISSING 25
C11138192 Group1 45
B12226507 Group1 26
B12226546 Group1 55
</code></pre>
<p>Print the length of each line:</p>
<pre><code class="language-bash">$ awk '{print length($0)}' file4.txt
29
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
20
19
19
19
</code></pre>
<p><strong>Example 4:</strong> Print the length of the second field (<code>length($2)</code>) in <code>file3.csv</code> and <code>file4.txt</code>.</p>
<p>Comma-separated file:</p>
<pre><code class="language-bash">$ awk '{print length($2)}' file4.txt
12
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
7
6
6
6
</code></pre>
<p>Space-separated file:</p>
<pre><code class="language-bash">$ awk -F',' '{print length($2)}' file3.csv
13
7
6
6
6
6
6
6
6
6
6
6
6
6
8
8
8
6
6
8
6
6
6
6
6
6
8
6
</code></pre>
<p><strong>Example 5:</strong> Print all the lines of <code>file4.txt</code> in upper-case.</p>
<p>To convert a string to upper-case use the function <code>toupper()</code> and pass as parameter <code>$0</code> which contains the whole line.</p>
<pre><code class="language-bash">$ awk '{print toupper($0)}' file4.txt
ANONYMIZEDID SUBJECTGROUP AGE
B11108326 GROUP1 59
B11108399 GROUP1 23
B11110893 GROUP1 28
B11119909 GROUP2 61
D11144030 GROUP3 11
D11144030 GROUP3 13
B11119903 GROUP2 84
C11131039 GROUP2 67
C11133100 GROUP1 23
C11135566 GROUP2 72
C11137159 GROUP3 11
C11137159 GROUP3 12
C11137167 GROUP3 14
C11137167 GROUP3 16
C11137439 GROUP3 15
C11137439 GROUP3 79
C11137443 GROUP3 15
C11137544 GROUP1 22
C11137123 GROUP2 68
C11138150 GROUP1 44
C11138152 GROUP1 10
C11138797 GROUP1 24
C11138184 GROUP1 57
C11138122 GROUP1 23
C11138122 MISSING 25
C11138192 GROUP1 45
B12226507 GROUP1 26
B12226546 GROUP1 55
</code></pre>
<p><strong>Example 6:</strong> Print all the lines of <code>file4.txt</code> in lower-case.</p>
<p>To convert a string to lower-case use the function <code>tolower()</code> and pass as parameter <code>$0</code> which contains the whole line.</p>
<pre><code class="language-bash">$ awk '{print tolower($0)}' file4.txt
anonymizedid subjectgroup age
b11108326 group1 59
b11108399 group1 23
b11110893 group1 28
b11119909 group2 61
d11144030 group3 11
d11144030 group3 13
b11119903 group2 84
c11131039 group2 67
c11133100 group1 23
c11135566 group2 72
c11137159 group3 11
c11137159 group3 12
c11137167 group3 14
c11137167 group3 16
c11137439 group3 15
c11137439 group3 79
c11137443 group3 15
c11137544 group1 22
c11137123 group2 68
c11138150 group1 44
c11138152 group1 10
c11138797 group1 24
c11138184 group1 57
c11138122 group1 23
c11138122 missing 25
c11138192 group1 45
b12226507 group1 26
b12226546 group1 55
</code></pre>
<p>Some other functions that can be used in addition to <code>toupper()</code> and <code>tolower()</code> can be found <a href="https://www.cs.princeton.edu/courses/archive/spr08/cos333/awk.help">here</a>.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../img_files/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../img_files/" class="btn btn-xs btn-link">
        Image files
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../files/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../files/" class="btn btn-xs btn-link">
        File manipulation
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>